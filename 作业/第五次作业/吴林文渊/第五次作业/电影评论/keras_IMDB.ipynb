{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_data,train_labels),(test_data,test_labels)=imdb.load_data(num_words=10000)#选取前10000个最常见的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]#单词索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]#0 负面 1 正面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-76b5b12b3c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_word_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#word_index将单词映射为整数索引的字典\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreverse_word_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#键值颠倒，将整数索引映射为单词\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdecoded_review\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreverse_word_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'?'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#前三个为保留索引\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "word_index=imdb.get_word_index()#word_index将单词映射为整数索引的字典\n",
    "reverse_word_index=dict([(value,key)for (key,value) in word_index.items()])#键值颠倒，将整数索引映射为单词\n",
    "decoded_review=' '.join([reverse_word_index.get(i-3,'?') for i in train_data[0]])#前三个为保留索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#把整数序列编码为二进制矩阵\n",
    "def vectorize_sequences(sequences,dimension=10000):\n",
    "    results=np.zeros((len(sequences),dimension))#创建一个形状为[len(sequences),dimension]的零矩阵\n",
    "    for i ,sequence in enumerate(sequences):\n",
    "        results[i,sequence]=1  #在train_data[i]存在的单词索引为1  单词索引也是数字\n",
    "    return results\n",
    "\n",
    "x_train= vectorize_sequences(train_data)\n",
    "x_test= vectorize_sequences(test_data)\n",
    "\n",
    "#标签向量化\n",
    "\n",
    "y_train=np.asarray(train_labels).astype('float32')\n",
    "y_test=np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#模型定义\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(10000,)))#小于0则输出为0  \n",
    "model.add(Dropout(0.5))#节点50%的丢弃率\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "#配置优化器\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss='binary_crossentropy',#使用交叉熵\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#验证集\n",
    "x_val=x_train[:10000]\n",
    "partial_x_train=x_train[10000:]\n",
    "\n",
    "y_val=y_train[:10000]\n",
    "partial_y_train=y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 4s 254us/step - loss: 0.6407 - acc: 0.6139 - val_loss: 0.5494 - val_acc: 0.8046\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 3s 202us/step - loss: 0.5237 - acc: 0.7535 - val_loss: 0.4357 - val_acc: 0.8586\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 3s 203us/step - loss: 0.4380 - acc: 0.8123 - val_loss: 0.3501 - val_acc: 0.8780\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 3s 214us/step - loss: 0.3677 - acc: 0.8555 - val_loss: 0.3054 - val_acc: 0.8846\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 3s 205us/step - loss: 0.3158 - acc: 0.8819 - val_loss: 0.3045 - val_acc: 0.8740\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 3s 206us/step - loss: 0.2833 - acc: 0.8988 - val_loss: 0.2769 - val_acc: 0.8874\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 3s 205us/step - loss: 0.2501 - acc: 0.9131 - val_loss: 0.2825 - val_acc: 0.8845\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 3s 206us/step - loss: 0.2174 - acc: 0.9255 - val_loss: 0.2913 - val_acc: 0.8835\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 3s 223us/step - loss: 0.1947 - acc: 0.9325 - val_loss: 0.2956 - val_acc: 0.8901\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 4s 241us/step - loss: 0.1722 - acc: 0.9435 - val_loss: 0.3182 - val_acc: 0.8887\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 3s 224us/step - loss: 0.1569 - acc: 0.9491 - val_loss: 0.3212 - val_acc: 0.8869\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 3s 224us/step - loss: 0.1427 - acc: 0.9527 - val_loss: 0.3487 - val_acc: 0.8862\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 5s 313us/step - loss: 0.1243 - acc: 0.9603 - val_loss: 0.3923 - val_acc: 0.8826\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 3s 221us/step - loss: 0.1164 - acc: 0.9623 - val_loss: 0.3993 - val_acc: 0.8836\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 3s 196us/step - loss: 0.1064 - acc: 0.9639 - val_loss: 0.3996 - val_acc: 0.8866\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 3s 200us/step - loss: 0.1011 - acc: 0.9666 - val_loss: 0.4375 - val_acc: 0.8865\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 3s 212us/step - loss: 0.0906 - acc: 0.9697 - val_loss: 0.4785 - val_acc: 0.8862\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 3s 227us/step - loss: 0.0861 - acc: 0.9703 - val_loss: 0.4905 - val_acc: 0.8859\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 3s 200us/step - loss: 0.0849 - acc: 0.9737 - val_loss: 0.4980 - val_acc: 0.8850\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 3s 174us/step - loss: 0.0796 - acc: 0.9735 - val_loss: 0.5155 - val_acc: 0.8871\n"
     ]
    }
   ],
   "source": [
    "#训练模型  \n",
    "history=model.fit(partial_x_train,\n",
    "                 partial_y_train,\n",
    "                 epochs=20,\n",
    "                 batch_size=512,\n",
    "                 validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['acc', 'val_loss', 'loss', 'val_acc'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict=history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54944855012893679, 0.43566300020217896, 0.35009291930198672, 0.30537174491882324, 0.30452811541557312, 0.27687929182052612, 0.28247027359008792, 0.29132863259315489, 0.2955847466945648, 0.31816559724807741, 0.32115684018135071, 0.34870341534614563, 0.39229655008316039, 0.39925487208366395, 0.39955431141853331, 0.43752663850784301, 0.47845565342903135, 0.49046609005928038, 0.49803362994194028, 0.51546882958412166]\n",
      "[0.54944855012893679, 0.43566300020217896, 0.35009291930198672, 0.30537174491882324, 0.30452811541557312, 0.27687929182052612, 0.28247027359008792, 0.29132863259315489, 0.2955847466945648, 0.31816559724807741, 0.32115684018135071, 0.34870341534614563, 0.39229655008316039, 0.39925487208366395, 0.39955431141853331, 0.43752663850784301, 0.47845565342903135, 0.49046609005928038, 0.49803362994194028, 0.51546882958412166]\n"
     ]
    }
   ],
   "source": [
    "loss_values=history_dict['val_loss']\n",
    "val_loss_values=history_dict['val_loss']\n",
    "print(loss_values)\n",
    "print(val_loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 4s 159us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87283999999999995"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=model.evaluate(x_test,y_test)#训练\n",
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
