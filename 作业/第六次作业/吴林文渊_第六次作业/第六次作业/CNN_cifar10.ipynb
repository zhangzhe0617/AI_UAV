{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n",
      "(10000, 1)\n",
      "(50000,)\n",
      "(10000,)\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "y_train=y_train.flatten()#展开\n",
    "y_test=y_test.flatten()\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#缩放数据\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "#消除重复  即得到有多少种类\n",
    "num_classes=len(np.unique(y_train))\n",
    "#编码\n",
    "y_train=to_categorical(y_train,num_classes)\n",
    "y_test =to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               512500    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 528,054\n",
      "Trainable params: 528,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#构造神经网络\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "model=Sequential()\n",
    "model.add(Convolution2D(filters=16,kernel_size=2,padding='same',activation='relu',input_shape=(32,32,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Convolution2D(filters=32,kernel_size=2,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Convolution2D(filters=64,kernel_size=2,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.1))\n",
    "#展开为向量放入MLP中\n",
    "model.add(Flatten())\n",
    "#全连接层\n",
    "model.add(Dense(500,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#交叉熵\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 53s 1ms/step - loss: 0.8839 - acc: 0.7031 - val_loss: 0.9398 - val_acc: 0.6816\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93980, saving model to cifar10.model.best.hdf5\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 52s 1ms/step - loss: 0.8195 - acc: 0.7212 - val_loss: 0.9414 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.93980\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 45s 994us/step - loss: 0.7875 - acc: 0.7300 - val_loss: 0.8571 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.93980 to 0.85714, saving model to cifar10.model.best.hdf5\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 43s 966us/step - loss: 0.7543 - acc: 0.7406 - val_loss: 1.0566 - val_acc: 0.6840\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.85714\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 49s 1ms/step - loss: 0.7325 - acc: 0.7486 - val_loss: 0.8364 - val_acc: 0.7306\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.85714 to 0.83645, saving model to cifar10.model.best.hdf5\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 49s 1ms/step - loss: 0.7123 - acc: 0.7550 - val_loss: 0.8282 - val_acc: 0.7274\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.83645 to 0.82824, saving model to cifar10.model.best.hdf5\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 50s 1ms/step - loss: 0.6879 - acc: 0.7643 - val_loss: 0.8655 - val_acc: 0.7096\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.82824\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 51s 1ms/step - loss: 0.6686 - acc: 0.7706 - val_loss: 0.7752 - val_acc: 0.7406\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.82824 to 0.77521, saving model to cifar10.model.best.hdf5\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 51s 1ms/step - loss: 0.6477 - acc: 0.7782 - val_loss: 0.8152 - val_acc: 0.7312\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.77521\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 50s 1ms/step - loss: 0.6328 - acc: 0.7827 - val_loss: 0.8587 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.77521\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer=ModelCheckpoint(filepath='cifar10.model.best.hdf5',verbose=1,save_best_only=True)\n",
    "hist=model.fit(x_train,y_train,batch_size=128,epochs=10,validation_split=0.1,callbacks=[checkpointer],verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 473us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7229"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#提取训练好的权重\n",
    "model.load_weights('cifar10.model.best.hdf5')\n",
    "score=model.evaluate(x_test,y_test,verbose=1)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
