{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder\n",
    "\n",
    "Sticking with the MNIST dataset, let's improve our autoencoder's performance using convolutional layers. Again, loading modules and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\zhangwenqi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting C:\\Users\\zhangwenqi\\Desktop\\神经网络test\\第二课卷积神经网络\\4自编码器\\MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\zhangwenqi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting C:\\Users\\zhangwenqi\\Desktop\\神经网络test\\第二课卷积神经网络\\4自编码器\\MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting C:\\Users\\zhangwenqi\\Desktop\\神经网络test\\第二课卷积神经网络\\4自编码器\\MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting C:\\Users\\zhangwenqi\\Desktop\\神经网络test\\第二课卷积神经网络\\4自编码器\\MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\zhangwenqi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(r'C:\\Users\\zhangwenqi\\Desktop\\神经网络test\\第二课卷积神经网络\\4自编码器\\MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c4d2978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "attachments": {
    "convolutional_autoencoder.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "\n",
    "The encoder part of the network will be a typical convolutional pyramid. Each convolutional layer will be followed by a max-pooling layer to reduce the dimensions of the layers. The decoder though might be something new to you. The decoder needs to convert from a narrow representation to a wide reconstructed image. For example, the representation could be a 4x4x8 max-pool layer. This is the output of the encoder, but also the input to the decoder. We want to get a 28x28x1 image out from the decoder so we need to work our way back up from the narrow decoder input layer. A schematic of the network is shown below.\n",
    "\n",
    "\n",
    "![convolutional_autoencoder.png](attachment:convolutional_autoencoder.png)\n",
    "Here our final encoder layer has size 4x4x8 = 128. The original images have size 28x28 = 784, so the encoded vector is roughly 16% the size of the original image. These are just suggested sizes for each of the layers. Feel free to change the depths and sizes, but remember our goal here is to find a small representation of the input data.\n",
    "\n",
    "### What's going on with the decoder\n",
    "\n",
    "Okay, so the decoder has these \"Upsample\" layers that you might not have seen before. First off, I'll discuss a bit what these layers *aren't*. Usually, you'll see **transposed convolution** layers used to increase the width and height of the layers. They work almost exactly the same as convolutional layers, but in reverse. A stride in the input layer results in a larger stride in the transposed convolution layer. For example, if you have a 3x3 kernel, a 3x3 patch in the input layer will be reduced to one unit in a convolutional layer. Comparatively, one unit in the input layer will be expanded to a 3x3 path in a transposed convolution layer. The TensorFlow API provides us with an easy way to create the layers, [`tf.nn.conv2d_transpose`]   反向卷积过程 ：卷积逆过程，将卷积层一个点恢复成3*3的输入(https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose). \n",
    "\n",
    "However, transposed convolution layers can lead to artifacts in the final images, such as checkerboard patterns. This is due to overlap in the kernels which can be avoided by setting the stride and kernel size equal. In [this Distill article](http://distill.pub/2016/deconv-checkerboard/) from Augustus Odena, *et al*, the authors show that these checkerboard artifacts can be avoided by resizing the layers using nearest neighbor or bilinear interpolation (upsampling) followed by a convolutional layer采用近邻采样或者双线性插值能够解决反向卷积过程中的棋盘问题. In TensorFlow, this is easily done with [`tf.image.resize_images`](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/image/resize_images), followed by a convolution. Be sure to read the Distill article to get a better understanding of deconvolutional layers and why we're using upsampling.\n",
    "\n",
    "> **Exercise:** Build the network shown above. Remember that a convolutional layer with strides of 1 and 'same' padding won't reduce the height and width. That is, if the input is 28x28 and the convolution layer has stride = 1 and 'same' padding, the convolutional layer will also be 28x28. The max-pool layers are used the reduce the width and height. A stride of 2 will reduce the size by a factor of 2. Odena *et al* claim that nearest neighbor interpolation works best for the upsampling(近邻插值是较好的上采样办法), so make sure to include that as a parameter in `tf.image.resize_images` or use [`tf.image.resize_nearest_neighbor`]( `https://www.tensorflow.org/api_docs/python/tf/image/resize_nearest_neighbor). For convolutional layers, use [`tf.layers.conv2d`](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d). For example, you would write `conv1 = tf.layers.conv2d(inputs, 32, (5,5), padding='same', activation=tf.nn.relu)` for a layer with a depth of 32, a 5x5 kernel, stride of (1,1), padding is 'same', and a ReLU activation. Similarly, for the max-pool layers, use [`tf.layers.max_pooling2d`](https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像的上采样方法有很多种，即多种插值方法，较为简单的是邻近插值和双线性插值法，邻近插值计算量小，但容易造成边缘的灰度不连续，双线性插值正好相反，效果较好，但是容易造成边缘模糊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 16, (3,3), padding='same', activation=tf.nn.relu)#深度16，卷积窗3*3\n",
    "# Now 28x28x16\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')#最大池化层，池化窗2*2，步幅2*2\n",
    "# Now 14x14x16\n",
    "conv2 = tf.layers.conv2d(maxpool1, 8, (3,3), padding='same', activation=tf.nn.relu)#深度8\n",
    "# Now 14x14x8\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')#最大池化\n",
    "# Now 7x7x8\n",
    "conv3 = tf.layers.conv2d(maxpool2, 8, (3,3), padding='same', activation=tf.nn.relu)#在卷积 深度8\n",
    "# Now 7x7x8\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')#最大池化 \n",
    "# Now 4x4x8\n",
    "# 去卷积过程    上采样-卷积-上采样-卷积\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))#最邻近法上采样\n",
    "# Now 7x7x8\n",
    "conv4 = tf.layers.conv2d(upsample1, 8, (3,3), padding='same', activation=tf.nn.relu)#卷积\n",
    "# Now 7x7x8\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))#上采样\n",
    "# Now 14x14x8\n",
    "conv5 = tf.layers.conv2d(upsample2, 8, (3,3), padding='same', activation=tf.nn.relu)#卷积\n",
    "# Now 14x14x8\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))#上采样\n",
    "# Now 28x28x8\n",
    "conv6 = tf.layers.conv2d(upsample3, 16, (3,3), padding='same', activation=tf.nn.relu)#卷积\n",
    "# Now 28x28x16\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)#最后卷积变成28*28*1\n",
    "#Now 28x28x1\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "As before, here wi'll train the network. Instead of flattening the images though, we can pass them in as 28x28x1 arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.7096\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.6941\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.6839\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.6736\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.6602\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.6426\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.6174\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.5899\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.5533\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.5311\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.5260\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.5386\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.5344\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.5232\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.4819\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.4820\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.4699\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.4638\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.4515\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.4425\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.4227\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.4277\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.4063\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.3955\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.3730\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.3497\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.3469\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.3243\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.3161\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.3016\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2854\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2718\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2653\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2548\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2579\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2423\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2268\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2337\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2332\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2289\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2258\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2295\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2217\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2214\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2081\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2217\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2181\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2134\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2091\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2052\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2040\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2042\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2055\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2062\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2030\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1977\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2042\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2020\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.2031\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1969\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1938\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1946\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1902\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1813\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1830\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1791\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1763\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1749\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1821\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1797\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1754\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1775\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1757\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1792\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1739\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1748\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1771\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1735\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1716\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1707\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1644\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1658\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1686\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1649\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1669\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1663\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1681\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1616\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1642\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1643\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1632\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1634\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1593\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1616\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1560\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1584\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1650\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1556\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1550\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1606\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1604\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1513\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1566\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1559\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1512\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1545\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1577\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1521\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1520\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1515\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1515\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1481\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1494\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1475\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1502\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1580\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1540\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1487\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1481\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1451\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1468\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1461\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1465\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1425\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1446\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1409\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1479\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1461\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1456\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1443\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1435\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1434\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1456\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1459\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1395\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1406\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1462\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1385\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1404\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1424\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1466\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1414\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1384\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.1404\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1407\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1405\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1357\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1419\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1360\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1370\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1398\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1392\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1372\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1403\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1414\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1411\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1421\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1350\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1326\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1392\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1321\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1369\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1430\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1367\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1399\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1384\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1320\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1334\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1375\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1367\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1341\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1336\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1308\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1343\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1336\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1359\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1278\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1316\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1304\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1312\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1290\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1261\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1339\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1276\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1304\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1338\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1278\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1341\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1316\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1298\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1323\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1351\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1306\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1352\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1279\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1357\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1316\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1300\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1256\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1287\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1288\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1263\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1283\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1322\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1274\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1253\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1278\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1307\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1248\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1310\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1268\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1239\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1231\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1283\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1224\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1256\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1243\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1255\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1238\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1239\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1267\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1246\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1286\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1179\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1225\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1236\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1243\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1228\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1220\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1218\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1239\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1279\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1210\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1215\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1229\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1200\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1262\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1222\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1232\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1201\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1184\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1250\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1238\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1183\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1225\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1201\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1243\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1203\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1233\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1218\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1232\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1256\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1205\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1189\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1225\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1178\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1210\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1182\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1231\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1168\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1212\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1203\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1221\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1174\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1200\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1180\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1197\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1209\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1188\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1212\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1179\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1189\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1194\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1154\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1168\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1195\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1209\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1152\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1130\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1179\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1143\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1163\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1176\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1198\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1138\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1150\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1153\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1159\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1163\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1166\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 1/20... Training loss: 0.1137\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1174\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1156\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1129\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1142\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20... Training loss: 0.1144\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1186\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1170\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1189\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1166\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1157\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1130\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1119\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1144\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1140\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1167\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1164\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1111\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1120\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1180\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1174\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1168\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1161\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1157\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1141\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1123\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1186\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1135\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1161\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1112\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1153\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1165\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1155\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1152\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1143\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1171\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1109\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1126\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1111\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1138\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1109\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1159\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1136\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1103\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1161\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1134\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1141\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1143\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1082\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1111\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1139\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1165\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1119\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1122\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1072\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1105\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1112\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1112\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1145\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1070\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1106\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1093\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1120\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1126\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1123\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1109\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1072\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1051\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1094\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1105\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1116\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1122\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1113\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1103\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1120\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1108\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1158\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1055\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1106\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1068\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1085\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1081\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1118\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1087\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1080\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1065\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1068\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1068\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1055\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1094\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1115\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1072\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1080\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1096\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1083\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1115\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1111\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1097\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1112\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1091\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1115\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1060\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1043\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1094\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1080\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1074\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1076\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1056\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1066\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1074\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1029\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1068\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1082\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1059\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1072\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1123\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1058\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1054\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1099\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1087\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1069\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1082\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1040\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1079\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1066\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1102\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1069\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1073\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1069\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1038\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1060\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1084\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1110\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1088\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1102\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1044\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1089\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1051\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1068\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1100\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1068\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1075\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1060\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1082\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1053\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1065\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1057\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1103\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1086\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1084\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1045\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1028\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1036\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1010\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1086\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1057\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1093\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20... Training loss: 0.1075\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1083\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1040\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1041\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1022\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1076\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1017\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1041\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1038\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1043\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1035\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1024\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1062\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1104\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1052\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1045\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1076\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1061\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1029\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1058\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1058\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1053\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1054\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1039\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1079\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1042\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1037\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1087\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1053\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1064\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1041\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1004\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1021\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1025\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1052\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1042\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1055\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1016\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1023\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1056\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1043\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1050\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1053\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1035\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1022\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1033\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1057\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1051\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1032\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1056\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1038\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1098\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1055\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1067\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1011\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1048\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1011\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1027\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1062\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1022\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1056\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1050\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1017\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1059\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1031\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1030\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1040\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1025\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1025\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1032\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1003\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1032\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1009\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1041\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1071\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1054\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1052\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1008\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1035\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1066\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0994\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1025\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1068\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1022\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1007\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0997\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1008\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1004\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1026\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1032\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1027\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1035\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1008\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1000\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1016\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1008\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1005\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1005\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1031\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0972\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1002\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1007\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0979\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1028\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1009\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0997\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0987\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0956\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1044\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1033\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1036\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1039\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1017\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1021\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1021\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1001\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1009\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0997\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1033\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1029\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0967\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1004\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0986\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1055\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1015\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1017\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0974\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1039\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1051\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1006\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1007\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1016\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1011\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.0963\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1019\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 2/20... Training loss: 0.1017\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0998\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0971\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0991\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0986\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1065\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0987\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1030\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0970\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.1041\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0997\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1025\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1005\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0973\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0983\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1006\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0991\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1003\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0989\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1023\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0985\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1020\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1004\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0990\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1043\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0998\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1011\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1008\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0989\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1012\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0989\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0999\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0999\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0978\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0994\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1005\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0998\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1012\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0960\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0993\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1052\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1032\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1010\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0968\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1005\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0979\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0986\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0999\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0996\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0987\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1008\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1024\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0984\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0975\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0977\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1047\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1032\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1021\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1014\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0977\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0995\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0948\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0992\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0975\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0970\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1016\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1008\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1022\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0994\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1012\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1000\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0993\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0978\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0966\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0970\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1034\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0986\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0973\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0939\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0980\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0991\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0985\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0962\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0998\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0974\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0976\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0958\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0979\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0965\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0986\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0977\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0990\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0936\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0971\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0973\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0971\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1024\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0976\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0983\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0942\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0971\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0917\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0987\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0988\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0986\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0982\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1016\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0952\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0956\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0969\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0991\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0978\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0972\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0984\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0976\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0945\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0936\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0941\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0958\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0988\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0967\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0955\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0967\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1002\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0966\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0990\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0945\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0991\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0968\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0967\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0947\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0999\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0999\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0920\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0992\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0937\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0974\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0986\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0973\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0983\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0971\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0978\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0948\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0990\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0984\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0984\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0985\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0990\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0950\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0998\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0944\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0980\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0961\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0966\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0965\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0971\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0969\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0980\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1004\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0962\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0960\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0949\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0986\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0984\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0966\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0947\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0961\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0954\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0965\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0946\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0968\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0991\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0958\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0964\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0966\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0998\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0975\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0972\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0960\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1001\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0984\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0954\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0950\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0948\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0970\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0946\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0954\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0964\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0942\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0968\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0980\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0966\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0954\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0966\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0965\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0934\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0978\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0944\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0952\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0933\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0924\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0948\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.1008\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0955\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0970\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0937\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0943\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0933\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0956\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0943\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0976\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0972\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0965\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0936\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0966\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0964\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0926\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0954\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0950\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0964\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0956\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0977\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0960\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0964\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0972\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0923\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0951\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0970\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0960\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0958\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0979\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0967\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0946\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0945\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0947\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0960\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0920\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0953\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0939\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0971\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0952\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0979\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0957\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0923\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0938\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0954\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0999\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0936\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0933\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0964\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0975\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0919\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0932\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0972\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0967\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0963\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0958\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0969\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0947\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0905\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0932\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0937\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0940\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0968\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0960\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0950\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0944\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0955\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0963\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0991\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0939\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0995\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0956\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 3/20... Training loss: 0.0955\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0965\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0977\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0934\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0926\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0939\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0978\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0940\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0952\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20... Training loss: 0.0933\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0941\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0918\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0924\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0971\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0967\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0937\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0947\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0923\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0931\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0932\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0972\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0951\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0938\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0926\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0918\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0932\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0939\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0943\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0935\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0959\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0946\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0949\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0950\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0944\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0941\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0940\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0932\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0957\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0944\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0941\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0944\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0948\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0958\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0931\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0920\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0924\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0920\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0935\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0935\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0921\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0919\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0957\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0953\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0896\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0945\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0938\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0936\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0902\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0919\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0936\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0920\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0947\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0957\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0894\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0905\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0921\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0940\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0919\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0946\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0962\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0948\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0949\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0938\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0938\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0932\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0955\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0954\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0919\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0958\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0956\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0954\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0948\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0946\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0915\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0955\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0915\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0894\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0935\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0915\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0931\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0915\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0968\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0920\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0921\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0939\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0918\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0954\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0940\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20... Training loss: 0.0937\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0921\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0923\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0917\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0937\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0918\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0950\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0938\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0924\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0937\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0944\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0932\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0916\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0936\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0930\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0903\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0926\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0926\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0933\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0917\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0939\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0937\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0952\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0961\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0931\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0852\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0919\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0921\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0931\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0905\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0918\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0935\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0935\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0936\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0933\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0886\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0894\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0918\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0905\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0918\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0917\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0905\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0921\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0905\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0902\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0902\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0920\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0931\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0923\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0931\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0967\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0943\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 4/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0922\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0902\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0896\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0916\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0916\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0871\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0919\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0918\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0894\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0897\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0931\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0897\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0896\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0941\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0917\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0905\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0902\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0899\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0903\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0920\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0940\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0863\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0920\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0934\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0896\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0915\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0897\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0917\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0917\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0897\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0899\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0899\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0899\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0917\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0903\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0925\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0919\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0911\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0928\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0886\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0899\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0894\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0914\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0852\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0854\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0886\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0886\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0923\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0902\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0839\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0929\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0896\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0894\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0871\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0894\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0847\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0894\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0905\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0913\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0915\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0901\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0841\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0854\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0915\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0871\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0897\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 5/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0834\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0850\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0836\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0927\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0906\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0896\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0867\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0897\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0850\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0902\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0845\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0897\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0909\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0850\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0886\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0898\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0886\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0849\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0908\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0837\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0895\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0871\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0849\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0846\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0847\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0919\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0903\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0867\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0834\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0854\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0841\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0840\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0867\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0831\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0800\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0832\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0863\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0825\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0830\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0846\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0816\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0846\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0834\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0863\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0871\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0867\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0886\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0900\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0896\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0845\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0829\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0863\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0854\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0854\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0894\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0848\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0854\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0910\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0838\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0838\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0854\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0850\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0912\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0867\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0840\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0886\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0871\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0854\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0825\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0907\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 6/20... Training loss: 0.0893\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0892\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0835\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0849\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0889\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0886\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0829\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0897\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0883\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0836\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0852\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0848\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0808\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0887\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0891\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0845\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0871\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0823\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0837\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0837\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0863\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0888\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0830\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0890\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0833\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0856\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0841\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0831\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0867\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0850\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0904\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0897\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0835\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0827\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0845\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0825\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0816\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0846\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0840\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0841\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0825\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0830\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0847\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0878\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0863\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0814\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0835\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0841\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0852\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0840\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0863\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0868\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0848\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0848\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0822\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0852\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0845\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0848\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0849\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0839\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0880\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0825\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0855\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0837\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0847\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0849\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0850\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0841\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0849\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0850\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0874\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0847\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0873\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0871\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0847\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0836\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0820\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0827\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0838\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0861\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0845\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0848\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0857\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0833\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0847\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0879\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0870\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0863\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0851\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0877\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0885\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0881\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0859\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0869\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0853\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20... Training loss: 0.0858\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0839\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0852\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0867\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0837\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0876\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0860\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0848\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0872\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0832\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0882\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0852\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0848\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0865\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0837\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0837\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0845\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0866\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0884\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0831\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0841\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0836\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0875\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0864\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0863\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0840\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0843\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0862\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0841\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0846\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0842\n",
      "(200, 28, 28, 1)\n",
      "Epoch: 7/20... Training loss: 0.0844\n",
      "(200, 28, 28, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0656c93b4081>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: imgs,\n\u001b[1;32m---> 10\u001b[1;33m                                                          targets_: imgs})\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "\u001b[1;32mc:\\users\\zhangwenqi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhangwenqi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhangwenqi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhangwenqi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhangwenqi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhangwenqi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        print(np.shape(imgs))\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: in_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([in_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising 利用自编码器完成图片降噪\n",
    "\n",
    "As I've mentioned before, autoencoders like the ones you've built so far aren't too useful in practive. However, they can be used to denoise images quite successfully just by training the network on noisy images. We can create the noisy images ourselves by adding Gaussian noise to the training images, then clipping the values to be between 0 and 1. We'll use noisy images as input and the original, clean images as targets. Here's an example of the noisy images I generated and the denoised images.\n",
    "\n",
    "Since this is a harder problem for the network, we'll want to use deeper convolutional layers here, more feature maps. I suggest something like 32-32-16 for the depths of the convolutional layers in the encoder, and the same depths going backward through the decoder. Otherwise the architecture is the same as before.\n",
    "\n",
    "> **Exercise:** Build the network for the denoising autoencoder. It's the same as before, but with deeper layers. I suggest 32-32-16 for the depths, but you can play with these numbers, or add more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "# Now 14x14x32\n",
    "conv2 = tf.layers.conv2d(maxpool1, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "# Now 7x7x32\n",
    "conv3 = tf.layers.conv2d(maxpool2, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')#最后是4*4*16的编码模式 \n",
    "# Now 4x4x16\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x16\n",
    "conv4 = tf.layers.conv2d(upsample1, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "# Now 14x14x16\n",
    "conv5 = tf.layers.conv2d(upsample2, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x32\n",
    "conv6 = tf.layers.conv2d(upsample3, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 28, 28, 1)\n",
      "(200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(imgs))\n",
    "noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "print(np.shape(noisy_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.6872\n",
      "Epoch: 1/100... Training loss: 0.6520\n",
      "Epoch: 1/100... Training loss: 0.6130\n",
      "Epoch: 1/100... Training loss: 0.5677\n",
      "Epoch: 1/100... Training loss: 0.5197\n",
      "Epoch: 1/100... Training loss: 0.5078\n",
      "Epoch: 1/100... Training loss: 0.5370\n",
      "Epoch: 1/100... Training loss: 0.5123\n",
      "Epoch: 1/100... Training loss: 0.5119\n",
      "Epoch: 1/100... Training loss: 0.4758\n",
      "Epoch: 1/100... Training loss: 0.4694\n",
      "Epoch: 1/100... Training loss: 0.4791\n",
      "Epoch: 1/100... Training loss: 0.4615\n",
      "Epoch: 1/100... Training loss: 0.4645\n",
      "Epoch: 1/100... Training loss: 0.4498\n",
      "Epoch: 1/100... Training loss: 0.4323\n",
      "Epoch: 1/100... Training loss: 0.4244\n",
      "Epoch: 1/100... Training loss: 0.4134\n",
      "Epoch: 1/100... Training loss: 0.4074\n",
      "Epoch: 1/100... Training loss: 0.3890\n",
      "Epoch: 1/100... Training loss: 0.3747\n",
      "Epoch: 1/100... Training loss: 0.3636\n",
      "Epoch: 1/100... Training loss: 0.3576\n",
      "Epoch: 1/100... Training loss: 0.3425\n",
      "Epoch: 1/100... Training loss: 0.3318\n",
      "Epoch: 1/100... Training loss: 0.3123\n",
      "Epoch: 1/100... Training loss: 0.3114\n",
      "Epoch: 1/100... Training loss: 0.3041\n",
      "Epoch: 1/100... Training loss: 0.2936\n",
      "Epoch: 1/100... Training loss: 0.2910\n",
      "Epoch: 1/100... Training loss: 0.2860\n",
      "Epoch: 1/100... Training loss: 0.2785\n",
      "Epoch: 1/100... Training loss: 0.2728\n",
      "Epoch: 1/100... Training loss: 0.2755\n",
      "Epoch: 1/100... Training loss: 0.2687\n",
      "Epoch: 1/100... Training loss: 0.2716\n",
      "Epoch: 1/100... Training loss: 0.2646\n",
      "Epoch: 1/100... Training loss: 0.2649\n",
      "Epoch: 1/100... Training loss: 0.2613\n",
      "Epoch: 1/100... Training loss: 0.2714\n",
      "Epoch: 1/100... Training loss: 0.2581\n",
      "Epoch: 1/100... Training loss: 0.2596\n",
      "Epoch: 1/100... Training loss: 0.2530\n",
      "Epoch: 1/100... Training loss: 0.2622\n",
      "Epoch: 1/100... Training loss: 0.2458\n",
      "Epoch: 1/100... Training loss: 0.2395\n",
      "Epoch: 1/100... Training loss: 0.2481\n",
      "Epoch: 1/100... Training loss: 0.2438\n",
      "Epoch: 1/100... Training loss: 0.2411\n",
      "Epoch: 1/100... Training loss: 0.2497\n",
      "Epoch: 1/100... Training loss: 0.2526\n",
      "Epoch: 1/100... Training loss: 0.2460\n",
      "Epoch: 1/100... Training loss: 0.2427\n",
      "Epoch: 1/100... Training loss: 0.2356\n",
      "Epoch: 1/100... Training loss: 0.2359\n",
      "Epoch: 1/100... Training loss: 0.2366\n",
      "Epoch: 1/100... Training loss: 0.2358\n",
      "Epoch: 1/100... Training loss: 0.2303\n",
      "Epoch: 1/100... Training loss: 0.2323\n",
      "Epoch: 1/100... Training loss: 0.2296\n",
      "Epoch: 1/100... Training loss: 0.2248\n",
      "Epoch: 1/100... Training loss: 0.2325\n",
      "Epoch: 1/100... Training loss: 0.2274\n",
      "Epoch: 1/100... Training loss: 0.2249\n",
      "Epoch: 1/100... Training loss: 0.2289\n",
      "Epoch: 1/100... Training loss: 0.2266\n",
      "Epoch: 1/100... Training loss: 0.2286\n",
      "Epoch: 1/100... Training loss: 0.2206\n",
      "Epoch: 1/100... Training loss: 0.2202\n",
      "Epoch: 1/100... Training loss: 0.2237\n",
      "Epoch: 1/100... Training loss: 0.2296\n",
      "Epoch: 1/100... Training loss: 0.2319\n",
      "Epoch: 1/100... Training loss: 0.2265\n",
      "Epoch: 1/100... Training loss: 0.2220\n",
      "Epoch: 1/100... Training loss: 0.2231\n",
      "Epoch: 1/100... Training loss: 0.2187\n",
      "Epoch: 1/100... Training loss: 0.2249\n",
      "Epoch: 1/100... Training loss: 0.2202\n",
      "Epoch: 1/100... Training loss: 0.2168\n",
      "Epoch: 1/100... Training loss: 0.2201\n",
      "Epoch: 1/100... Training loss: 0.2171\n",
      "Epoch: 1/100... Training loss: 0.2143\n",
      "Epoch: 1/100... Training loss: 0.2162\n",
      "Epoch: 1/100... Training loss: 0.2245\n",
      "Epoch: 1/100... Training loss: 0.2167\n",
      "Epoch: 1/100... Training loss: 0.2185\n",
      "Epoch: 1/100... Training loss: 0.2151\n",
      "Epoch: 1/100... Training loss: 0.2193\n",
      "Epoch: 1/100... Training loss: 0.2195\n",
      "Epoch: 1/100... Training loss: 0.2137\n",
      "Epoch: 1/100... Training loss: 0.2155\n",
      "Epoch: 1/100... Training loss: 0.2176\n",
      "Epoch: 1/100... Training loss: 0.2143\n",
      "Epoch: 1/100... Training loss: 0.2190\n",
      "Epoch: 1/100... Training loss: 0.2123\n",
      "Epoch: 1/100... Training loss: 0.2185\n",
      "Epoch: 1/100... Training loss: 0.2119\n",
      "Epoch: 1/100... Training loss: 0.2101\n",
      "Epoch: 1/100... Training loss: 0.2140\n",
      "Epoch: 1/100... Training loss: 0.2130\n",
      "Epoch: 1/100... Training loss: 0.2151\n",
      "Epoch: 1/100... Training loss: 0.2145\n",
      "Epoch: 1/100... Training loss: 0.2083\n",
      "Epoch: 1/100... Training loss: 0.2051\n",
      "Epoch: 1/100... Training loss: 0.2112\n",
      "Epoch: 1/100... Training loss: 0.2098\n",
      "Epoch: 1/100... Training loss: 0.2098\n",
      "Epoch: 1/100... Training loss: 0.2123\n",
      "Epoch: 1/100... Training loss: 0.2079\n",
      "Epoch: 1/100... Training loss: 0.2115\n",
      "Epoch: 1/100... Training loss: 0.2088\n",
      "Epoch: 1/100... Training loss: 0.2037\n",
      "Epoch: 1/100... Training loss: 0.2059\n",
      "Epoch: 1/100... Training loss: 0.2006\n",
      "Epoch: 1/100... Training loss: 0.2079\n",
      "Epoch: 1/100... Training loss: 0.2082\n",
      "Epoch: 1/100... Training loss: 0.2063\n",
      "Epoch: 1/100... Training loss: 0.2022\n",
      "Epoch: 1/100... Training loss: 0.2079\n",
      "Epoch: 1/100... Training loss: 0.2023\n",
      "Epoch: 1/100... Training loss: 0.2022\n",
      "Epoch: 1/100... Training loss: 0.2037\n",
      "Epoch: 1/100... Training loss: 0.1973\n",
      "Epoch: 1/100... Training loss: 0.2012\n",
      "Epoch: 1/100... Training loss: 0.2006\n",
      "Epoch: 1/100... Training loss: 0.2031\n",
      "Epoch: 1/100... Training loss: 0.1994\n",
      "Epoch: 1/100... Training loss: 0.2033\n",
      "Epoch: 1/100... Training loss: 0.2041\n",
      "Epoch: 1/100... Training loss: 0.1961\n",
      "Epoch: 1/100... Training loss: 0.2028\n",
      "Epoch: 1/100... Training loss: 0.2017\n",
      "Epoch: 1/100... Training loss: 0.2037\n",
      "Epoch: 1/100... Training loss: 0.2002\n",
      "Epoch: 1/100... Training loss: 0.2030\n",
      "Epoch: 1/100... Training loss: 0.1963\n",
      "Epoch: 1/100... Training loss: 0.1995\n",
      "Epoch: 1/100... Training loss: 0.1996\n",
      "Epoch: 1/100... Training loss: 0.1922\n",
      "Epoch: 1/100... Training loss: 0.1979\n",
      "Epoch: 1/100... Training loss: 0.1912\n",
      "Epoch: 1/100... Training loss: 0.1986\n",
      "Epoch: 1/100... Training loss: 0.1943\n",
      "Epoch: 1/100... Training loss: 0.1922\n",
      "Epoch: 1/100... Training loss: 0.1957\n",
      "Epoch: 1/100... Training loss: 0.1922\n",
      "Epoch: 1/100... Training loss: 0.1955\n",
      "Epoch: 1/100... Training loss: 0.1957\n",
      "Epoch: 1/100... Training loss: 0.1936\n",
      "Epoch: 1/100... Training loss: 0.1931\n",
      "Epoch: 1/100... Training loss: 0.1962\n",
      "Epoch: 1/100... Training loss: 0.1920\n",
      "Epoch: 1/100... Training loss: 0.1969\n",
      "Epoch: 1/100... Training loss: 0.1937\n",
      "Epoch: 1/100... Training loss: 0.1919\n",
      "Epoch: 1/100... Training loss: 0.1841\n",
      "Epoch: 1/100... Training loss: 0.1944\n",
      "Epoch: 1/100... Training loss: 0.1890\n",
      "Epoch: 1/100... Training loss: 0.1912\n",
      "Epoch: 1/100... Training loss: 0.1983\n",
      "Epoch: 1/100... Training loss: 0.1879\n",
      "Epoch: 1/100... Training loss: 0.1863\n",
      "Epoch: 1/100... Training loss: 0.1910\n",
      "Epoch: 1/100... Training loss: 0.1918\n",
      "Epoch: 1/100... Training loss: 0.1895\n",
      "Epoch: 1/100... Training loss: 0.1872\n",
      "Epoch: 1/100... Training loss: 0.1916\n",
      "Epoch: 1/100... Training loss: 0.1880\n",
      "Epoch: 1/100... Training loss: 0.1894\n",
      "Epoch: 1/100... Training loss: 0.1822\n",
      "Epoch: 1/100... Training loss: 0.1932\n",
      "Epoch: 1/100... Training loss: 0.1948\n",
      "Epoch: 1/100... Training loss: 0.1869\n",
      "Epoch: 1/100... Training loss: 0.1866\n",
      "Epoch: 1/100... Training loss: 0.1838\n",
      "Epoch: 1/100... Training loss: 0.1885\n",
      "Epoch: 1/100... Training loss: 0.1902\n",
      "Epoch: 1/100... Training loss: 0.1907\n",
      "Epoch: 1/100... Training loss: 0.1822\n",
      "Epoch: 1/100... Training loss: 0.1844\n",
      "Epoch: 1/100... Training loss: 0.1847\n",
      "Epoch: 1/100... Training loss: 0.1937\n",
      "Epoch: 1/100... Training loss: 0.1829\n",
      "Epoch: 1/100... Training loss: 0.1851\n",
      "Epoch: 1/100... Training loss: 0.1857\n",
      "Epoch: 1/100... Training loss: 0.1865\n",
      "Epoch: 1/100... Training loss: 0.1832\n",
      "Epoch: 1/100... Training loss: 0.1860\n",
      "Epoch: 1/100... Training loss: 0.1849\n",
      "Epoch: 1/100... Training loss: 0.1808\n",
      "Epoch: 1/100... Training loss: 0.1777\n",
      "Epoch: 1/100... Training loss: 0.1817\n",
      "Epoch: 1/100... Training loss: 0.1875\n",
      "Epoch: 1/100... Training loss: 0.1842\n",
      "Epoch: 1/100... Training loss: 0.1797\n",
      "Epoch: 1/100... Training loss: 0.1782\n",
      "Epoch: 1/100... Training loss: 0.1807\n",
      "Epoch: 1/100... Training loss: 0.1855\n",
      "Epoch: 1/100... Training loss: 0.1812\n",
      "Epoch: 1/100... Training loss: 0.1877\n",
      "Epoch: 1/100... Training loss: 0.1880\n",
      "Epoch: 1/100... Training loss: 0.1809\n",
      "Epoch: 1/100... Training loss: 0.1849\n",
      "Epoch: 1/100... Training loss: 0.1798\n",
      "Epoch: 1/100... Training loss: 0.1844\n",
      "Epoch: 1/100... Training loss: 0.1816\n",
      "Epoch: 1/100... Training loss: 0.1822\n",
      "Epoch: 1/100... Training loss: 0.1886\n",
      "Epoch: 1/100... Training loss: 0.1825\n",
      "Epoch: 1/100... Training loss: 0.1830\n",
      "Epoch: 1/100... Training loss: 0.1824\n",
      "Epoch: 1/100... Training loss: 0.1785\n",
      "Epoch: 1/100... Training loss: 0.1793\n",
      "Epoch: 1/100... Training loss: 0.1756\n",
      "Epoch: 1/100... Training loss: 0.1835\n",
      "Epoch: 1/100... Training loss: 0.1785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.1806\n",
      "Epoch: 1/100... Training loss: 0.1775\n",
      "Epoch: 1/100... Training loss: 0.1768\n",
      "Epoch: 1/100... Training loss: 0.1819\n",
      "Epoch: 1/100... Training loss: 0.1805\n",
      "Epoch: 1/100... Training loss: 0.1776\n",
      "Epoch: 1/100... Training loss: 0.1761\n",
      "Epoch: 1/100... Training loss: 0.1735\n",
      "Epoch: 1/100... Training loss: 0.1775\n",
      "Epoch: 1/100... Training loss: 0.1787\n",
      "Epoch: 1/100... Training loss: 0.1807\n",
      "Epoch: 1/100... Training loss: 0.1780\n",
      "Epoch: 1/100... Training loss: 0.1817\n",
      "Epoch: 1/100... Training loss: 0.1717\n",
      "Epoch: 1/100... Training loss: 0.1767\n",
      "Epoch: 1/100... Training loss: 0.1758\n",
      "Epoch: 1/100... Training loss: 0.1769\n",
      "Epoch: 1/100... Training loss: 0.1774\n",
      "Epoch: 1/100... Training loss: 0.1747\n",
      "Epoch: 1/100... Training loss: 0.1741\n",
      "Epoch: 1/100... Training loss: 0.1770\n",
      "Epoch: 1/100... Training loss: 0.1789\n",
      "Epoch: 1/100... Training loss: 0.1741\n",
      "Epoch: 1/100... Training loss: 0.1725\n",
      "Epoch: 1/100... Training loss: 0.1728\n",
      "Epoch: 1/100... Training loss: 0.1767\n",
      "Epoch: 1/100... Training loss: 0.1788\n",
      "Epoch: 1/100... Training loss: 0.1720\n",
      "Epoch: 1/100... Training loss: 0.1717\n",
      "Epoch: 1/100... Training loss: 0.1691\n",
      "Epoch: 1/100... Training loss: 0.1742\n",
      "Epoch: 1/100... Training loss: 0.1678\n",
      "Epoch: 1/100... Training loss: 0.1769\n",
      "Epoch: 1/100... Training loss: 0.1689\n",
      "Epoch: 1/100... Training loss: 0.1746\n",
      "Epoch: 1/100... Training loss: 0.1739\n",
      "Epoch: 1/100... Training loss: 0.1717\n",
      "Epoch: 1/100... Training loss: 0.1700\n",
      "Epoch: 1/100... Training loss: 0.1742\n",
      "Epoch: 1/100... Training loss: 0.1725\n",
      "Epoch: 1/100... Training loss: 0.1782\n",
      "Epoch: 1/100... Training loss: 0.1712\n",
      "Epoch: 1/100... Training loss: 0.1705\n",
      "Epoch: 1/100... Training loss: 0.1736\n",
      "Epoch: 1/100... Training loss: 0.1746\n",
      "Epoch: 1/100... Training loss: 0.1770\n",
      "Epoch: 1/100... Training loss: 0.1705\n",
      "Epoch: 1/100... Training loss: 0.1694\n",
      "Epoch: 1/100... Training loss: 0.1753\n",
      "Epoch: 1/100... Training loss: 0.1758\n",
      "Epoch: 1/100... Training loss: 0.1741\n",
      "Epoch: 1/100... Training loss: 0.1730\n",
      "Epoch: 1/100... Training loss: 0.1646\n",
      "Epoch: 1/100... Training loss: 0.1695\n",
      "Epoch: 1/100... Training loss: 0.1655\n",
      "Epoch: 1/100... Training loss: 0.1710\n",
      "Epoch: 1/100... Training loss: 0.1684\n",
      "Epoch: 1/100... Training loss: 0.1674\n",
      "Epoch: 1/100... Training loss: 0.1717\n",
      "Epoch: 1/100... Training loss: 0.1696\n",
      "Epoch: 1/100... Training loss: 0.1715\n",
      "Epoch: 1/100... Training loss: 0.1671\n",
      "Epoch: 1/100... Training loss: 0.1678\n",
      "Epoch: 1/100... Training loss: 0.1680\n",
      "Epoch: 1/100... Training loss: 0.1674\n",
      "Epoch: 1/100... Training loss: 0.1666\n",
      "Epoch: 1/100... Training loss: 0.1655\n",
      "Epoch: 1/100... Training loss: 0.1656\n",
      "Epoch: 1/100... Training loss: 0.1700\n",
      "Epoch: 1/100... Training loss: 0.1648\n",
      "Epoch: 1/100... Training loss: 0.1691\n",
      "Epoch: 1/100... Training loss: 0.1689\n",
      "Epoch: 1/100... Training loss: 0.1706\n",
      "Epoch: 1/100... Training loss: 0.1671\n",
      "Epoch: 1/100... Training loss: 0.1685\n",
      "Epoch: 1/100... Training loss: 0.1642\n",
      "Epoch: 1/100... Training loss: 0.1678\n",
      "Epoch: 1/100... Training loss: 0.1711\n",
      "Epoch: 1/100... Training loss: 0.1678\n",
      "Epoch: 1/100... Training loss: 0.1653\n",
      "Epoch: 1/100... Training loss: 0.1654\n",
      "Epoch: 1/100... Training loss: 0.1643\n",
      "Epoch: 1/100... Training loss: 0.1677\n",
      "Epoch: 1/100... Training loss: 0.1684\n",
      "Epoch: 2/100... Training loss: 0.1654\n",
      "Epoch: 2/100... Training loss: 0.1652\n",
      "Epoch: 2/100... Training loss: 0.1624\n",
      "Epoch: 2/100... Training loss: 0.1692\n",
      "Epoch: 2/100... Training loss: 0.1641\n",
      "Epoch: 2/100... Training loss: 0.1587\n",
      "Epoch: 2/100... Training loss: 0.1692\n",
      "Epoch: 2/100... Training loss: 0.1686\n",
      "Epoch: 2/100... Training loss: 0.1652\n",
      "Epoch: 2/100... Training loss: 0.1621\n",
      "Epoch: 2/100... Training loss: 0.1650\n",
      "Epoch: 2/100... Training loss: 0.1685\n",
      "Epoch: 2/100... Training loss: 0.1630\n",
      "Epoch: 2/100... Training loss: 0.1649\n",
      "Epoch: 2/100... Training loss: 0.1642\n",
      "Epoch: 2/100... Training loss: 0.1631\n",
      "Epoch: 2/100... Training loss: 0.1605\n",
      "Epoch: 2/100... Training loss: 0.1665\n",
      "Epoch: 2/100... Training loss: 0.1666\n",
      "Epoch: 2/100... Training loss: 0.1688\n",
      "Epoch: 2/100... Training loss: 0.1656\n",
      "Epoch: 2/100... Training loss: 0.1624\n",
      "Epoch: 2/100... Training loss: 0.1641\n",
      "Epoch: 2/100... Training loss: 0.1615\n",
      "Epoch: 2/100... Training loss: 0.1637\n",
      "Epoch: 2/100... Training loss: 0.1658\n",
      "Epoch: 2/100... Training loss: 0.1649\n",
      "Epoch: 2/100... Training loss: 0.1608\n",
      "Epoch: 2/100... Training loss: 0.1653\n",
      "Epoch: 2/100... Training loss: 0.1588\n",
      "Epoch: 2/100... Training loss: 0.1640\n",
      "Epoch: 2/100... Training loss: 0.1607\n",
      "Epoch: 2/100... Training loss: 0.1682\n",
      "Epoch: 2/100... Training loss: 0.1613\n",
      "Epoch: 2/100... Training loss: 0.1618\n",
      "Epoch: 2/100... Training loss: 0.1649\n",
      "Epoch: 2/100... Training loss: 0.1669\n",
      "Epoch: 2/100... Training loss: 0.1607\n",
      "Epoch: 2/100... Training loss: 0.1636\n",
      "Epoch: 2/100... Training loss: 0.1591\n",
      "Epoch: 2/100... Training loss: 0.1604\n",
      "Epoch: 2/100... Training loss: 0.1591\n",
      "Epoch: 2/100... Training loss: 0.1617\n",
      "Epoch: 2/100... Training loss: 0.1613\n",
      "Epoch: 2/100... Training loss: 0.1629\n",
      "Epoch: 2/100... Training loss: 0.1601\n",
      "Epoch: 2/100... Training loss: 0.1608\n",
      "Epoch: 2/100... Training loss: 0.1562\n",
      "Epoch: 2/100... Training loss: 0.1637\n",
      "Epoch: 2/100... Training loss: 0.1595\n",
      "Epoch: 2/100... Training loss: 0.1596\n",
      "Epoch: 2/100... Training loss: 0.1632\n",
      "Epoch: 2/100... Training loss: 0.1603\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1623\n",
      "Epoch: 2/100... Training loss: 0.1583\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1526\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1586\n",
      "Epoch: 2/100... Training loss: 0.1588\n",
      "Epoch: 2/100... Training loss: 0.1600\n",
      "Epoch: 2/100... Training loss: 0.1613\n",
      "Epoch: 2/100... Training loss: 0.1594\n",
      "Epoch: 2/100... Training loss: 0.1593\n",
      "Epoch: 2/100... Training loss: 0.1594\n",
      "Epoch: 2/100... Training loss: 0.1591\n",
      "Epoch: 2/100... Training loss: 0.1564\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1625\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1585\n",
      "Epoch: 2/100... Training loss: 0.1606\n",
      "Epoch: 2/100... Training loss: 0.1587\n",
      "Epoch: 2/100... Training loss: 0.1559\n",
      "Epoch: 2/100... Training loss: 0.1587\n",
      "Epoch: 2/100... Training loss: 0.1636\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1690\n",
      "Epoch: 2/100... Training loss: 0.1597\n",
      "Epoch: 2/100... Training loss: 0.1609\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1577\n",
      "Epoch: 2/100... Training loss: 0.1563\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1579\n",
      "Epoch: 2/100... Training loss: 0.1586\n",
      "Epoch: 2/100... Training loss: 0.1589\n",
      "Epoch: 2/100... Training loss: 0.1553\n",
      "Epoch: 2/100... Training loss: 0.1549\n",
      "Epoch: 2/100... Training loss: 0.1571\n",
      "Epoch: 2/100... Training loss: 0.1594\n",
      "Epoch: 2/100... Training loss: 0.1516\n",
      "Epoch: 2/100... Training loss: 0.1579\n",
      "Epoch: 2/100... Training loss: 0.1573\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1570\n",
      "Epoch: 2/100... Training loss: 0.1559\n",
      "Epoch: 2/100... Training loss: 0.1531\n",
      "Epoch: 2/100... Training loss: 0.1574\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1558\n",
      "Epoch: 2/100... Training loss: 0.1572\n",
      "Epoch: 2/100... Training loss: 0.1547\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1564\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1500\n",
      "Epoch: 2/100... Training loss: 0.1527\n",
      "Epoch: 2/100... Training loss: 0.1567\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1540\n",
      "Epoch: 2/100... Training loss: 0.1564\n",
      "Epoch: 2/100... Training loss: 0.1558\n",
      "Epoch: 2/100... Training loss: 0.1533\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1554\n",
      "Epoch: 2/100... Training loss: 0.1572\n",
      "Epoch: 2/100... Training loss: 0.1515\n",
      "Epoch: 2/100... Training loss: 0.1563\n",
      "Epoch: 2/100... Training loss: 0.1532\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1582\n",
      "Epoch: 2/100... Training loss: 0.1559\n",
      "Epoch: 2/100... Training loss: 0.1537\n",
      "Epoch: 2/100... Training loss: 0.1606\n",
      "Epoch: 2/100... Training loss: 0.1545\n",
      "Epoch: 2/100... Training loss: 0.1539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100... Training loss: 0.1544\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1527\n",
      "Epoch: 2/100... Training loss: 0.1532\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1558\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1529\n",
      "Epoch: 2/100... Training loss: 0.1525\n",
      "Epoch: 2/100... Training loss: 0.1493\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1528\n",
      "Epoch: 2/100... Training loss: 0.1514\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1524\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1525\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1522\n",
      "Epoch: 2/100... Training loss: 0.1508\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1526\n",
      "Epoch: 2/100... Training loss: 0.1528\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1539\n",
      "Epoch: 2/100... Training loss: 0.1462\n",
      "Epoch: 2/100... Training loss: 0.1524\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1503\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1533\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1465\n",
      "Epoch: 2/100... Training loss: 0.1529\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1522\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1483\n",
      "Epoch: 2/100... Training loss: 0.1490\n",
      "Epoch: 2/100... Training loss: 0.1462\n",
      "Epoch: 2/100... Training loss: 0.1489\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1515\n",
      "Epoch: 2/100... Training loss: 0.1418\n",
      "Epoch: 2/100... Training loss: 0.1517\n",
      "Epoch: 2/100... Training loss: 0.1484\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 2/100... Training loss: 0.1435\n",
      "Epoch: 2/100... Training loss: 0.1486\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1483\n",
      "Epoch: 2/100... Training loss: 0.1431\n",
      "Epoch: 2/100... Training loss: 0.1471\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1466\n",
      "Epoch: 2/100... Training loss: 0.1481\n",
      "Epoch: 2/100... Training loss: 0.1480\n",
      "Epoch: 2/100... Training loss: 0.1532\n",
      "Epoch: 2/100... Training loss: 0.1526\n",
      "Epoch: 2/100... Training loss: 0.1449\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1404\n",
      "Epoch: 2/100... Training loss: 0.1531\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1496\n",
      "Epoch: 2/100... Training loss: 0.1444\n",
      "Epoch: 2/100... Training loss: 0.1433\n",
      "Epoch: 2/100... Training loss: 0.1433\n",
      "Epoch: 2/100... Training loss: 0.1490\n",
      "Epoch: 2/100... Training loss: 0.1514\n",
      "Epoch: 2/100... Training loss: 0.1516\n",
      "Epoch: 2/100... Training loss: 0.1504\n",
      "Epoch: 2/100... Training loss: 0.1465\n",
      "Epoch: 2/100... Training loss: 0.1503\n",
      "Epoch: 2/100... Training loss: 0.1476\n",
      "Epoch: 2/100... Training loss: 0.1526\n",
      "Epoch: 2/100... Training loss: 0.1424\n",
      "Epoch: 2/100... Training loss: 0.1456\n",
      "Epoch: 2/100... Training loss: 0.1429\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1451\n",
      "Epoch: 2/100... Training loss: 0.1456\n",
      "Epoch: 2/100... Training loss: 0.1432\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1461\n",
      "Epoch: 2/100... Training loss: 0.1482\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1438\n",
      "Epoch: 2/100... Training loss: 0.1449\n",
      "Epoch: 2/100... Training loss: 0.1453\n",
      "Epoch: 2/100... Training loss: 0.1484\n",
      "Epoch: 2/100... Training loss: 0.1454\n",
      "Epoch: 2/100... Training loss: 0.1507\n",
      "Epoch: 2/100... Training loss: 0.1453\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1475\n",
      "Epoch: 2/100... Training loss: 0.1443\n",
      "Epoch: 2/100... Training loss: 0.1441\n",
      "Epoch: 2/100... Training loss: 0.1451\n",
      "Epoch: 2/100... Training loss: 0.1478\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 2/100... Training loss: 0.1407\n",
      "Epoch: 2/100... Training loss: 0.1449\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1449\n",
      "Epoch: 2/100... Training loss: 0.1401\n",
      "Epoch: 2/100... Training loss: 0.1422\n",
      "Epoch: 2/100... Training loss: 0.1424\n",
      "Epoch: 2/100... Training loss: 0.1438\n",
      "Epoch: 2/100... Training loss: 0.1431\n",
      "Epoch: 2/100... Training loss: 0.1430\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1416\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1462\n",
      "Epoch: 2/100... Training loss: 0.1422\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1450\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1422\n",
      "Epoch: 2/100... Training loss: 0.1484\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1449\n",
      "Epoch: 2/100... Training loss: 0.1420\n",
      "Epoch: 2/100... Training loss: 0.1432\n",
      "Epoch: 2/100... Training loss: 0.1471\n",
      "Epoch: 2/100... Training loss: 0.1441\n",
      "Epoch: 2/100... Training loss: 0.1377\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1464\n",
      "Epoch: 2/100... Training loss: 0.1458\n",
      "Epoch: 2/100... Training loss: 0.1415\n",
      "Epoch: 2/100... Training loss: 0.1351\n",
      "Epoch: 2/100... Training loss: 0.1411\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1461\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1440\n",
      "Epoch: 2/100... Training loss: 0.1432\n",
      "Epoch: 2/100... Training loss: 0.1427\n",
      "Epoch: 2/100... Training loss: 0.1424\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1401\n",
      "Epoch: 2/100... Training loss: 0.1413\n",
      "Epoch: 2/100... Training loss: 0.1421\n",
      "Epoch: 2/100... Training loss: 0.1482\n",
      "Epoch: 2/100... Training loss: 0.1451\n",
      "Epoch: 2/100... Training loss: 0.1458\n",
      "Epoch: 2/100... Training loss: 0.1426\n",
      "Epoch: 2/100... Training loss: 0.1425\n",
      "Epoch: 2/100... Training loss: 0.1440\n",
      "Epoch: 2/100... Training loss: 0.1413\n",
      "Epoch: 2/100... Training loss: 0.1491\n",
      "Epoch: 2/100... Training loss: 0.1436\n",
      "Epoch: 2/100... Training loss: 0.1416\n",
      "Epoch: 2/100... Training loss: 0.1465\n",
      "Epoch: 3/100... Training loss: 0.1442\n",
      "Epoch: 3/100... Training loss: 0.1479\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1467\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1459\n",
      "Epoch: 3/100... Training loss: 0.1439\n",
      "Epoch: 3/100... Training loss: 0.1409\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1463\n",
      "Epoch: 3/100... Training loss: 0.1427\n",
      "Epoch: 3/100... Training loss: 0.1393\n",
      "Epoch: 3/100... Training loss: 0.1390\n",
      "Epoch: 3/100... Training loss: 0.1421\n",
      "Epoch: 3/100... Training loss: 0.1421\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1451\n",
      "Epoch: 3/100... Training loss: 0.1433\n",
      "Epoch: 3/100... Training loss: 0.1436\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1430\n",
      "Epoch: 3/100... Training loss: 0.1428\n",
      "Epoch: 3/100... Training loss: 0.1418\n",
      "Epoch: 3/100... Training loss: 0.1456\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1442\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1442\n",
      "Epoch: 3/100... Training loss: 0.1371\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1409\n",
      "Epoch: 3/100... Training loss: 0.1425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1410\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1468\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1440\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1390\n",
      "Epoch: 3/100... Training loss: 0.1393\n",
      "Epoch: 3/100... Training loss: 0.1308\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1422\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1390\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1395\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1430\n",
      "Epoch: 3/100... Training loss: 0.1361\n",
      "Epoch: 3/100... Training loss: 0.1407\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1403\n",
      "Epoch: 3/100... Training loss: 0.1390\n",
      "Epoch: 3/100... Training loss: 0.1395\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1312\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1346\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1403\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1458\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1342\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1429\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1428\n",
      "Epoch: 3/100... Training loss: 0.1375\n",
      "Epoch: 3/100... Training loss: 0.1368\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1314\n",
      "Epoch: 3/100... Training loss: 0.1347\n",
      "Epoch: 3/100... Training loss: 0.1403\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1395\n",
      "Epoch: 3/100... Training loss: 0.1332\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1411\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1374\n",
      "Epoch: 3/100... Training loss: 0.1384\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1406\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1326\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1299\n",
      "Epoch: 3/100... Training loss: 0.1376\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1342\n",
      "Epoch: 3/100... Training loss: 0.1346\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1294\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1427\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1356\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1336\n",
      "Epoch: 3/100... Training loss: 0.1309\n",
      "Epoch: 3/100... Training loss: 0.1371\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1299\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1384\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1374\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1312\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1374\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1340\n",
      "Epoch: 3/100... Training loss: 0.1330\n",
      "Epoch: 3/100... Training loss: 0.1371\n",
      "Epoch: 3/100... Training loss: 0.1336\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1330\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1298\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1294\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1320\n",
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1395\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1326\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1270\n",
      "Epoch: 3/100... Training loss: 0.1326\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1328\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1337\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1314\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1292\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1326\n",
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1312\n",
      "Epoch: 3/100... Training loss: 0.1304\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1346\n",
      "Epoch: 3/100... Training loss: 0.1343\n",
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1319\n",
      "Epoch: 3/100... Training loss: 0.1338\n",
      "Epoch: 3/100... Training loss: 0.1317\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1321\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1282\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1319\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1310\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1319\n",
      "Epoch: 3/100... Training loss: 0.1313\n",
      "Epoch: 3/100... Training loss: 0.1262\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1308\n",
      "Epoch: 3/100... Training loss: 0.1302\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1330\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1321\n",
      "Epoch: 3/100... Training loss: 0.1315\n",
      "Epoch: 3/100... Training loss: 0.1301\n",
      "Epoch: 3/100... Training loss: 0.1275\n",
      "Epoch: 3/100... Training loss: 0.1313\n",
      "Epoch: 3/100... Training loss: 0.1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Training loss: 0.1281\n",
      "Epoch: 3/100... Training loss: 0.1292\n",
      "Epoch: 3/100... Training loss: 0.1312\n",
      "Epoch: 3/100... Training loss: 0.1323\n",
      "Epoch: 3/100... Training loss: 0.1338\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1344\n",
      "Epoch: 3/100... Training loss: 0.1258\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1343\n",
      "Epoch: 3/100... Training loss: 0.1305\n",
      "Epoch: 3/100... Training loss: 0.1314\n",
      "Epoch: 3/100... Training loss: 0.1309\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1294\n",
      "Epoch: 3/100... Training loss: 0.1263\n",
      "Epoch: 3/100... Training loss: 0.1323\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1325\n",
      "Epoch: 3/100... Training loss: 0.1319\n",
      "Epoch: 3/100... Training loss: 0.1306\n",
      "Epoch: 3/100... Training loss: 0.1286\n",
      "Epoch: 3/100... Training loss: 0.1306\n",
      "Epoch: 3/100... Training loss: 0.1356\n",
      "Epoch: 3/100... Training loss: 0.1312\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1258\n",
      "Epoch: 3/100... Training loss: 0.1320\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1276\n",
      "Epoch: 3/100... Training loss: 0.1323\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1346\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1380\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1310\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1258\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1327\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1257\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1241\n",
      "Epoch: 4/100... Training loss: 0.1272\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1258\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1313\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1286\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1360\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1378\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1284\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1301\n",
      "Epoch: 4/100... Training loss: 0.1257\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1242\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1284\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1252\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1286\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1249\n",
      "Epoch: 4/100... Training loss: 0.1286\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1255\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1266\n",
      "Epoch: 4/100... Training loss: 0.1269\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1284\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1262\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1252\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1246\n",
      "Epoch: 4/100... Training loss: 0.1272\n",
      "Epoch: 4/100... Training loss: 0.1232\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1207\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1259\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1233\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1246\n",
      "Epoch: 4/100... Training loss: 0.1221\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1263\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1240\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1260\n",
      "Epoch: 4/100... Training loss: 0.1233\n",
      "Epoch: 4/100... Training loss: 0.1286\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1242\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1269\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1225\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1228\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1253\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1252\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1267\n",
      "Epoch: 4/100... Training loss: 0.1253\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1272\n",
      "Epoch: 4/100... Training loss: 0.1225\n",
      "Epoch: 4/100... Training loss: 0.1272\n",
      "Epoch: 4/100... Training loss: 0.1216\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1260\n",
      "Epoch: 4/100... Training loss: 0.1266\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1233\n",
      "Epoch: 4/100... Training loss: 0.1238\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1267\n",
      "Epoch: 4/100... Training loss: 0.1260\n",
      "Epoch: 4/100... Training loss: 0.1260\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1269\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1230\n",
      "Epoch: 4/100... Training loss: 0.1255\n",
      "Epoch: 4/100... Training loss: 0.1263\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1259\n",
      "Epoch: 4/100... Training loss: 0.1230\n",
      "Epoch: 4/100... Training loss: 0.1216\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1207\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1269\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1231\n",
      "Epoch: 4/100... Training loss: 0.1233\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1245\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1269\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1216\n",
      "Epoch: 4/100... Training loss: 0.1229\n",
      "Epoch: 4/100... Training loss: 0.1252\n",
      "Epoch: 4/100... Training loss: 0.1235\n",
      "Epoch: 4/100... Training loss: 0.1239\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1255\n",
      "Epoch: 4/100... Training loss: 0.1240\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1246\n",
      "Epoch: 4/100... Training loss: 0.1248\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1243\n",
      "Epoch: 4/100... Training loss: 0.1268\n",
      "Epoch: 4/100... Training loss: 0.1205\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1220\n",
      "Epoch: 4/100... Training loss: 0.1258\n",
      "Epoch: 4/100... Training loss: 0.1215\n",
      "Epoch: 4/100... Training loss: 0.1223\n",
      "Epoch: 4/100... Training loss: 0.1253\n",
      "Epoch: 4/100... Training loss: 0.1256\n",
      "Epoch: 4/100... Training loss: 0.1250\n",
      "Epoch: 4/100... Training loss: 0.1239\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1238\n",
      "Epoch: 4/100... Training loss: 0.1263\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1229\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1220\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1321\n",
      "Epoch: 5/100... Training loss: 0.1202\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1261\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1230\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1205\n",
      "Epoch: 5/100... Training loss: 0.1211\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1270\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1201\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1202\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1200\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1211\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1211\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1229\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1207\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1222\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1270\n",
      "Epoch: 5/100... Training loss: 0.1190\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1212\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1274\n",
      "Epoch: 5/100... Training loss: 0.1177\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1222\n",
      "Epoch: 5/100... Training loss: 0.1220\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1218\n",
      "Epoch: 5/100... Training loss: 0.1261\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1208\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1289\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1274\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1188\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1208\n",
      "Epoch: 5/100... Training loss: 0.1204\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1179\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1230\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1188\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1194\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1214\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1193\n",
      "Epoch: 5/100... Training loss: 0.1185\n",
      "Epoch: 5/100... Training loss: 0.1187\n",
      "Epoch: 5/100... Training loss: 0.1222\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1195\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1212\n",
      "Epoch: 5/100... Training loss: 0.1230\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1190\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1183\n",
      "Epoch: 5/100... Training loss: 0.1203\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1193\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1218\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1206\n",
      "Epoch: 5/100... Training loss: 0.1204\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1218\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1214\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1205\n",
      "Epoch: 5/100... Training loss: 0.1207\n",
      "Epoch: 5/100... Training loss: 0.1189\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1209\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1200\n",
      "Epoch: 5/100... Training loss: 0.1223\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1274\n",
      "Epoch: 5/100... Training loss: 0.1196\n",
      "Epoch: 5/100... Training loss: 0.1162\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1218\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1207\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1208\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1195\n",
      "Epoch: 5/100... Training loss: 0.1270\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1226\n",
      "Epoch: 5/100... Training loss: 0.1214\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1208\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1230\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1218\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1178\n",
      "Epoch: 5/100... Training loss: 0.1208\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1195\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1191\n",
      "Epoch: 5/100... Training loss: 0.1199\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1199\n",
      "Epoch: 5/100... Training loss: 0.1203\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1202\n",
      "Epoch: 5/100... Training loss: 0.1207\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1162\n",
      "Epoch: 5/100... Training loss: 0.1206\n",
      "Epoch: 5/100... Training loss: 0.1205\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1201\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1209\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1229\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1210\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1178\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1203\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1193\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1189\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1167\n",
      "Epoch: 6/100... Training loss: 0.1168\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1167\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1173\n",
      "Epoch: 6/100... Training loss: 0.1177\n",
      "Epoch: 6/100... Training loss: 0.1171\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1203\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1162\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1189\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1193\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1164\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1156\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1178\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1166\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1190\n",
      "Epoch: 6/100... Training loss: 0.1174\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1166\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1162\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1144\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1173\n",
      "Epoch: 6/100... Training loss: 0.1157\n",
      "Epoch: 6/100... Training loss: 0.1180\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1190\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1170\n",
      "Epoch: 6/100... Training loss: 0.1189\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1177\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1163\n",
      "Epoch: 6/100... Training loss: 0.1149\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1152\n",
      "Epoch: 6/100... Training loss: 0.1194\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1189\n",
      "Epoch: 6/100... Training loss: 0.1178\n",
      "Epoch: 6/100... Training loss: 0.1190\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1155\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1145\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1171\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1172\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1189\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1182\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1173\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1164\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1190\n",
      "Epoch: 6/100... Training loss: 0.1168\n",
      "Epoch: 6/100... Training loss: 0.1193\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1154\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1170\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1179\n",
      "Epoch: 6/100... Training loss: 0.1159\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1178\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1167\n",
      "Epoch: 6/100... Training loss: 0.1177\n",
      "Epoch: 6/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1189\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1177\n",
      "Epoch: 6/100... Training loss: 0.1160\n",
      "Epoch: 6/100... Training loss: 0.1144\n",
      "Epoch: 6/100... Training loss: 0.1171\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1143\n",
      "Epoch: 6/100... Training loss: 0.1174\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1172\n",
      "Epoch: 6/100... Training loss: 0.1179\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1173\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1184\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1177\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1160\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1171\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1194\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1160\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1236\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1138\n",
      "Epoch: 7/100... Training loss: 0.1218\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1161\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1178\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1134\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1144\n",
      "Epoch: 7/100... Training loss: 0.1146\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1170\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1134\n",
      "Epoch: 7/100... Training loss: 0.1151\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1128\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1149\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1157\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1135\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1137\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1160\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1150\n",
      "Epoch: 7/100... Training loss: 0.1147\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1153\n",
      "Epoch: 7/100... Training loss: 0.1170\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1136\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1167\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1162\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1167\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1159\n",
      "Epoch: 7/100... Training loss: 0.1151\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1148\n",
      "Epoch: 7/100... Training loss: 0.1151\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1152\n",
      "Epoch: 7/100... Training loss: 0.1146\n",
      "Epoch: 7/100... Training loss: 0.1161\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1148\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1156\n",
      "Epoch: 7/100... Training loss: 0.1156\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1143\n",
      "Epoch: 7/100... Training loss: 0.1138\n",
      "Epoch: 7/100... Training loss: 0.1162\n",
      "Epoch: 7/100... Training loss: 0.1147\n",
      "Epoch: 7/100... Training loss: 0.1156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1157\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1137\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1167\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1157\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1141\n",
      "Epoch: 7/100... Training loss: 0.1152\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1149\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1167\n",
      "Epoch: 7/100... Training loss: 0.1154\n",
      "Epoch: 7/100... Training loss: 0.1160\n",
      "Epoch: 7/100... Training loss: 0.1178\n",
      "Epoch: 7/100... Training loss: 0.1154\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1138\n",
      "Epoch: 7/100... Training loss: 0.1156\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1151\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1144\n",
      "Epoch: 7/100... Training loss: 0.1134\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1126\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1153\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1134\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1096\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1148\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1147\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1170\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1149\n",
      "Epoch: 7/100... Training loss: 0.1149\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1159\n",
      "Epoch: 7/100... Training loss: 0.1157\n",
      "Epoch: 7/100... Training loss: 0.1151\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1151\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1129\n",
      "Epoch: 7/100... Training loss: 0.1145\n",
      "Epoch: 7/100... Training loss: 0.1144\n",
      "Epoch: 7/100... Training loss: 0.1112\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1129\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1121\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1145\n",
      "Epoch: 7/100... Training loss: 0.1160\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1103\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1118\n",
      "Epoch: 7/100... Training loss: 0.1151\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1178\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1133\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1178\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1160\n",
      "Epoch: 7/100... Training loss: 0.1155\n",
      "Epoch: 7/100... Training loss: 0.1160\n",
      "Epoch: 7/100... Training loss: 0.1170\n",
      "Epoch: 7/100... Training loss: 0.1152\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1136\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1155\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1167\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1159\n",
      "Epoch: 7/100... Training loss: 0.1146\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1150\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1128\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1137\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1132\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1231\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1121\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1182\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1124\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1123\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1135\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1130\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1119\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1141\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1134\n",
      "Epoch: 8/100... Training loss: 0.1123\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1127\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1137\n",
      "Epoch: 8/100... Training loss: 0.1109\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1130\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1141\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1129\n",
      "Epoch: 8/100... Training loss: 0.1126\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1121\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1132\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1125\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1126\n",
      "Epoch: 8/100... Training loss: 0.1127\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1124\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1121\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1102\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1120\n",
      "Epoch: 8/100... Training loss: 0.1123\n",
      "Epoch: 8/100... Training loss: 0.1102\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1144\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1130\n",
      "Epoch: 8/100... Training loss: 0.1115\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1130\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1126\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1126\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1085\n",
      "Epoch: 8/100... Training loss: 0.1144\n",
      "Epoch: 8/100... Training loss: 0.1088\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1121\n",
      "Epoch: 8/100... Training loss: 0.1125\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1130\n",
      "Epoch: 8/100... Training loss: 0.1128\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1127\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1114\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1120\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1137\n",
      "Epoch: 8/100... Training loss: 0.1105\n",
      "Epoch: 8/100... Training loss: 0.1118\n",
      "Epoch: 8/100... Training loss: 0.1137\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1127\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1115\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1122\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1126\n",
      "Epoch: 8/100... Training loss: 0.1126\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1114\n",
      "Epoch: 8/100... Training loss: 0.1100\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1139\n",
      "Epoch: 8/100... Training loss: 0.1130\n",
      "Epoch: 8/100... Training loss: 0.1134\n",
      "Epoch: 8/100... Training loss: 0.1137\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1124\n",
      "Epoch: 8/100... Training loss: 0.1098\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1142\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1130\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1139\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1104\n",
      "Epoch: 8/100... Training loss: 0.1133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1124\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1128\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1130\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1137\n",
      "Epoch: 8/100... Training loss: 0.1119\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1112\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1103\n",
      "Epoch: 9/100... Training loss: 0.1121\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1108\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1103\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1123\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1083\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1125\n",
      "Epoch: 9/100... Training loss: 0.1107\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1107\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1122\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1107\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1120\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1122\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1134\n",
      "Epoch: 9/100... Training loss: 0.1130\n",
      "Epoch: 9/100... Training loss: 0.1095\n",
      "Epoch: 9/100... Training loss: 0.1100\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1103\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1122\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 9/100... Training loss: 0.1134\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1112\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1073\n",
      "Epoch: 9/100... Training loss: 0.1092\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1080\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1109\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1098\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1089\n",
      "Epoch: 9/100... Training loss: 0.1109\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1098\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1123\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1121\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1119\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1109\n",
      "Epoch: 9/100... Training loss: 0.1115\n",
      "Epoch: 9/100... Training loss: 0.1092\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1108\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1105\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1113\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1193\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1087\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1115\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1112\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1102\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1112\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1134\n",
      "Epoch: 9/100... Training loss: 0.1115\n",
      "Epoch: 9/100... Training loss: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1116\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1098\n",
      "Epoch: 9/100... Training loss: 0.1110\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1120\n",
      "Epoch: 9/100... Training loss: 0.1088\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1078\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1109\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1111\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1130\n",
      "Epoch: 9/100... Training loss: 0.1130\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1092\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1117\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1108\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1114\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1120\n",
      "Epoch: 9/100... Training loss: 0.1104\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1115\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1089\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1117\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1117\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1105\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1110\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1087\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1103\n",
      "Epoch: 9/100... Training loss: 0.1115\n",
      "Epoch: 9/100... Training loss: 0.1124\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1126\n",
      "Epoch: 9/100... Training loss: 0.1094\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1125\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1093\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1099\n",
      "Epoch: 9/100... Training loss: 0.1125\n",
      "Epoch: 9/100... Training loss: 0.1080\n",
      "Epoch: 9/100... Training loss: 0.1113\n",
      "Epoch: 9/100... Training loss: 0.1118\n",
      "Epoch: 9/100... Training loss: 0.1076\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1114\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1097\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1089\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1107\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1114\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1065\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1114\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1104\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1114\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1084\n",
      "Epoch: 10/100... Training loss: 0.1094\n",
      "Epoch: 10/100... Training loss: 0.1114\n",
      "Epoch: 10/100... Training loss: 0.1105\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1113\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1083\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1085\n",
      "Epoch: 10/100... Training loss: 0.1130\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1108\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1068\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1097\n",
      "Epoch: 10/100... Training loss: 0.1101\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1088\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1172\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1078\n",
      "Epoch: 10/100... Training loss: 0.1107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100... Training loss: 0.1097\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1071\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1109\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1095\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1098\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1084\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1070\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1088\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1081\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1089\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1109\n",
      "Epoch: 10/100... Training loss: 0.1107\n",
      "Epoch: 10/100... Training loss: 0.1100\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1107\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1088\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1082\n",
      "Epoch: 10/100... Training loss: 0.1091\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1097\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1096\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1114\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1096\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1109\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1099\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1081\n",
      "Epoch: 10/100... Training loss: 0.1107\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1100\n",
      "Epoch: 10/100... Training loss: 0.1107\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1066\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1095\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1104\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1091\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1084\n",
      "Epoch: 10/100... Training loss: 0.1101\n",
      "Epoch: 10/100... Training loss: 0.1097\n",
      "Epoch: 10/100... Training loss: 0.1100\n",
      "Epoch: 10/100... Training loss: 0.1114\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1108\n",
      "Epoch: 10/100... Training loss: 0.1107\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1109\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1088\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1081\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1100\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1117\n",
      "Epoch: 10/100... Training loss: 0.1096\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1091\n",
      "Epoch: 10/100... Training loss: 0.1098\n",
      "Epoch: 10/100... Training loss: 0.1082\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1091\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1104\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1130\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1100\n",
      "Epoch: 10/100... Training loss: 0.1087\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1113\n",
      "Epoch: 10/100... Training loss: 0.1095\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1097\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1095\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1084\n",
      "Epoch: 11/100... Training loss: 0.1097\n",
      "Epoch: 11/100... Training loss: 0.1095\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1089\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1093\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1087\n",
      "Epoch: 11/100... Training loss: 0.1083\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1077\n",
      "Epoch: 11/100... Training loss: 0.1103\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1089\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1088\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1084\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1176\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1094\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1086\n",
      "Epoch: 11/100... Training loss: 0.1056\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1084\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1100\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1079\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1103\n",
      "Epoch: 11/100... Training loss: 0.1086\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1097\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1068\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1077\n",
      "Epoch: 11/100... Training loss: 0.1085\n",
      "Epoch: 11/100... Training loss: 0.1083\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1079\n",
      "Epoch: 11/100... Training loss: 0.1062\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1066\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1083\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1086\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1076\n",
      "Epoch: 11/100... Training loss: 0.1074\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1092\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1085\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1095\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1092\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1076\n",
      "Epoch: 11/100... Training loss: 0.1100\n",
      "Epoch: 11/100... Training loss: 0.1091\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1077\n",
      "Epoch: 11/100... Training loss: 0.1074\n",
      "Epoch: 11/100... Training loss: 0.1083\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1083\n",
      "Epoch: 11/100... Training loss: 0.1089\n",
      "Epoch: 11/100... Training loss: 0.1071\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1073\n",
      "Epoch: 11/100... Training loss: 0.1027\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1103\n",
      "Epoch: 11/100... Training loss: 0.1089\n",
      "Epoch: 11/100... Training loss: 0.1083\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1052\n",
      "Epoch: 11/100... Training loss: 0.1085\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1092\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1079\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1067\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1095\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1090\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1073\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1082\n",
      "Epoch: 11/100... Training loss: 0.1093\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1112\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1089\n",
      "Epoch: 11/100... Training loss: 0.1093\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1069\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1056\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1085\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1094\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1090\n",
      "Epoch: 11/100... Training loss: 0.1066\n",
      "Epoch: 11/100... Training loss: 0.1085\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1092\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1072\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1103\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1088\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1076\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1070\n",
      "Epoch: 11/100... Training loss: 0.1077\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1078\n",
      "Epoch: 11/100... Training loss: 0.1095\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1092\n",
      "Epoch: 11/100... Training loss: 0.1093\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1070\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1090\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1072\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1082\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1056\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1070\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1080\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1065\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1090\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1081\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1076\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1066\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1078\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1078\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1080\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1090\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1085\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1158\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1087\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1078\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1091\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1079\n",
      "Epoch: 12/100... Training loss: 0.1059\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1080\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1087\n",
      "Epoch: 12/100... Training loss: 0.1079\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1071\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1078\n",
      "Epoch: 12/100... Training loss: 0.1073\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1077\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1075\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1071\n",
      "Epoch: 12/100... Training loss: 0.1102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100... Training loss: 0.1083\n",
      "Epoch: 12/100... Training loss: 0.1074\n",
      "Epoch: 12/100... Training loss: 0.1083\n",
      "Epoch: 12/100... Training loss: 0.1069\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1085\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1082\n",
      "Epoch: 12/100... Training loss: 0.1075\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1096\n",
      "Epoch: 12/100... Training loss: 0.1087\n",
      "Epoch: 12/100... Training loss: 0.1066\n",
      "Epoch: 12/100... Training loss: 0.1079\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1079\n",
      "Epoch: 12/100... Training loss: 0.1073\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1071\n",
      "Epoch: 12/100... Training loss: 0.1078\n",
      "Epoch: 12/100... Training loss: 0.1091\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1064\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1078\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1082\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1085\n",
      "Epoch: 12/100... Training loss: 0.1066\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1058\n",
      "Epoch: 12/100... Training loss: 0.1085\n",
      "Epoch: 12/100... Training loss: 0.1075\n",
      "Epoch: 12/100... Training loss: 0.1090\n",
      "Epoch: 12/100... Training loss: 0.1061\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1065\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1155\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1096\n",
      "Epoch: 12/100... Training loss: 0.1083\n",
      "Epoch: 12/100... Training loss: 0.1087\n",
      "Epoch: 12/100... Training loss: 0.1065\n",
      "Epoch: 12/100... Training loss: 0.1096\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1068\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1086\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1070\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1092\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1087\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1078\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1081\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1147\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1081\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1082\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1080\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1072\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1090\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1156\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1070\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1090\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1080\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1066\n",
      "Epoch: 12/100... Training loss: 0.1077\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1070\n",
      "Epoch: 12/100... Training loss: 0.1083\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1077\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1085\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1070\n",
      "Epoch: 12/100... Training loss: 0.1056\n",
      "Epoch: 12/100... Training loss: 0.1055\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1080\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1078\n",
      "Epoch: 13/100... Training loss: 0.1066\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1059\n",
      "Epoch: 13/100... Training loss: 0.1065\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1059\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1061\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1060\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1078\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1151\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1072\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1080\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1134\n",
      "Epoch: 13/100... Training loss: 0.1136\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1106\n",
      "Epoch: 13/100... Training loss: 0.1072\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100... Training loss: 0.1078\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1063\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1060\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1064\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1075\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1065\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1066\n",
      "Epoch: 13/100... Training loss: 0.1054\n",
      "Epoch: 13/100... Training loss: 0.1054\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1064\n",
      "Epoch: 13/100... Training loss: 0.1069\n",
      "Epoch: 13/100... Training loss: 0.1075\n",
      "Epoch: 13/100... Training loss: 0.1049\n",
      "Epoch: 13/100... Training loss: 0.1071\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1067\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1051\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1074\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1070\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1067\n",
      "Epoch: 13/100... Training loss: 0.1070\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1070\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1073\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1071\n",
      "Epoch: 13/100... Training loss: 0.1075\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1078\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1068\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1077\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1082\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1080\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1081\n",
      "Epoch: 13/100... Training loss: 0.1068\n",
      "Epoch: 13/100... Training loss: 0.1066\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1060\n",
      "Epoch: 13/100... Training loss: 0.1054\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1048\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1063\n",
      "Epoch: 13/100... Training loss: 0.1045\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1075\n",
      "Epoch: 13/100... Training loss: 0.1057\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1056\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1063\n",
      "Epoch: 13/100... Training loss: 0.1075\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1064\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1053\n",
      "Epoch: 13/100... Training loss: 0.1053\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1059\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1073\n",
      "Epoch: 13/100... Training loss: 0.1064\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1070\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1060\n",
      "Epoch: 13/100... Training loss: 0.1065\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1062\n",
      "Epoch: 13/100... Training loss: 0.1081\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1096\n",
      "Epoch: 13/100... Training loss: 0.1079\n",
      "Epoch: 13/100... Training loss: 0.1051\n",
      "Epoch: 13/100... Training loss: 0.1077\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1075\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1065\n",
      "Epoch: 13/100... Training loss: 0.1078\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1106\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1055\n",
      "Epoch: 13/100... Training loss: 0.1073\n",
      "Epoch: 13/100... Training loss: 0.1065\n",
      "Epoch: 13/100... Training loss: 0.1066\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1077\n",
      "Epoch: 13/100... Training loss: 0.1053\n",
      "Epoch: 13/100... Training loss: 0.1076\n",
      "Epoch: 13/100... Training loss: 0.1119\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1066\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1064\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1069\n",
      "Epoch: 13/100... Training loss: 0.1067\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1066\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1066\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1065\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1150\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1142\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1121\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1060\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1166\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1065\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1066\n",
      "Epoch: 14/100... Training loss: 0.1072\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1054\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1061\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1073\n",
      "Epoch: 14/100... Training loss: 0.1067\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1050\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1059\n",
      "Epoch: 14/100... Training loss: 0.1142\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1033\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1051\n",
      "Epoch: 14/100... Training loss: 0.1059\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1063\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1052\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1072\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1035\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1067\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1072\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1073\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1067\n",
      "Epoch: 14/100... Training loss: 0.1111\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1057\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1048\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1068\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1038\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1061\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1048\n",
      "Epoch: 14/100... Training loss: 0.1074\n",
      "Epoch: 14/100... Training loss: 0.1070\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1064\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1060\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1065\n",
      "Epoch: 14/100... Training loss: 0.1078\n",
      "Epoch: 14/100... Training loss: 0.1134\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1066\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1069\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1059\n",
      "Epoch: 14/100... Training loss: 0.1062\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1065\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1064\n",
      "Epoch: 14/100... Training loss: 0.1057\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1065\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1046\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1069\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1066\n",
      "Epoch: 14/100... Training loss: 0.1068\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1048\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1069\n",
      "Epoch: 14/100... Training loss: 0.1068\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1065\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1070\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1048\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1078\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1078\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1067\n",
      "Epoch: 14/100... Training loss: 0.1058\n",
      "Epoch: 14/100... Training loss: 0.1069\n",
      "Epoch: 14/100... Training loss: 0.1067\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1067\n",
      "Epoch: 14/100... Training loss: 0.1057\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1074\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1059\n",
      "Epoch: 14/100... Training loss: 0.1064\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1045\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1043\n",
      "Epoch: 14/100... Training loss: 0.1063\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1074\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1053\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1059\n",
      "Epoch: 14/100... Training loss: 0.1056\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1085\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1072\n",
      "Epoch: 14/100... Training loss: 0.1078\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1039\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1078\n",
      "Epoch: 14/100... Training loss: 0.1153\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1078\n",
      "Epoch: 14/100... Training loss: 0.1057\n",
      "Epoch: 14/100... Training loss: 0.1063\n",
      "Epoch: 14/100... Training loss: 0.1072\n",
      "Epoch: 14/100... Training loss: 0.1063\n",
      "Epoch: 14/100... Training loss: 0.1014\n",
      "Epoch: 14/100... Training loss: 0.1034\n",
      "Epoch: 14/100... Training loss: 0.1050\n",
      "Epoch: 14/100... Training loss: 0.1058\n",
      "Epoch: 14/100... Training loss: 0.1054\n",
      "Epoch: 14/100... Training loss: 0.1059\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1046\n",
      "Epoch: 14/100... Training loss: 0.1040\n",
      "Epoch: 14/100... Training loss: 0.1032\n",
      "Epoch: 14/100... Training loss: 0.1069\n",
      "Epoch: 14/100... Training loss: 0.1064\n",
      "Epoch: 14/100... Training loss: 0.1056\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1039\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1043\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1054\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1057\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1041\n",
      "Epoch: 15/100... Training loss: 0.1062\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1062\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1063\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1067\n",
      "Epoch: 15/100... Training loss: 0.1061\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1065\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1032\n",
      "Epoch: 15/100... Training loss: 0.1054\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1034\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1052\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1048\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1063\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1036\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1063\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1041\n",
      "Epoch: 15/100... Training loss: 0.1055\n",
      "Epoch: 15/100... Training loss: 0.1040\n",
      "Epoch: 15/100... Training loss: 0.1029\n",
      "Epoch: 15/100... Training loss: 0.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100... Training loss: 0.1067\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1044\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1071\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1059\n",
      "Epoch: 15/100... Training loss: 0.1059\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1029\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1052\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1051\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1140\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1060\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1057\n",
      "Epoch: 15/100... Training loss: 0.1043\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1047\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1065\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1063\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1032\n",
      "Epoch: 15/100... Training loss: 0.1057\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1059\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1043\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1052\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1035\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1071\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1059\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1058\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1046\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1050\n",
      "Epoch: 15/100... Training loss: 0.1061\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1062\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1061\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1061\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1030\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1035\n",
      "Epoch: 15/100... Training loss: 0.1058\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1065\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1030\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1062\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1059\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1055\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1045\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1047\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1063\n",
      "Epoch: 15/100... Training loss: 0.1039\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1047\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1063\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1071\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1062\n",
      "Epoch: 15/100... Training loss: 0.1071\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1048\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1063\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1071\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1046\n",
      "Epoch: 15/100... Training loss: 0.1045\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1052\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1062\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1042\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1034\n",
      "Epoch: 15/100... Training loss: 0.1046\n",
      "Epoch: 15/100... Training loss: 0.1052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1063\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1045\n",
      "Epoch: 15/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1054\n",
      "Epoch: 16/100... Training loss: 0.1051\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1049\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1054\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1009\n",
      "Epoch: 16/100... Training loss: 0.1127\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1048\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1063\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1047\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1057\n",
      "Epoch: 16/100... Training loss: 0.1053\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1038\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1056\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1058\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1047\n",
      "Epoch: 16/100... Training loss: 0.1048\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1043\n",
      "Epoch: 16/100... Training loss: 0.1056\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1057\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1051\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1041\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1049\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1032\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1025\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1040\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1045\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1053\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1048\n",
      "Epoch: 16/100... Training loss: 0.1065\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1047\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1056\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1055\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1053\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1039\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1042\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1063\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1058\n",
      "Epoch: 16/100... Training loss: 0.1047\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1045\n",
      "Epoch: 16/100... Training loss: 0.1054\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1053\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1048\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1052\n",
      "Epoch: 16/100... Training loss: 0.1045\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1055\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1062\n",
      "Epoch: 16/100... Training loss: 0.1030\n",
      "Epoch: 16/100... Training loss: 0.1109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100... Training loss: 0.1030\n",
      "Epoch: 16/100... Training loss: 0.1048\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1048\n",
      "Epoch: 16/100... Training loss: 0.1043\n",
      "Epoch: 16/100... Training loss: 0.1054\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1071\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1055\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1053\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1026\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1051\n",
      "Epoch: 16/100... Training loss: 0.1056\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1071\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1030\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1042\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1034\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1058\n",
      "Epoch: 16/100... Training loss: 0.1038\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1028\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1049\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1043\n",
      "Epoch: 16/100... Training loss: 0.1071\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1009\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1052\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1055\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1047\n",
      "Epoch: 16/100... Training loss: 0.1032\n",
      "Epoch: 16/100... Training loss: 0.1032\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1058\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1044\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1063\n",
      "Epoch: 16/100... Training loss: 0.1049\n",
      "Epoch: 16/100... Training loss: 0.1062\n",
      "Epoch: 16/100... Training loss: 0.1056\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1025\n",
      "Epoch: 17/100... Training loss: 0.1051\n",
      "Epoch: 17/100... Training loss: 0.1065\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1047\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1037\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1023\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1029\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1035\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1029\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1043\n",
      "Epoch: 17/100... Training loss: 0.1061\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1051\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1048\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1047\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1057\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1033\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1017\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1043\n",
      "Epoch: 17/100... Training loss: 0.1032\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1052\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1048\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1021\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1045\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1045\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1051\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1051\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1054\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1025\n",
      "Epoch: 17/100... Training loss: 0.1065\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1045\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1026\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1035\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1123\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1056\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1065\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1047\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1037\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1052\n",
      "Epoch: 17/100... Training loss: 0.1051\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1043\n",
      "Epoch: 17/100... Training loss: 0.1057\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1086\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1052\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1045\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1020\n",
      "Epoch: 17/100... Training loss: 0.1054\n",
      "Epoch: 17/100... Training loss: 0.1037\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1054\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1056\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1053\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1053\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1037\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1025\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1048\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1029\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1039\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1047\n",
      "Epoch: 17/100... Training loss: 0.1048\n",
      "Epoch: 17/100... Training loss: 0.1039\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1038\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1057\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1061\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1022\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1061\n",
      "Epoch: 17/100... Training loss: 0.1043\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1048\n",
      "Epoch: 17/100... Training loss: 0.1059\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1046\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1053\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1051\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1053\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1033\n",
      "Epoch: 17/100... Training loss: 0.1026\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1048\n",
      "Epoch: 17/100... Training loss: 0.1026\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1037\n",
      "Epoch: 17/100... Training loss: 0.1021\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1046\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1051\n",
      "Epoch: 17/100... Training loss: 0.1061\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1056\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1031\n",
      "Epoch: 17/100... Training loss: 0.1040\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1029\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1052\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1038\n",
      "Epoch: 18/100... Training loss: 0.1052\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1033\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1035\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1060\n",
      "Epoch: 18/100... Training loss: 0.1037\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1057\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1029\n",
      "Epoch: 18/100... Training loss: 0.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100... Training loss: 0.1039\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1032\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1033\n",
      "Epoch: 18/100... Training loss: 0.1034\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1052\n",
      "Epoch: 18/100... Training loss: 0.1038\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1042\n",
      "Epoch: 18/100... Training loss: 0.1052\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1051\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1042\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1030\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1025\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1049\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1054\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1047\n",
      "Epoch: 18/100... Training loss: 0.1030\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1049\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.0997\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1041\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1042\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1016\n",
      "Epoch: 18/100... Training loss: 0.1035\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1039\n",
      "Epoch: 18/100... Training loss: 0.1038\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1042\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1039\n",
      "Epoch: 18/100... Training loss: 0.1039\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1052\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1054\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1042\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1060\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1012\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1049\n",
      "Epoch: 18/100... Training loss: 0.1030\n",
      "Epoch: 18/100... Training loss: 0.1052\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1042\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1030\n",
      "Epoch: 18/100... Training loss: 0.1034\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1034\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1030\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1036\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1050\n",
      "Epoch: 18/100... Training loss: 0.1033\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1057\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1033\n",
      "Epoch: 18/100... Training loss: 0.1046\n",
      "Epoch: 18/100... Training loss: 0.1028\n",
      "Epoch: 18/100... Training loss: 0.1036\n",
      "Epoch: 18/100... Training loss: 0.1025\n",
      "Epoch: 18/100... Training loss: 0.1032\n",
      "Epoch: 18/100... Training loss: 0.1023\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1043\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1049\n",
      "Epoch: 18/100... Training loss: 0.1050\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1022\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1038\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1022\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1029\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1047\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1044\n",
      "Epoch: 18/100... Training loss: 0.1049\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1039\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1035\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1020\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1054\n",
      "Epoch: 18/100... Training loss: 0.1019\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1033\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1057\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1052\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1050\n",
      "Epoch: 18/100... Training loss: 0.1060\n",
      "Epoch: 18/100... Training loss: 0.1042\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1047\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1057\n",
      "Epoch: 18/100... Training loss: 0.1019\n",
      "Epoch: 18/100... Training loss: 0.1038\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1033\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1028\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1033\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1029\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1033\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1045\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1015\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1033\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1045\n",
      "Epoch: 19/100... Training loss: 0.1033\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1046\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1057\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1025\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1045\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1057\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1042\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1031\n",
      "Epoch: 19/100... Training loss: 0.1035\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1042\n",
      "Epoch: 19/100... Training loss: 0.1032\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1033\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1038\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1042\n",
      "Epoch: 19/100... Training loss: 0.1021\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1018\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1035\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1037\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1034\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1010\n",
      "Epoch: 19/100... Training loss: 0.1039\n",
      "Epoch: 19/100... Training loss: 0.1028\n",
      "Epoch: 19/100... Training loss: 0.1038\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1030\n",
      "Epoch: 19/100... Training loss: 0.1057\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1028\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1037\n",
      "Epoch: 19/100... Training loss: 0.1018\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1015\n",
      "Epoch: 19/100... Training loss: 0.1045\n",
      "Epoch: 19/100... Training loss: 0.1048\n",
      "Epoch: 19/100... Training loss: 0.1034\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1103\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1022\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 19/100... Training loss: 0.1038\n",
      "Epoch: 19/100... Training loss: 0.1046\n",
      "Epoch: 19/100... Training loss: 0.1040\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1021\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1017\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1057\n",
      "Epoch: 19/100... Training loss: 0.1045\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1033\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1057\n",
      "Epoch: 19/100... Training loss: 0.1040\n",
      "Epoch: 19/100... Training loss: 0.1043\n",
      "Epoch: 19/100... Training loss: 0.1045\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1029\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1034\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1014\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1046\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1039\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1037\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1030\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1026\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1057\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1039\n",
      "Epoch: 19/100... Training loss: 0.1039\n",
      "Epoch: 19/100... Training loss: 0.1029\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1029\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1018\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1036\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1018\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1028\n",
      "Epoch: 20/100... Training loss: 0.1013\n",
      "Epoch: 20/100... Training loss: 0.1038\n",
      "Epoch: 20/100... Training loss: 0.1031\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1037\n",
      "Epoch: 20/100... Training loss: 0.1035\n",
      "Epoch: 20/100... Training loss: 0.1037\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1122\n",
      "Epoch: 20/100... Training loss: 0.1099\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1027\n",
      "Epoch: 20/100... Training loss: 0.1039\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1022\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1112\n",
      "Epoch: 20/100... Training loss: 0.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1028\n",
      "Epoch: 20/100... Training loss: 0.1031\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1017\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1026\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1031\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1026\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1025\n",
      "Epoch: 20/100... Training loss: 0.1055\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1035\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1025\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1084\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1023\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1041\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1037\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1022\n",
      "Epoch: 20/100... Training loss: 0.1024\n",
      "Epoch: 20/100... Training loss: 0.1035\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1027\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1032\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1016\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1010\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1032\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1034\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1033\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1038\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1052\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1014\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1041\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1001\n",
      "Epoch: 20/100... Training loss: 0.1002\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1023\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1020\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1015\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1025\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1038\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1037\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1027\n",
      "Epoch: 20/100... Training loss: 0.1055\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1039\n",
      "Epoch: 20/100... Training loss: 0.1015\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1027\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1026\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1036\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1033\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1045\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1020\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1036\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1052\n",
      "Epoch: 20/100... Training loss: 0.1031\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1033\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1022\n",
      "Epoch: 20/100... Training loss: 0.1019\n",
      "Epoch: 20/100... Training loss: 0.1021\n",
      "Epoch: 20/100... Training loss: 0.1003\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1036\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1052\n",
      "Epoch: 20/100... Training loss: 0.1039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1033\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1028\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1035\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1020\n",
      "Epoch: 20/100... Training loss: 0.1035\n",
      "Epoch: 20/100... Training loss: 0.1034\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1033\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1035\n",
      "Epoch: 20/100... Training loss: 0.1047\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1040\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1001\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1030\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1027\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1027\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1018\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1027\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1018\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1018\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1099\n",
      "Epoch: 21/100... Training loss: 0.1023\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1025\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1014\n",
      "Epoch: 21/100... Training loss: 0.1035\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1039\n",
      "Epoch: 21/100... Training loss: 0.1027\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1034\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1040\n",
      "Epoch: 21/100... Training loss: 0.1011\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1040\n",
      "Epoch: 21/100... Training loss: 0.1027\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1039\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1038\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1036\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1030\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1039\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1017\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1026\n",
      "Epoch: 21/100... Training loss: 0.1036\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1027\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1040\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1030\n",
      "Epoch: 21/100... Training loss: 0.1018\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1020\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1028\n",
      "Epoch: 21/100... Training loss: 0.1013\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1030\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.0991\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1026\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1016\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1038\n",
      "Epoch: 21/100... Training loss: 0.1027\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1039\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1040\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1027\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1024\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1025\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1028\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1032\n",
      "Epoch: 21/100... Training loss: 0.1026\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1035\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1023\n",
      "Epoch: 21/100... Training loss: 0.1019\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1024\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1012\n",
      "Epoch: 21/100... Training loss: 0.1022\n",
      "Epoch: 21/100... Training loss: 0.1036\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1024\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.0959\n",
      "Epoch: 21/100... Training loss: 0.1031\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1124\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1036\n",
      "Epoch: 21/100... Training loss: 0.1025\n",
      "Epoch: 21/100... Training loss: 0.1072\n",
      "Epoch: 21/100... Training loss: 0.1025\n",
      "Epoch: 21/100... Training loss: 0.1023\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1035\n",
      "Epoch: 21/100... Training loss: 0.1040\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1029\n",
      "Epoch: 21/100... Training loss: 0.1028\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1030\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1028\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1017\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1033\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1020\n",
      "Epoch: 22/100... Training loss: 0.1017\n",
      "Epoch: 22/100... Training loss: 0.1019\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1043\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1029\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1021\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1019\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1043\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.0999\n",
      "Epoch: 22/100... Training loss: 0.1011\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1040\n",
      "Epoch: 22/100... Training loss: 0.1028\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1033\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1031\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1097\n",
      "Epoch: 22/100... Training loss: 0.1043\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1014\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1031\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1022\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1036\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1036\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1054\n",
      "Epoch: 22/100... Training loss: 0.1043\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1040\n",
      "Epoch: 22/100... Training loss: 0.1028\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1043\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1025\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1022\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1032\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1043\n",
      "Epoch: 22/100... Training loss: 0.1033\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1029\n",
      "Epoch: 22/100... Training loss: 0.1023\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.0999\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1037\n",
      "Epoch: 22/100... Training loss: 0.1055\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1033\n",
      "Epoch: 22/100... Training loss: 0.1040\n",
      "Epoch: 22/100... Training loss: 0.1029\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1055\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1008\n",
      "Epoch: 22/100... Training loss: 0.1022\n",
      "Epoch: 22/100... Training loss: 0.1019\n",
      "Epoch: 22/100... Training loss: 0.1054\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1007\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1020\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1014\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1015\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1040\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1013\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1033\n",
      "Epoch: 22/100... Training loss: 0.1000\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1016\n",
      "Epoch: 22/100... Training loss: 0.1025\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1032\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1055\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1020\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1031\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1043\n",
      "Epoch: 22/100... Training loss: 0.1033\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1029\n",
      "Epoch: 22/100... Training loss: 0.1015\n",
      "Epoch: 22/100... Training loss: 0.1029\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1005\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1055\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1016\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1013\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1017\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1032\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1021\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1002\n",
      "Epoch: 22/100... Training loss: 0.1031\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1006\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1031\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1032\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1014\n",
      "Epoch: 22/100... Training loss: 0.1012\n",
      "Epoch: 22/100... Training loss: 0.1036\n",
      "Epoch: 22/100... Training loss: 0.1024\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1021\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1019\n",
      "Epoch: 22/100... Training loss: 0.1054\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1014\n",
      "Epoch: 23/100... Training loss: 0.1037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1032\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1008\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1017\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1040\n",
      "Epoch: 23/100... Training loss: 0.1023\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1028\n",
      "Epoch: 23/100... Training loss: 0.1032\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1017\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1010\n",
      "Epoch: 23/100... Training loss: 0.0995\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1039\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1024\n",
      "Epoch: 23/100... Training loss: 0.1017\n",
      "Epoch: 23/100... Training loss: 0.1020\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1018\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1011\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1012\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1020\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1021\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1004\n",
      "Epoch: 23/100... Training loss: 0.1012\n",
      "Epoch: 23/100... Training loss: 0.1049\n",
      "Epoch: 23/100... Training loss: 0.1032\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1049\n",
      "Epoch: 23/100... Training loss: 0.1051\n",
      "Epoch: 23/100... Training loss: 0.1022\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1007\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1020\n",
      "Epoch: 23/100... Training loss: 0.1039\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1012\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1027\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1028\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1018\n",
      "Epoch: 23/100... Training loss: 0.1019\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1020\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1039\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1017\n",
      "Epoch: 23/100... Training loss: 0.1024\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1032\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1039\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1021\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1039\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1040\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1040\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1010\n",
      "Epoch: 23/100... Training loss: 0.0994\n",
      "Epoch: 23/100... Training loss: 0.1049\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1023\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1023\n",
      "Epoch: 23/100... Training loss: 0.1024\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1039\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1017\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1039\n",
      "Epoch: 23/100... Training loss: 0.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1022\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.0995\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1017\n",
      "Epoch: 23/100... Training loss: 0.1004\n",
      "Epoch: 23/100... Training loss: 0.1028\n",
      "Epoch: 23/100... Training loss: 0.1020\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1007\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1028\n",
      "Epoch: 23/100... Training loss: 0.1019\n",
      "Epoch: 23/100... Training loss: 0.1034\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1024\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1023\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1040\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1010\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1018\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1021\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1017\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1020\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1020\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.0999\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1019\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1023\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1001\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1023\n",
      "Epoch: 24/100... Training loss: 0.1022\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1015\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1006\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1015\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1012\n",
      "Epoch: 24/100... Training loss: 0.1012\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1003\n",
      "Epoch: 24/100... Training loss: 0.1026\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1010\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1024\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1006\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1023\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1028\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1013\n",
      "Epoch: 24/100... Training loss: 0.1022\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1020\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1026\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1028\n",
      "Epoch: 24/100... Training loss: 0.1001\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1019\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1012\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1025\n",
      "Epoch: 24/100... Training loss: 0.1013\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1014\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1014\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1085\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1018\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1016\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.0986\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1013\n",
      "Epoch: 24/100... Training loss: 0.0997\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.0981\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1020\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1004\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1026\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1023\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1023\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1023\n",
      "Epoch: 24/100... Training loss: 0.0995\n",
      "Epoch: 24/100... Training loss: 0.0993\n",
      "Epoch: 24/100... Training loss: 0.1028\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1016\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.0997\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1012\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1022\n",
      "Epoch: 24/100... Training loss: 0.1001\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1014\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1099\n",
      "Epoch: 24/100... Training loss: 0.1013\n",
      "Epoch: 24/100... Training loss: 0.1024\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1012\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1013\n",
      "Epoch: 24/100... Training loss: 0.1028\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1026\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1012\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1119\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.0984\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1083\n",
      "Epoch: 24/100... Training loss: 0.1014\n",
      "Epoch: 24/100... Training loss: 0.1030\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1027\n",
      "Epoch: 24/100... Training loss: 0.1019\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1021\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1018\n",
      "Epoch: 24/100... Training loss: 0.1019\n",
      "Epoch: 24/100... Training loss: 0.1007\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1017\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1019\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1016\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1021\n",
      "Epoch: 24/100... Training loss: 0.1085\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1028\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1004\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1019\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1100\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1000\n",
      "Epoch: 24/100... Training loss: 0.1026\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1010\n",
      "Epoch: 24/100... Training loss: 0.1027\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1028\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1016\n",
      "Epoch: 24/100... Training loss: 0.1028\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1026\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1022\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.0981\n",
      "Epoch: 25/100... Training loss: 0.1025\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1019\n",
      "Epoch: 25/100... Training loss: 0.1025\n",
      "Epoch: 25/100... Training loss: 0.1022\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1003\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1006\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1023\n",
      "Epoch: 25/100... Training loss: 0.1018\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1045\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1012\n",
      "Epoch: 25/100... Training loss: 0.1018\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1018\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1017\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1011\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1004\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1022\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1024\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1015\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1024\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1045\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1023\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1024\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1023\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1006\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1103\n",
      "Epoch: 25/100... Training loss: 0.1018\n",
      "Epoch: 25/100... Training loss: 0.0998\n",
      "Epoch: 25/100... Training loss: 0.1013\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1004\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1045\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.0992\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1007\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.0992\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1010\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1017\n",
      "Epoch: 25/100... Training loss: 0.1023\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1020\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1023\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.0984\n",
      "Epoch: 25/100... Training loss: 0.1024\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1004\n",
      "Epoch: 25/100... Training loss: 0.1026\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1015\n",
      "Epoch: 25/100... Training loss: 0.1019\n",
      "Epoch: 25/100... Training loss: 0.1008\n",
      "Epoch: 25/100... Training loss: 0.1003\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1016\n",
      "Epoch: 25/100... Training loss: 0.1008\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1015\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1016\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.0991\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1024\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1005\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1022\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.0988\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1025\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1010\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1025\n",
      "Epoch: 25/100... Training loss: 0.1008\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1012\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1016\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1045\n",
      "Epoch: 25/100... Training loss: 0.1036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100... Training loss: 0.1024\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1019\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1023\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1011\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1009\n",
      "Epoch: 25/100... Training loss: 0.1024\n",
      "Epoch: 25/100... Training loss: 0.0975\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1000\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1004\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1019\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1025\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.0977\n",
      "Epoch: 25/100... Training loss: 0.1009\n",
      "Epoch: 25/100... Training loss: 0.1026\n",
      "Epoch: 25/100... Training loss: 0.1019\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1002\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1020\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.0997\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1004\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1012\n",
      "Epoch: 26/100... Training loss: 0.1015\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1021\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1015\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1012\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1012\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1012\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1010\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1004\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.0997\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1019\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1019\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1010\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1004\n",
      "Epoch: 26/100... Training loss: 0.1021\n",
      "Epoch: 26/100... Training loss: 0.1020\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1014\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.0995\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1021\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1008\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1021\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1010\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1023\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1015\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.0992\n",
      "Epoch: 26/100... Training loss: 0.1019\n",
      "Epoch: 26/100... Training loss: 0.0991\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1013\n",
      "Epoch: 26/100... Training loss: 0.1014\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.0986\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1021\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1019\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1019\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1004\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1005\n",
      "Epoch: 26/100... Training loss: 0.0996\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1014\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1023\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.0995\n",
      "Epoch: 26/100... Training loss: 0.1004\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.0974\n",
      "Epoch: 26/100... Training loss: 0.1009\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1020\n",
      "Epoch: 26/100... Training loss: 0.1009\n",
      "Epoch: 26/100... Training loss: 0.1045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1017\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1015\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1004\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1013\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1019\n",
      "Epoch: 26/100... Training loss: 0.1016\n",
      "Epoch: 26/100... Training loss: 0.1009\n",
      "Epoch: 26/100... Training loss: 0.0961\n",
      "Epoch: 26/100... Training loss: 0.1014\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1023\n",
      "Epoch: 26/100... Training loss: 0.1016\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1020\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1009\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.0994\n",
      "Epoch: 26/100... Training loss: 0.1029\n",
      "Epoch: 26/100... Training loss: 0.1013\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1021\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1029\n",
      "Epoch: 26/100... Training loss: 0.1008\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1092\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1020\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.0998\n",
      "Epoch: 26/100... Training loss: 0.1021\n",
      "Epoch: 26/100... Training loss: 0.1012\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1013\n",
      "Epoch: 26/100... Training loss: 0.1020\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1016\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1021\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1084\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1012\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1009\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1008\n",
      "Epoch: 26/100... Training loss: 0.1000\n",
      "Epoch: 27/100... Training loss: 0.1007\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1018\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1010\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1003\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1016\n",
      "Epoch: 27/100... Training loss: 0.1013\n",
      "Epoch: 27/100... Training loss: 0.1001\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1015\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1007\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1009\n",
      "Epoch: 27/100... Training loss: 0.0978\n",
      "Epoch: 27/100... Training loss: 0.1005\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1015\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1025\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1018\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1009\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1006\n",
      "Epoch: 27/100... Training loss: 0.1007\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1025\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.0999\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100... Training loss: 0.1017\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1017\n",
      "Epoch: 27/100... Training loss: 0.1021\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1017\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1003\n",
      "Epoch: 27/100... Training loss: 0.1001\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1019\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.0984\n",
      "Epoch: 27/100... Training loss: 0.1021\n",
      "Epoch: 27/100... Training loss: 0.1016\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.0982\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1018\n",
      "Epoch: 27/100... Training loss: 0.1002\n",
      "Epoch: 27/100... Training loss: 0.1019\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1021\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.0991\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.0997\n",
      "Epoch: 27/100... Training loss: 0.1002\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1016\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1016\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1013\n",
      "Epoch: 27/100... Training loss: 0.1007\n",
      "Epoch: 27/100... Training loss: 0.1015\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1025\n",
      "Epoch: 27/100... Training loss: 0.1013\n",
      "Epoch: 27/100... Training loss: 0.1013\n",
      "Epoch: 27/100... Training loss: 0.1011\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1018\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1002\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1015\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1018\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1017\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1004\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1016\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1018\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1013\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1009\n",
      "Epoch: 27/100... Training loss: 0.0988\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1004\n",
      "Epoch: 27/100... Training loss: 0.1018\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1019\n",
      "Epoch: 27/100... Training loss: 0.1007\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1017\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1019\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.0988\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1013\n",
      "Epoch: 27/100... Training loss: 0.1011\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1070\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1009\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1006\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1011\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1015\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1016\n",
      "Epoch: 27/100... Training loss: 0.1003\n",
      "Epoch: 27/100... Training loss: 0.0999\n",
      "Epoch: 27/100... Training loss: 0.1016\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1015\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1018\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.0996\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.0994\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1007\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1011\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1025\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1015\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.0984\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1008\n",
      "Epoch: 28/100... Training loss: 0.1005\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1011\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1009\n",
      "Epoch: 28/100... Training loss: 0.0999\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1007\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1025\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1011\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.0990\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1013\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1005\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.0996\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1003\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1013\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1018\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1000\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.0988\n",
      "Epoch: 28/100... Training loss: 0.1025\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.0994\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.0984\n",
      "Epoch: 28/100... Training loss: 0.0983\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1014\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.0997\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1014\n",
      "Epoch: 28/100... Training loss: 0.1005\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1008\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1012\n",
      "Epoch: 28/100... Training loss: 0.0989\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1003\n",
      "Epoch: 28/100... Training loss: 0.1018\n",
      "Epoch: 28/100... Training loss: 0.1006\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.0983\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1025\n",
      "Epoch: 28/100... Training loss: 0.0996\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.0986\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.0994\n",
      "Epoch: 28/100... Training loss: 0.1011\n",
      "Epoch: 28/100... Training loss: 0.1015\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1005\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1014\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1014\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1001\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1008\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1006\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.0999\n",
      "Epoch: 28/100... Training loss: 0.1004\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1013\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1007\n",
      "Epoch: 28/100... Training loss: 0.0999\n",
      "Epoch: 28/100... Training loss: 0.1013\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1005\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1008\n",
      "Epoch: 28/100... Training loss: 0.1003\n",
      "Epoch: 28/100... Training loss: 0.1006\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.0998\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1004\n",
      "Epoch: 28/100... Training loss: 0.1029\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1005\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1017\n",
      "Epoch: 28/100... Training loss: 0.1018\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.0986\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1009\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1009\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1000\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.0998\n",
      "Epoch: 29/100... Training loss: 0.1020\n",
      "Epoch: 29/100... Training loss: 0.1017\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1013\n",
      "Epoch: 29/100... Training loss: 0.0986\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1017\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1010\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1002\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1010\n",
      "Epoch: 29/100... Training loss: 0.1016\n",
      "Epoch: 29/100... Training loss: 0.0986\n",
      "Epoch: 29/100... Training loss: 0.1017\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.0993\n",
      "Epoch: 29/100... Training loss: 0.1015\n",
      "Epoch: 29/100... Training loss: 0.0994\n",
      "Epoch: 29/100... Training loss: 0.1014\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1007\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.0991\n",
      "Epoch: 29/100... Training loss: 0.1008\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.0994\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1002\n",
      "Epoch: 29/100... Training loss: 0.1017\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1002\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.0996\n",
      "Epoch: 29/100... Training loss: 0.1001\n",
      "Epoch: 29/100... Training loss: 0.1015\n",
      "Epoch: 29/100... Training loss: 0.1061\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1015\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1005\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1008\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.0996\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1008\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1015\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1010\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.0986\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.0979\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.0987\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1017\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1004\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1013\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1006\n",
      "Epoch: 29/100... Training loss: 0.1004\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1013\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1020\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.0991\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1009\n",
      "Epoch: 29/100... Training loss: 0.0994\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1013\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1008\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1002\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1015\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1007\n",
      "Epoch: 29/100... Training loss: 0.1005\n",
      "Epoch: 29/100... Training loss: 0.0983\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.0996\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.0988\n",
      "Epoch: 29/100... Training loss: 0.1005\n",
      "Epoch: 29/100... Training loss: 0.1023\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.0997\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1002\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1004\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.0998\n",
      "Epoch: 29/100... Training loss: 0.1004\n",
      "Epoch: 29/100... Training loss: 0.1016\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1008\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1006\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1017\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1068\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1015\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1009\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1002\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1061\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1013\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1001\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1006\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.0989\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1008\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1013\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1013\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.0997\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.0991\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1017\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1006\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1016\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1009\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1001\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1010\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1068\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.0992\n",
      "Epoch: 29/100... Training loss: 0.1000\n",
      "Epoch: 29/100... Training loss: 0.0992\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1015\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1001\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1003\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1011\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1000\n",
      "Epoch: 30/100... Training loss: 0.1005\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1007\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1006\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.0990\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.0987\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.0983\n",
      "Epoch: 30/100... Training loss: 0.1076\n",
      "Epoch: 30/100... Training loss: 0.0998\n",
      "Epoch: 30/100... Training loss: 0.1004\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1010\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.0997\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1002\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1017\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1007\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1004\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1028\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1004\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1011\n",
      "Epoch: 30/100... Training loss: 0.1000\n",
      "Epoch: 30/100... Training loss: 0.0972\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1017\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.0997\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.0997\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1010\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.0958\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1005\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.0995\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1011\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.0998\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1005\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.0964\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.0981\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1076\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.0986\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1008\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1011\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1008\n",
      "Epoch: 30/100... Training loss: 0.0981\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1004\n",
      "Epoch: 30/100... Training loss: 0.1008\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1006\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.0989\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.0989\n",
      "Epoch: 30/100... Training loss: 0.1003\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1011\n",
      "Epoch: 30/100... Training loss: 0.1007\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.0994\n",
      "Epoch: 30/100... Training loss: 0.1063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1000\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1011\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.0998\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1011\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.0997\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.0988\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1005\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.0985\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1028\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1017\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1005\n",
      "Epoch: 30/100... Training loss: 0.0994\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1017\n",
      "Epoch: 30/100... Training loss: 0.1011\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1004\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1010\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1002\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.0993\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1007\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1093\n",
      "Epoch: 31/100... Training loss: 0.0998\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1006\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.1007\n",
      "Epoch: 31/100... Training loss: 0.0988\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1005\n",
      "Epoch: 31/100... Training loss: 0.0993\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.0987\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.0997\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1017\n",
      "Epoch: 31/100... Training loss: 0.1017\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1003\n",
      "Epoch: 31/100... Training loss: 0.1015\n",
      "Epoch: 31/100... Training loss: 0.1006\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1003\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1004\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1008\n",
      "Epoch: 31/100... Training loss: 0.1004\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.0980\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.0989\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1074\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.0965\n",
      "Epoch: 31/100... Training loss: 0.1012\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.0988\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.0998\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.0998\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.0987\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1005\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.0988\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1006\n",
      "Epoch: 31/100... Training loss: 0.1005\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1002\n",
      "Epoch: 31/100... Training loss: 0.1005\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1015\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.0984\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1008\n",
      "Epoch: 31/100... Training loss: 0.1008\n",
      "Epoch: 31/100... Training loss: 0.1015\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.0989\n",
      "Epoch: 31/100... Training loss: 0.1006\n",
      "Epoch: 31/100... Training loss: 0.0994\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1015\n",
      "Epoch: 31/100... Training loss: 0.1000\n",
      "Epoch: 31/100... Training loss: 0.0993\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.0984\n",
      "Epoch: 31/100... Training loss: 0.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100... Training loss: 0.1015\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1015\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.0977\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.0990\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.0991\n",
      "Epoch: 31/100... Training loss: 0.1002\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.0995\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.0991\n",
      "Epoch: 31/100... Training loss: 0.0995\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.0999\n",
      "Epoch: 31/100... Training loss: 0.1007\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.0998\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1012\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1017\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.0985\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.0985\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1017\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.0990\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.0996\n",
      "Epoch: 31/100... Training loss: 0.0998\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.0995\n",
      "Epoch: 31/100... Training loss: 0.0985\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.0988\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.0999\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.0996\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1001\n",
      "Epoch: 31/100... Training loss: 0.0995\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1005\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1001\n",
      "Epoch: 31/100... Training loss: 0.1017\n",
      "Epoch: 31/100... Training loss: 0.1015\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1007\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.0987\n",
      "Epoch: 31/100... Training loss: 0.1017\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1006\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1000\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1005\n",
      "Epoch: 31/100... Training loss: 0.0981\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.0981\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1012\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.0996\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1003\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1002\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1001\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1004\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.0993\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.0991\n",
      "Epoch: 32/100... Training loss: 0.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1003\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.0991\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.0984\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.0993\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1010\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.0983\n",
      "Epoch: 32/100... Training loss: 0.1001\n",
      "Epoch: 32/100... Training loss: 0.0991\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1010\n",
      "Epoch: 32/100... Training loss: 0.0994\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1005\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1001\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.0985\n",
      "Epoch: 32/100... Training loss: 0.1005\n",
      "Epoch: 32/100... Training loss: 0.0995\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.0998\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.1007\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1005\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.0995\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1000\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1007\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.0988\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1010\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1000\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.0992\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.0981\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.0994\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.0990\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.0996\n",
      "Epoch: 32/100... Training loss: 0.1005\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.0990\n",
      "Epoch: 32/100... Training loss: 0.1004\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1001\n",
      "Epoch: 32/100... Training loss: 0.1001\n",
      "Epoch: 32/100... Training loss: 0.1005\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.0991\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.0999\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.1002\n",
      "Epoch: 32/100... Training loss: 0.0999\n",
      "Epoch: 32/100... Training loss: 0.0984\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.0993\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1005\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1000\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.0988\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.0990\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.0997\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1053\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.0973\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.0977\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.0981\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.0984\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1006\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.0989\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.1000\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.0990\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.0984\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1005\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1003\n",
      "Epoch: 33/100... Training loss: 0.0983\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1079\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.0990\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.0993\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.0992\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1008\n",
      "Epoch: 33/100... Training loss: 0.0988\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1002\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1002\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.0995\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.0992\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1000\n",
      "Epoch: 33/100... Training loss: 0.1002\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.0991\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.0994\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1001\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1002\n",
      "Epoch: 33/100... Training loss: 0.1066\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.0997\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1000\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1003\n",
      "Epoch: 33/100... Training loss: 0.1001\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.0997\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.0992\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.0999\n",
      "Epoch: 33/100... Training loss: 0.0976\n",
      "Epoch: 33/100... Training loss: 0.0968\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1003\n",
      "Epoch: 33/100... Training loss: 0.0992\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.0955\n",
      "Epoch: 33/100... Training loss: 0.0995\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1008\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.0988\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.0992\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.0991\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1008\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.0990\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.0986\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1001\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1002\n",
      "Epoch: 33/100... Training loss: 0.1003\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.0997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100... Training loss: 0.1001\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1004\n",
      "Epoch: 33/100... Training loss: 0.1010\n",
      "Epoch: 33/100... Training loss: 0.0986\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1002\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1010\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.0999\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1003\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.0998\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1001\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.0998\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1083\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1000\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1002\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.0987\n",
      "Epoch: 33/100... Training loss: 0.1005\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1000\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.0979\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.0983\n",
      "Epoch: 33/100... Training loss: 0.0997\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.0979\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1004\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.0970\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1000\n",
      "Epoch: 33/100... Training loss: 0.0997\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.0993\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.0984\n",
      "Epoch: 33/100... Training loss: 0.0985\n",
      "Epoch: 33/100... Training loss: 0.0998\n",
      "Epoch: 33/100... Training loss: 0.1008\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1019\n",
      "Epoch: 33/100... Training loss: 0.0994\n",
      "Epoch: 33/100... Training loss: 0.1001\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1010\n",
      "Epoch: 33/100... Training loss: 0.1005\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1005\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.0992\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1010\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1008\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.0997\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1001\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.0995\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.0997\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.0995\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.0984\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.0981\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.0998\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.0990\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.0986\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.0990\n",
      "Epoch: 34/100... Training loss: 0.0985\n",
      "Epoch: 34/100... Training loss: 0.0981\n",
      "Epoch: 34/100... Training loss: 0.0975\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.0995\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.0986\n",
      "Epoch: 34/100... Training loss: 0.1001\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.0993\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1001\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1002\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.0997\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.0999\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.0981\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.0967\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.0980\n",
      "Epoch: 34/100... Training loss: 0.0992\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1002\n",
      "Epoch: 34/100... Training loss: 0.1008\n",
      "Epoch: 34/100... Training loss: 0.0990\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.0990\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.0989\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.0988\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.0991\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1004\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1002\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1002\n",
      "Epoch: 34/100... Training loss: 0.1001\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.0998\n",
      "Epoch: 34/100... Training loss: 0.1002\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1006\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.0985\n",
      "Epoch: 34/100... Training loss: 0.1004\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1002\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.0980\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.0999\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.0983\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1001\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.0972\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.0998\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.0996\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1002\n",
      "Epoch: 34/100... Training loss: 0.1001\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.0983\n",
      "Epoch: 34/100... Training loss: 0.0991\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.0989\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.0989\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.0996\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.0995\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1008\n",
      "Epoch: 34/100... Training loss: 0.0960\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.0986\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1008\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1001\n",
      "Epoch: 34/100... Training loss: 0.0995\n",
      "Epoch: 34/100... Training loss: 0.0984\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1002\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.0984\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1000\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.0999\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.0999\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.0992\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1003\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.0999\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.0997\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.0986\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.0976\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.0979\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.0992\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.0997\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.0994\n",
      "Epoch: 35/100... Training loss: 0.0993\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1015\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1005\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.0991\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1015\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.0999\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.0996\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.0990\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.0997\n",
      "Epoch: 35/100... Training loss: 0.0996\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.0969\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.0994\n",
      "Epoch: 35/100... Training loss: 0.0988\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.0978\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1000\n",
      "Epoch: 35/100... Training loss: 0.0987\n",
      "Epoch: 35/100... Training loss: 0.1000\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1000\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.0980\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.0995\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.0995\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.0983\n",
      "Epoch: 35/100... Training loss: 0.0994\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.0999\n",
      "Epoch: 35/100... Training loss: 0.0972\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.0999\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.0986\n",
      "Epoch: 35/100... Training loss: 0.1000\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.0979\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.0988\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.0988\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1002\n",
      "Epoch: 35/100... Training loss: 0.0995\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.0994\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1000\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.0989\n",
      "Epoch: 35/100... Training loss: 0.0996\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.0981\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.0996\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.0989\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.0989\n",
      "Epoch: 35/100... Training loss: 0.0996\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.0990\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.0997\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.0993\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.0997\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.0995\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.0994\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1005\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.0991\n",
      "Epoch: 35/100... Training loss: 0.0993\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.0981\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.0985\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.0986\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.0990\n",
      "Epoch: 35/100... Training loss: 0.1000\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.0992\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.0996\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1000\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1005\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.0988\n",
      "Epoch: 35/100... Training loss: 0.1005\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.0998\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.0978\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1006\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.0976\n",
      "Epoch: 36/100... Training loss: 0.0974\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.0995\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.0991\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.0994\n",
      "Epoch: 36/100... Training loss: 0.0981\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.0990\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1000\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.0998\n",
      "Epoch: 36/100... Training loss: 0.1000\n",
      "Epoch: 36/100... Training loss: 0.1000\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.0981\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.0990\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1002\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.0994\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.0994\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.0992\n",
      "Epoch: 36/100... Training loss: 0.0987\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.0992\n",
      "Epoch: 36/100... Training loss: 0.0978\n",
      "Epoch: 36/100... Training loss: 0.0968\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.0998\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.0986\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1006\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.0989\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.0992\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.0976\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.0986\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.0992\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.0993\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.0988\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.0983\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.0986\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.0985\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.0983\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.0989\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 36/100... Training loss: 0.0998\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.0994\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1067\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.0990\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.0980\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.0993\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.0994\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.0977\n",
      "Epoch: 36/100... Training loss: 0.0990\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.0991\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1006\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.0987\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1002\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.0986\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.0990\n",
      "Epoch: 36/100... Training loss: 0.1002\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.0974\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.0985\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1006\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.0984\n",
      "Epoch: 37/100... Training loss: 0.0993\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.0976\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.0993\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.0984\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.0974\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.0999\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.0984\n",
      "Epoch: 37/100... Training loss: 0.0982\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.0999\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.0996\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.0994\n",
      "Epoch: 37/100... Training loss: 0.0979\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.0971\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.0988\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.0985\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1004\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.0949\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.0999\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1004\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.0989\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.0979\n",
      "Epoch: 37/100... Training loss: 0.0992\n",
      "Epoch: 37/100... Training loss: 0.0989\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.0991\n",
      "Epoch: 37/100... Training loss: 0.1004\n",
      "Epoch: 37/100... Training loss: 0.0996\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.0982\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.0974\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.0980\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1068\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.0987\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.0993\n",
      "Epoch: 37/100... Training loss: 0.0989\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.0989\n",
      "Epoch: 37/100... Training loss: 0.0990\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.0994\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.0986\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.0991\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.0994\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.0964\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.0984\n",
      "Epoch: 37/100... Training loss: 0.0991\n",
      "Epoch: 37/100... Training loss: 0.0996\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1008\n",
      "Epoch: 37/100... Training loss: 0.0972\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1004\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1008\n",
      "Epoch: 37/100... Training loss: 0.0993\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.0985\n",
      "Epoch: 37/100... Training loss: 0.0991\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.0991\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1008\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.0993\n",
      "Epoch: 37/100... Training loss: 0.0980\n",
      "Epoch: 37/100... Training loss: 0.0985\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.0999\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.0987\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.0996\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.0975\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.0986\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.0994\n",
      "Epoch: 37/100... Training loss: 0.0989\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.0992\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.0980\n",
      "Epoch: 37/100... Training loss: 0.0997\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.0999\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.0979\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.0990\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.0997\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.0990\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.0977\n",
      "Epoch: 38/100... Training loss: 0.0995\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.0989\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.0992\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.0992\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.0995\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.0975\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1067\n",
      "Epoch: 38/100... Training loss: 0.0965\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.0969\n",
      "Epoch: 38/100... Training loss: 0.0984\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.0993\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.0977\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.0984\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.0994\n",
      "Epoch: 38/100... Training loss: 0.0978\n",
      "Epoch: 38/100... Training loss: 0.0987\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.0995\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.0953\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1005\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1064\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.0998\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.0993\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.0974\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.0981\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.0995\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.0975\n",
      "Epoch: 38/100... Training loss: 0.0999\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.0998\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.0970\n",
      "Epoch: 38/100... Training loss: 0.0999\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.0995\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.0995\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.0973\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.0977\n",
      "Epoch: 38/100... Training loss: 0.0991\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.0966\n",
      "Epoch: 38/100... Training loss: 0.1005\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.0995\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.0989\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.0987\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.0980\n",
      "Epoch: 38/100... Training loss: 0.0998\n",
      "Epoch: 38/100... Training loss: 0.0985\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.0992\n",
      "Epoch: 38/100... Training loss: 0.0992\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.0987\n",
      "Epoch: 38/100... Training loss: 0.0999\n",
      "Epoch: 38/100... Training loss: 0.0981\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.0983\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.0994\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.0997\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.0987\n",
      "Epoch: 38/100... Training loss: 0.0992\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.0990\n",
      "Epoch: 38/100... Training loss: 0.0974\n",
      "Epoch: 38/100... Training loss: 0.0969\n",
      "Epoch: 38/100... Training loss: 0.0999\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.0997\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1000\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.0989\n",
      "Epoch: 38/100... Training loss: 0.0979\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.0987\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.0989\n",
      "Epoch: 38/100... Training loss: 0.0973\n",
      "Epoch: 38/100... Training loss: 0.0983\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.0994\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.0960\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.0992\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.0967\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.0987\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.0978\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.0967\n",
      "Epoch: 39/100... Training loss: 0.0982\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.0972\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.0994\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.0967\n",
      "Epoch: 39/100... Training loss: 0.0979\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1000\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.0978\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.0963\n",
      "Epoch: 39/100... Training loss: 0.0998\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.0992\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.0978\n",
      "Epoch: 39/100... Training loss: 0.0980\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.0985\n",
      "Epoch: 39/100... Training loss: 0.0986\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.0983\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.0972\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.0981\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.0990\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.0981\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.0990\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.0979\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.0974\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.0979\n",
      "Epoch: 39/100... Training loss: 0.0973\n",
      "Epoch: 39/100... Training loss: 0.0991\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1008\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1000\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.0974\n",
      "Epoch: 39/100... Training loss: 0.0998\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1003\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.1000\n",
      "Epoch: 39/100... Training loss: 0.0993\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.0993\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1000\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.0989\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.0982\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.0992\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.0994\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.0994\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.0994\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.0994\n",
      "Epoch: 39/100... Training loss: 0.0989\n",
      "Epoch: 39/100... Training loss: 0.0986\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.0974\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.0998\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.0967\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.0987\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.0965\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.0990\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.0977\n",
      "Epoch: 39/100... Training loss: 0.0986\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.0989\n",
      "Epoch: 39/100... Training loss: 0.0964\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.0993\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.0992\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1008\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.0972\n",
      "Epoch: 39/100... Training loss: 0.0968\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.0959\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.0967\n",
      "Epoch: 39/100... Training loss: 0.0986\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.0970\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1008\n",
      "Epoch: 39/100... Training loss: 0.0994\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.0978\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1008\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.0987\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.0971\n",
      "Epoch: 39/100... Training loss: 0.1008\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.0983\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.0970\n",
      "Epoch: 39/100... Training loss: 0.0975\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.0974\n",
      "Epoch: 39/100... Training loss: 0.0989\n",
      "Epoch: 39/100... Training loss: 0.1008\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.0985\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.0990\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.0993\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.0988\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.0982\n",
      "Epoch: 40/100... Training loss: 0.0982\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.0979\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.0974\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.0986\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.0976\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.0988\n",
      "Epoch: 40/100... Training loss: 0.0972\n",
      "Epoch: 40/100... Training loss: 0.0978\n",
      "Epoch: 40/100... Training loss: 0.0988\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1016\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.0984\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1016\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.0980\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.0987\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.0990\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.0969\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.0982\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.0993\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.0988\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.0991\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.0981\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.0988\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.0987\n",
      "Epoch: 40/100... Training loss: 0.0986\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.0981\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.0991\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.0985\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.0981\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.0987\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1016\n",
      "Epoch: 40/100... Training loss: 0.0981\n",
      "Epoch: 40/100... Training loss: 0.0966\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.0990\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.0982\n",
      "Epoch: 40/100... Training loss: 0.0983\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.0996\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.0980\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.0991\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1016\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.0987\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.0992\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.1022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100... Training loss: 0.0974\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.0986\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.0995\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.0993\n",
      "Epoch: 40/100... Training loss: 0.0990\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1016\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.0970\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.0975\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.0986\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.0996\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.0986\n",
      "Epoch: 40/100... Training loss: 0.0971\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.0991\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.0979\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1001\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.0954\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.0986\n",
      "Epoch: 40/100... Training loss: 0.0984\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.0996\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.0988\n",
      "Epoch: 40/100... Training loss: 0.0982\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.0983\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.0983\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.0991\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.0979\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.0999\n",
      "Epoch: 41/100... Training loss: 0.0980\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.0984\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.0984\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.0981\n",
      "Epoch: 41/100... Training loss: 0.0997\n",
      "Epoch: 41/100... Training loss: 0.0969\n",
      "Epoch: 41/100... Training loss: 0.0999\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.0970\n",
      "Epoch: 41/100... Training loss: 0.0977\n",
      "Epoch: 41/100... Training loss: 0.0974\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.0984\n",
      "Epoch: 41/100... Training loss: 0.0990\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1054\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.0986\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.0986\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.0979\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.0995\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.0975\n",
      "Epoch: 41/100... Training loss: 0.0977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.0969\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.0977\n",
      "Epoch: 41/100... Training loss: 0.0992\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.0980\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.0992\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1001\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.0997\n",
      "Epoch: 41/100... Training loss: 0.0973\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.0996\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.0997\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.0996\n",
      "Epoch: 41/100... Training loss: 0.0997\n",
      "Epoch: 41/100... Training loss: 0.0985\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.0966\n",
      "Epoch: 41/100... Training loss: 0.1001\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.0984\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.0977\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.0987\n",
      "Epoch: 41/100... Training loss: 0.1008\n",
      "Epoch: 41/100... Training loss: 0.0995\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.0993\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.0966\n",
      "Epoch: 41/100... Training loss: 0.1008\n",
      "Epoch: 41/100... Training loss: 0.0999\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.0981\n",
      "Epoch: 41/100... Training loss: 0.0960\n",
      "Epoch: 41/100... Training loss: 0.0999\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.0977\n",
      "Epoch: 41/100... Training loss: 0.0990\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.0972\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.0984\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.0986\n",
      "Epoch: 41/100... Training loss: 0.0994\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.0983\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.0993\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.0997\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.0988\n",
      "Epoch: 41/100... Training loss: 0.0974\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.0966\n",
      "Epoch: 41/100... Training loss: 0.0990\n",
      "Epoch: 41/100... Training loss: 0.1001\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.0987\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1001\n",
      "Epoch: 41/100... Training loss: 0.0992\n",
      "Epoch: 41/100... Training loss: 0.1001\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.0971\n",
      "Epoch: 41/100... Training loss: 0.0975\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.0990\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.0986\n",
      "Epoch: 41/100... Training loss: 0.0944\n",
      "Epoch: 41/100... Training loss: 0.0993\n",
      "Epoch: 41/100... Training loss: 0.0999\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.0994\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.0994\n",
      "Epoch: 41/100... Training loss: 0.0997\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.0996\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.0975\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.0983\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.0977\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.0987\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.0992\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.0982\n",
      "Epoch: 41/100... Training loss: 0.0981\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.0970\n",
      "Epoch: 41/100... Training loss: 0.0991\n",
      "Epoch: 41/100... Training loss: 0.0995\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.0980\n",
      "Epoch: 41/100... Training loss: 0.0974\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.0982\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.0981\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.0995\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.0977\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.0980\n",
      "Epoch: 41/100... Training loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.0984\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.0988\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.0984\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.0994\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.0988\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.0967\n",
      "Epoch: 42/100... Training loss: 0.0988\n",
      "Epoch: 42/100... Training loss: 0.0962\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.0959\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.0975\n",
      "Epoch: 42/100... Training loss: 0.0971\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.0992\n",
      "Epoch: 42/100... Training loss: 0.0994\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.0979\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.0988\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.0984\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.0994\n",
      "Epoch: 42/100... Training loss: 0.0980\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.0992\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.0975\n",
      "Epoch: 42/100... Training loss: 0.0978\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.0976\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.0983\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.0977\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.0973\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.0986\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.0988\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.0965\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.0980\n",
      "Epoch: 42/100... Training loss: 0.0986\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.0982\n",
      "Epoch: 42/100... Training loss: 0.0991\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.0980\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.0971\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.0985\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.0990\n",
      "Epoch: 42/100... Training loss: 0.0970\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.0986\n",
      "Epoch: 42/100... Training loss: 0.0988\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.0971\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100... Training loss: 0.0980\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.0967\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.0991\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.0991\n",
      "Epoch: 42/100... Training loss: 0.0983\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.0990\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.0966\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.0954\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.0970\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.0984\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.0981\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.0970\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.0973\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.0975\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1002\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.0985\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.0983\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.0990\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.0967\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.0966\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.0984\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.0979\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.0979\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.0992\n",
      "Epoch: 43/100... Training loss: 0.0988\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.0961\n",
      "Epoch: 43/100... Training loss: 0.0992\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.0991\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.0992\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.0990\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.0968\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.0987\n",
      "Epoch: 43/100... Training loss: 0.0984\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.0992\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.0973\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.0964\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.0971\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.0997\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.0973\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.0961\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.0973\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.0966\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.0987\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.0982\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.0997\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.0975\n",
      "Epoch: 43/100... Training loss: 0.0978\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.0974\n",
      "Epoch: 43/100... Training loss: 0.0990\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.0981\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.0980\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.0979\n",
      "Epoch: 43/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.0974\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.0981\n",
      "Epoch: 43/100... Training loss: 0.0987\n",
      "Epoch: 43/100... Training loss: 0.0985\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.0962\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.0959\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.0974\n",
      "Epoch: 43/100... Training loss: 0.0991\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.0991\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.0979\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.0990\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.0976\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.0985\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.0943\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.0977\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.0977\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.0982\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.0967\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.0982\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.0997\n",
      "Epoch: 43/100... Training loss: 0.0978\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.0979\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.0975\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.0988\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.0991\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.0982\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1061\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.0986\n",
      "Epoch: 43/100... Training loss: 0.0992\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.0976\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.0975\n",
      "Epoch: 43/100... Training loss: 0.0972\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.0981\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.0975\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.0996\n",
      "Epoch: 44/100... Training loss: 0.0978\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.0973\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.0976\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.0985\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.0972\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.0996\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.0992\n",
      "Epoch: 44/100... Training loss: 0.0993\n",
      "Epoch: 44/100... Training loss: 0.0984\n",
      "Epoch: 44/100... Training loss: 0.0964\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.0984\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100... Training loss: 0.0993\n",
      "Epoch: 44/100... Training loss: 0.0988\n",
      "Epoch: 44/100... Training loss: 0.0991\n",
      "Epoch: 44/100... Training loss: 0.0973\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.0994\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.0966\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.0976\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.0971\n",
      "Epoch: 44/100... Training loss: 0.0993\n",
      "Epoch: 44/100... Training loss: 0.0987\n",
      "Epoch: 44/100... Training loss: 0.0962\n",
      "Epoch: 44/100... Training loss: 0.0995\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.0983\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.0984\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.0996\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.0989\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.0988\n",
      "Epoch: 44/100... Training loss: 0.0991\n",
      "Epoch: 44/100... Training loss: 0.0985\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.0989\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.0996\n",
      "Epoch: 44/100... Training loss: 0.0972\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.0994\n",
      "Epoch: 44/100... Training loss: 0.0988\n",
      "Epoch: 44/100... Training loss: 0.0987\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.0983\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.0992\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.0981\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.0957\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.0996\n",
      "Epoch: 44/100... Training loss: 0.0992\n",
      "Epoch: 44/100... Training loss: 0.0961\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.0970\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.0987\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.0993\n",
      "Epoch: 44/100... Training loss: 0.0988\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.0980\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.0977\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.0954\n",
      "Epoch: 44/100... Training loss: 0.0989\n",
      "Epoch: 44/100... Training loss: 0.0980\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.0979\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.0986\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.0975\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.0982\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.0964\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.0994\n",
      "Epoch: 44/100... Training loss: 0.1063\n",
      "Epoch: 44/100... Training loss: 0.1059\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.0995\n",
      "Epoch: 44/100... Training loss: 0.0995\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.0984\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.0994\n",
      "Epoch: 44/100... Training loss: 0.0991\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.0982\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.0984\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.0966\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.0994\n",
      "Epoch: 44/100... Training loss: 0.0993\n",
      "Epoch: 44/100... Training loss: 0.0985\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.0977\n",
      "Epoch: 44/100... Training loss: 0.0957\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.0986\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.0957\n",
      "Epoch: 44/100... Training loss: 0.0989\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.0983\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.0966\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.0962\n",
      "Epoch: 44/100... Training loss: 0.0987\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.0992\n",
      "Epoch: 44/100... Training loss: 0.0983\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100... Training loss: 0.0991\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.0964\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.0970\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.0987\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.0989\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.0986\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.0987\n",
      "Epoch: 44/100... Training loss: 0.0960\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.0985\n",
      "Epoch: 44/100... Training loss: 0.0984\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.0992\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.0988\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.0972\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.0963\n",
      "Epoch: 44/100... Training loss: 0.0985\n",
      "Epoch: 44/100... Training loss: 0.1062\n",
      "Epoch: 44/100... Training loss: 0.0975\n",
      "Epoch: 44/100... Training loss: 0.0993\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.0977\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.0972\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.0995\n",
      "Epoch: 44/100... Training loss: 0.0987\n",
      "Epoch: 45/100... Training loss: 0.0997\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.0972\n",
      "Epoch: 45/100... Training loss: 0.0979\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.0973\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.0997\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.0990\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.0983\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.0989\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.0958\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1058\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.0992\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.0988\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.0979\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.0973\n",
      "Epoch: 45/100... Training loss: 0.0960\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.0974\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.0985\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.0992\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.0974\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.0983\n",
      "Epoch: 45/100... Training loss: 0.0997\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.0990\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.0979\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.0961\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.0980\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.0983\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.0988\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.0954\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.0971\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.0971\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.0990\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.0972\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.0968\n",
      "Epoch: 45/100... Training loss: 0.0997\n",
      "Epoch: 45/100... Training loss: 0.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.0979\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.0976\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.0980\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.0981\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.0988\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.0980\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.0980\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.0983\n",
      "Epoch: 45/100... Training loss: 0.0988\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1054\n",
      "Epoch: 45/100... Training loss: 0.0993\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.0989\n",
      "Epoch: 45/100... Training loss: 0.0988\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.0969\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.0973\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.0985\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.0983\n",
      "Epoch: 45/100... Training loss: 0.0968\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.0977\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.0981\n",
      "Epoch: 45/100... Training loss: 0.0985\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.0992\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.0989\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.0997\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.0974\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.0977\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.0972\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.0968\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.0990\n",
      "Epoch: 45/100... Training loss: 0.0997\n",
      "Epoch: 45/100... Training loss: 0.0985\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.0993\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.0971\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.0990\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.0988\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.0988\n",
      "Epoch: 45/100... Training loss: 0.0981\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.0984\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.0961\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.0986\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.0965\n",
      "Epoch: 46/100... Training loss: 0.0976\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.0989\n",
      "Epoch: 46/100... Training loss: 0.0997\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.0963\n",
      "Epoch: 46/100... Training loss: 0.0994\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.0989\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.0984\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.0981\n",
      "Epoch: 46/100... Training loss: 0.0994\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.0976\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.0989\n",
      "Epoch: 46/100... Training loss: 0.0991\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.0965\n",
      "Epoch: 46/100... Training loss: 0.0974\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.0984\n",
      "Epoch: 46/100... Training loss: 0.0995\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.0975\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.0970\n",
      "Epoch: 46/100... Training loss: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.0990\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.0997\n",
      "Epoch: 46/100... Training loss: 0.0968\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.0982\n",
      "Epoch: 46/100... Training loss: 0.0991\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.0983\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.0995\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.0991\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.0986\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.0969\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.0977\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.0977\n",
      "Epoch: 46/100... Training loss: 0.0982\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.0986\n",
      "Epoch: 46/100... Training loss: 0.0963\n",
      "Epoch: 46/100... Training loss: 0.0967\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.0967\n",
      "Epoch: 46/100... Training loss: 0.0984\n",
      "Epoch: 46/100... Training loss: 0.0974\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.0991\n",
      "Epoch: 46/100... Training loss: 0.0985\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.0982\n",
      "Epoch: 46/100... Training loss: 0.0980\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.0955\n",
      "Epoch: 46/100... Training loss: 0.0995\n",
      "Epoch: 46/100... Training loss: 0.0985\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.0979\n",
      "Epoch: 46/100... Training loss: 0.0973\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.0967\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.0982\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.0997\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.0983\n",
      "Epoch: 46/100... Training loss: 0.0976\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.0978\n",
      "Epoch: 46/100... Training loss: 0.0990\n",
      "Epoch: 46/100... Training loss: 0.0995\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.0971\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.0986\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.0990\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.0991\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.0983\n",
      "Epoch: 46/100... Training loss: 0.0995\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.0976\n",
      "Epoch: 46/100... Training loss: 0.0985\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.0985\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.0979\n",
      "Epoch: 46/100... Training loss: 0.0986\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.0976\n",
      "Epoch: 46/100... Training loss: 0.0985\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.0936\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.0994\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.0964\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.0936\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.0960\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.0969\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.0985\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100... Training loss: 0.0964\n",
      "Epoch: 46/100... Training loss: 0.0982\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.0989\n",
      "Epoch: 46/100... Training loss: 0.0981\n",
      "Epoch: 46/100... Training loss: 0.0995\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.0997\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.0976\n",
      "Epoch: 46/100... Training loss: 0.0997\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.0983\n",
      "Epoch: 47/100... Training loss: 0.0980\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.0994\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.0994\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.0980\n",
      "Epoch: 47/100... Training loss: 0.0972\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.0972\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.0968\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.0987\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.0991\n",
      "Epoch: 47/100... Training loss: 0.0974\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.0966\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.0978\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.0968\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.0991\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.0981\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0985\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.0976\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0989\n",
      "Epoch: 47/100... Training loss: 0.0980\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.0979\n",
      "Epoch: 47/100... Training loss: 0.1058\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0989\n",
      "Epoch: 47/100... Training loss: 0.0985\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.0994\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0971\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.0972\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0979\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.0991\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.0981\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.0987\n",
      "Epoch: 47/100... Training loss: 0.0975\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.0979\n",
      "Epoch: 47/100... Training loss: 0.0966\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.0978\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.0976\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.0971\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.0977\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.0977\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.0972\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.0974\n",
      "Epoch: 47/100... Training loss: 0.0966\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.0963\n",
      "Epoch: 47/100... Training loss: 0.0963\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.0981\n",
      "Epoch: 47/100... Training loss: 0.0982\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100... Training loss: 0.0980\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.0983\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.0972\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.0982\n",
      "Epoch: 47/100... Training loss: 0.0983\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0960\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.0989\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.0985\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.0980\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.0989\n",
      "Epoch: 47/100... Training loss: 0.0980\n",
      "Epoch: 47/100... Training loss: 0.0979\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.0982\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.0978\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.0976\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.0972\n",
      "Epoch: 47/100... Training loss: 0.0969\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.0985\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.0988\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.0988\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.0950\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.0985\n",
      "Epoch: 47/100... Training loss: 0.0980\n",
      "Epoch: 47/100... Training loss: 0.0973\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.0980\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.0982\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.0980\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.0988\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.0976\n",
      "Epoch: 48/100... Training loss: 0.0978\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.0978\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.0978\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.0976\n",
      "Epoch: 48/100... Training loss: 0.0971\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.0979\n",
      "Epoch: 48/100... Training loss: 0.0985\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.0983\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.0985\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.0968\n",
      "Epoch: 48/100... Training loss: 0.0980\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.0990\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.0982\n",
      "Epoch: 48/100... Training loss: 0.0956\n",
      "Epoch: 48/100... Training loss: 0.0970\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.0975\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.0977\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.0982\n",
      "Epoch: 48/100... Training loss: 0.0988\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.0979\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100... Training loss: 0.0972\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.0972\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.0976\n",
      "Epoch: 48/100... Training loss: 0.0979\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.0974\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.0990\n",
      "Epoch: 48/100... Training loss: 0.0986\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.0978\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.0973\n",
      "Epoch: 48/100... Training loss: 0.0979\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.0983\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.0990\n",
      "Epoch: 48/100... Training loss: 0.0990\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.0974\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.0986\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.0979\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.0979\n",
      "Epoch: 48/100... Training loss: 0.0982\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.0985\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.0947\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.0988\n",
      "Epoch: 48/100... Training loss: 0.0973\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.0982\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.0974\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.0980\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.0983\n",
      "Epoch: 48/100... Training loss: 0.0967\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.0966\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.0966\n",
      "Epoch: 48/100... Training loss: 0.0982\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.0971\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.0970\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.0957\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.0963\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.0976\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.0968\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.0988\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.0978\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.0970\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.0980\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1034\n",
      "Epoch: 48/100... Training loss: 0.0955\n",
      "Epoch: 48/100... Training loss: 0.0977\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.0960\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.0980\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.0967\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.0980\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.0985\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.0982\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.0990\n",
      "Epoch: 49/100... Training loss: 0.0982\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.0980\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.0981\n",
      "Epoch: 49/100... Training loss: 0.0981\n",
      "Epoch: 49/100... Training loss: 0.0978\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.0989\n",
      "Epoch: 49/100... Training loss: 0.0989\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.0982\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.0962\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0980\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.0970\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0988\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0978\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.0978\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0987\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.0964\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.0978\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.0969\n",
      "Epoch: 49/100... Training loss: 0.0960\n",
      "Epoch: 49/100... Training loss: 0.0979\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.0987\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.0959\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1012\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0974\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.0972\n",
      "Epoch: 49/100... Training loss: 0.0981\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.0930\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.0986\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.0980\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.0980\n",
      "Epoch: 49/100... Training loss: 0.0989\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.0975\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.0944\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.0986\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.0982\n",
      "Epoch: 49/100... Training loss: 0.0976\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.0975\n",
      "Epoch: 49/100... Training loss: 0.0981\n",
      "Epoch: 49/100... Training loss: 0.1012\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.0987\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.0965\n",
      "Epoch: 49/100... Training loss: 0.0981\n",
      "Epoch: 49/100... Training loss: 0.0981\n",
      "Epoch: 49/100... Training loss: 0.0950\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.0986\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.0962\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.0973\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.0974\n",
      "Epoch: 49/100... Training loss: 0.0959\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.0981\n",
      "Epoch: 49/100... Training loss: 0.0980\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.0980\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.0990\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.0976\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.0978\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.0964\n",
      "Epoch: 49/100... Training loss: 0.0969\n",
      "Epoch: 49/100... Training loss: 0.0968\n",
      "Epoch: 49/100... Training loss: 0.0972\n",
      "Epoch: 49/100... Training loss: 0.0973\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.0988\n",
      "Epoch: 49/100... Training loss: 0.0986\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.0990\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.0980\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.0969\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.0995\n",
      "Epoch: 49/100... Training loss: 0.0957\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.0942\n",
      "Epoch: 49/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.0983\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.0976\n",
      "Epoch: 49/100... Training loss: 0.0947\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.0988\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.0969\n",
      "Epoch: 49/100... Training loss: 0.0995\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.0988\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.0972\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1045\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.0983\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.0988\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.0967\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.0974\n",
      "Epoch: 49/100... Training loss: 0.0967\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.0975\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.0978\n",
      "Epoch: 49/100... Training loss: 0.0978\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.0976\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.0973\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1012\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.0954\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.0990\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.0975\n",
      "Epoch: 50/100... Training loss: 0.0964\n",
      "Epoch: 50/100... Training loss: 0.0985\n",
      "Epoch: 50/100... Training loss: 0.0978\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.0985\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.0974\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.0973\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.0979\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.0983\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.0971\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.0992\n",
      "Epoch: 50/100... Training loss: 0.0988\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.0978\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.0978\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.0988\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.0983\n",
      "Epoch: 50/100... Training loss: 0.0972\n",
      "Epoch: 50/100... Training loss: 0.0984\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.0981\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.0990\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.0978\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0990\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.0977\n",
      "Epoch: 50/100... Training loss: 0.0951\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.0939\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.0974\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.0972\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.0945\n",
      "Epoch: 50/100... Training loss: 0.0979\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.0988\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.0978\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.0986\n",
      "Epoch: 50/100... Training loss: 0.0985\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.0984\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.0977\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.0972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0971\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.0972\n",
      "Epoch: 50/100... Training loss: 0.0976\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.0988\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0992\n",
      "Epoch: 50/100... Training loss: 0.0988\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.0974\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.0982\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.0977\n",
      "Epoch: 50/100... Training loss: 0.0978\n",
      "Epoch: 50/100... Training loss: 0.0983\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.0982\n",
      "Epoch: 50/100... Training loss: 0.0973\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.0976\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.0984\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.0988\n",
      "Epoch: 50/100... Training loss: 0.0976\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.0962\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.0977\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.0988\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.0985\n",
      "Epoch: 50/100... Training loss: 0.0990\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.0984\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.0952\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.0973\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.0976\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.0969\n",
      "Epoch: 50/100... Training loss: 0.0966\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.0983\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.0978\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.0984\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.0959\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.0992\n",
      "Epoch: 50/100... Training loss: 0.0947\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.0990\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.0959\n",
      "Epoch: 50/100... Training loss: 0.0992\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.0990\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.0986\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.0986\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.0993\n",
      "Epoch: 50/100... Training loss: 0.0965\n",
      "Epoch: 50/100... Training loss: 0.0976\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.0958\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.0976\n",
      "Epoch: 51/100... Training loss: 0.0973\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.0985\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.0979\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.0970\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.0979\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.0966\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.0963\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.0976\n",
      "Epoch: 51/100... Training loss: 0.0982\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.0967\n",
      "Epoch: 51/100... Training loss: 0.0975\n",
      "Epoch: 51/100... Training loss: 0.0978\n",
      "Epoch: 51/100... Training loss: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.0992\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.0963\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.0982\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.0977\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.0982\n",
      "Epoch: 51/100... Training loss: 0.0982\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.0975\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.0985\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.0962\n",
      "Epoch: 51/100... Training loss: 0.0978\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.0967\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.0970\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.0974\n",
      "Epoch: 51/100... Training loss: 0.0978\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.0978\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.0982\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0959\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.0980\n",
      "Epoch: 51/100... Training loss: 0.0971\n",
      "Epoch: 51/100... Training loss: 0.0958\n",
      "Epoch: 51/100... Training loss: 0.0985\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.0970\n",
      "Epoch: 51/100... Training loss: 0.0950\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.0974\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.0974\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.0970\n",
      "Epoch: 51/100... Training loss: 0.0965\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.0968\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.0973\n",
      "Epoch: 51/100... Training loss: 0.0968\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.0985\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0977\n",
      "Epoch: 51/100... Training loss: 0.0972\n",
      "Epoch: 51/100... Training loss: 0.0978\n",
      "Epoch: 51/100... Training loss: 0.0974\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.0972\n",
      "Epoch: 51/100... Training loss: 0.0974\n",
      "Epoch: 51/100... Training loss: 0.0980\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.1060\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.0977\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.0957\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.0973\n",
      "Epoch: 51/100... Training loss: 0.0956\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.0987\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.0963\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0973\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.0968\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.0979\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.0969\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.0976\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.0978\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.0978\n",
      "Epoch: 51/100... Training loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.0992\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.0964\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.0971\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.0992\n",
      "Epoch: 51/100... Training loss: 0.0969\n",
      "Epoch: 51/100... Training loss: 0.0984\n",
      "Epoch: 51/100... Training loss: 0.0967\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.0982\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.0992\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.0987\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.0977\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.0936\n",
      "Epoch: 52/100... Training loss: 0.0983\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0966\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.0979\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.0966\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.0965\n",
      "Epoch: 52/100... Training loss: 0.0964\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.0989\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.0972\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0975\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.0972\n",
      "Epoch: 52/100... Training loss: 0.0987\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.0977\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.0972\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.0960\n",
      "Epoch: 52/100... Training loss: 0.0968\n",
      "Epoch: 52/100... Training loss: 0.0964\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.0953\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.0988\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.0957\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.0983\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.0979\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.0962\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.0977\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.0975\n",
      "Epoch: 52/100... Training loss: 0.0989\n",
      "Epoch: 52/100... Training loss: 0.0965\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.0974\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.0960\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.0968\n",
      "Epoch: 52/100... Training loss: 0.0979\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.0958\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0988\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.0987\n",
      "Epoch: 52/100... Training loss: 0.1040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.0963\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.0976\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.0975\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.0965\n",
      "Epoch: 52/100... Training loss: 0.0978\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0980\n",
      "Epoch: 52/100... Training loss: 0.0967\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.0980\n",
      "Epoch: 52/100... Training loss: 0.0975\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.0988\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.0988\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.0977\n",
      "Epoch: 52/100... Training loss: 0.0965\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.0983\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.0983\n",
      "Epoch: 52/100... Training loss: 0.0983\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0967\n",
      "Epoch: 52/100... Training loss: 0.0954\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.0975\n",
      "Epoch: 52/100... Training loss: 0.0973\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.0979\n",
      "Epoch: 52/100... Training loss: 0.0972\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.0977\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.0967\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.0956\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.0983\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.0961\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.0969\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.0971\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.0954\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.0983\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.0970\n",
      "Epoch: 52/100... Training loss: 0.0977\n",
      "Epoch: 52/100... Training loss: 0.0962\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0969\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1057\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.0960\n",
      "Epoch: 52/100... Training loss: 0.0983\n",
      "Epoch: 52/100... Training loss: 0.0989\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.0976\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.0976\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0967\n",
      "Epoch: 53/100... Training loss: 0.0971\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0969\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.0971\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0973\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.0984\n",
      "Epoch: 53/100... Training loss: 0.0976\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.0981\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.0979\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.0981\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.0979\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.0979\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0973\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.0974\n",
      "Epoch: 53/100... Training loss: 0.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.0980\n",
      "Epoch: 53/100... Training loss: 0.0983\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.0972\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.0978\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.0961\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.0984\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.0978\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.0947\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.0953\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.0981\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.0983\n",
      "Epoch: 53/100... Training loss: 0.0974\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.0987\n",
      "Epoch: 53/100... Training loss: 0.0969\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.0955\n",
      "Epoch: 53/100... Training loss: 0.0975\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0980\n",
      "Epoch: 53/100... Training loss: 0.0987\n",
      "Epoch: 53/100... Training loss: 0.0987\n",
      "Epoch: 53/100... Training loss: 0.0943\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.0979\n",
      "Epoch: 53/100... Training loss: 0.0973\n",
      "Epoch: 53/100... Training loss: 0.0983\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.0979\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.0987\n",
      "Epoch: 53/100... Training loss: 0.0970\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.0955\n",
      "Epoch: 53/100... Training loss: 0.0977\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.0984\n",
      "Epoch: 53/100... Training loss: 0.0974\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.0954\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.0984\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.0973\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.0967\n",
      "Epoch: 53/100... Training loss: 0.0975\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.0979\n",
      "Epoch: 53/100... Training loss: 0.0983\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.0971\n",
      "Epoch: 53/100... Training loss: 0.0950\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.0963\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.0960\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.0976\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.0973\n",
      "Epoch: 53/100... Training loss: 0.0984\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.0963\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.0973\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.0984\n",
      "Epoch: 53/100... Training loss: 0.0972\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.0979\n",
      "Epoch: 53/100... Training loss: 0.0974\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.0980\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.0970\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.0978\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.0971\n",
      "Epoch: 53/100... Training loss: 0.0972\n",
      "Epoch: 53/100... Training loss: 0.0967\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.0984\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.0957\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.0958\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.0996\n",
      "Epoch: 53/100... Training loss: 0.0972\n",
      "Epoch: 53/100... Training loss: 0.0981\n",
      "Epoch: 53/100... Training loss: 0.0976\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.0972\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.0972\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.0972\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0978\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1056\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.0971\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.0964\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.0960\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0973\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.0981\n",
      "Epoch: 54/100... Training loss: 0.0971\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0977\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.0968\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1052\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.0978\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.0984\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.0977\n",
      "Epoch: 54/100... Training loss: 0.0977\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.0985\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.0941\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.0971\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.0984\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1042\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.0977\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.0974\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.0955\n",
      "Epoch: 54/100... Training loss: 0.0969\n",
      "Epoch: 54/100... Training loss: 0.0978\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.0981\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0981\n",
      "Epoch: 54/100... Training loss: 0.0975\n",
      "Epoch: 54/100... Training loss: 0.0971\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0966\n",
      "Epoch: 54/100... Training loss: 0.0978\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1042\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.0981\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.0979\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.0987\n",
      "Epoch: 54/100... Training loss: 0.0985\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.0979\n",
      "Epoch: 54/100... Training loss: 0.0984\n",
      "Epoch: 54/100... Training loss: 0.0969\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.0981\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0985\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0971\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.0975\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.0944\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.0971\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.0969\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.0981\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.0979\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.0972\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.0977\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.0967\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.0970\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.0984\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0969\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0981\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.0976\n",
      "Epoch: 54/100... Training loss: 0.0958\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0973\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.0949\n",
      "Epoch: 54/100... Training loss: 0.0963\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0945\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.0948\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.0963\n",
      "Epoch: 54/100... Training loss: 0.0978\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.0960\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.0987\n",
      "Epoch: 54/100... Training loss: 0.0971\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0970\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.0987\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.0977\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0975\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.0954\n",
      "Epoch: 55/100... Training loss: 0.0969\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.0970\n",
      "Epoch: 55/100... Training loss: 0.0965\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0968\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.0963\n",
      "Epoch: 55/100... Training loss: 0.0976\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.0976\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0955\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.0966\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.0960\n",
      "Epoch: 55/100... Training loss: 0.0967\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.0974\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.0968\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.0985\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.0979\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.0978\n",
      "Epoch: 55/100... Training loss: 0.0971\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0985\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.0971\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.0985\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0992\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.0977\n",
      "Epoch: 55/100... Training loss: 0.0955\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100... Training loss: 0.0955\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.0973\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0973\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.0992\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.0971\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.0961\n",
      "Epoch: 55/100... Training loss: 0.0962\n",
      "Epoch: 55/100... Training loss: 0.0971\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.0975\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.0974\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.0959\n",
      "Epoch: 55/100... Training loss: 0.0965\n",
      "Epoch: 55/100... Training loss: 0.0963\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.0985\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.0944\n",
      "Epoch: 55/100... Training loss: 0.0961\n",
      "Epoch: 55/100... Training loss: 0.0978\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.0980\n",
      "Epoch: 55/100... Training loss: 0.0970\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.0973\n",
      "Epoch: 55/100... Training loss: 0.0976\n",
      "Epoch: 55/100... Training loss: 0.0967\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.0971\n",
      "Epoch: 55/100... Training loss: 0.0973\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.0976\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.0961\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.0985\n",
      "Epoch: 55/100... Training loss: 0.0992\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.0977\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.0978\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.0967\n",
      "Epoch: 55/100... Training loss: 0.0977\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.0946\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.0974\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0965\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.0975\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.0965\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.0956\n",
      "Epoch: 55/100... Training loss: 0.0979\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0970\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.0961\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0979\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.0974\n",
      "Epoch: 55/100... Training loss: 0.0964\n",
      "Epoch: 55/100... Training loss: 0.0970\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0980\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.0962\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0980\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.0985\n",
      "Epoch: 55/100... Training loss: 0.0955\n",
      "Epoch: 55/100... Training loss: 0.0985\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.0976\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.0972\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.0981\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0977\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.0976\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0960\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0970\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0964\n",
      "Epoch: 56/100... Training loss: 0.0955\n",
      "Epoch: 56/100... Training loss: 0.0997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.0958\n",
      "Epoch: 56/100... Training loss: 0.0974\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.0976\n",
      "Epoch: 56/100... Training loss: 0.0968\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.0967\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.0981\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.0965\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0973\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.0922\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.0962\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.0961\n",
      "Epoch: 56/100... Training loss: 0.0976\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.0968\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.0983\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.0980\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.0981\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.0977\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.0980\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.0970\n",
      "Epoch: 56/100... Training loss: 0.0954\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.0983\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.0963\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.0969\n",
      "Epoch: 56/100... Training loss: 0.0965\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.0976\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0963\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.0972\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.0959\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.0981\n",
      "Epoch: 56/100... Training loss: 0.0981\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.0977\n",
      "Epoch: 56/100... Training loss: 0.0956\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.0960\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0974\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.0972\n",
      "Epoch: 56/100... Training loss: 0.0972\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.0965\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.0964\n",
      "Epoch: 56/100... Training loss: 0.0971\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0964\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.0974\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0937\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.0948\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0953\n",
      "Epoch: 56/100... Training loss: 0.0968\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0973\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.0974\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0964\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0973\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.0950\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.0950\n",
      "Epoch: 56/100... Training loss: 0.0967\n",
      "Epoch: 56/100... Training loss: 0.0977\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0968\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.0975\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0969\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0973\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.0961\n",
      "Epoch: 56/100... Training loss: 0.0973\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.0968\n",
      "Epoch: 56/100... Training loss: 0.0974\n",
      "Epoch: 56/100... Training loss: 0.0938\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0991\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.0981\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0991\n",
      "Epoch: 57/100... Training loss: 0.0981\n",
      "Epoch: 57/100... Training loss: 0.1001\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.0966\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1001\n",
      "Epoch: 57/100... Training loss: 0.0974\n",
      "Epoch: 57/100... Training loss: 0.0955\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.0962\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.0991\n",
      "Epoch: 57/100... Training loss: 0.0968\n",
      "Epoch: 57/100... Training loss: 0.0983\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.0971\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.0976\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.0974\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.0981\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.0977\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.0978\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.1001\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.0978\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.0970\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.0991\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.0958\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.0956\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.0977\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.0991\n",
      "Epoch: 57/100... Training loss: 0.0961\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.0963\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.0981\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.0983\n",
      "Epoch: 57/100... Training loss: 0.0970\n",
      "Epoch: 57/100... Training loss: 0.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.0977\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.0957\n",
      "Epoch: 57/100... Training loss: 0.0970\n",
      "Epoch: 57/100... Training loss: 0.0965\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.1001\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.0991\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.0976\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.0974\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.0965\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0975\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.0956\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.0966\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.0972\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.0975\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.0975\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.0977\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1001\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.0962\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.0962\n",
      "Epoch: 57/100... Training loss: 0.0976\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.0950\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.0961\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.0974\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.0983\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.0956\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.0991\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.0965\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.0976\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.0981\n",
      "Epoch: 57/100... Training loss: 0.0963\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1001\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.0977\n",
      "Epoch: 57/100... Training loss: 0.0976\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.0967\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.0964\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0969\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.0957\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0973\n",
      "Epoch: 58/100... Training loss: 0.0975\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.0980\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.0977\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0976\n",
      "Epoch: 58/100... Training loss: 0.0968\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.0973\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.0980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.0969\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0966\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.0976\n",
      "Epoch: 58/100... Training loss: 0.0976\n",
      "Epoch: 58/100... Training loss: 0.0977\n",
      "Epoch: 58/100... Training loss: 0.1047\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.0961\n",
      "Epoch: 58/100... Training loss: 0.0976\n",
      "Epoch: 58/100... Training loss: 0.0975\n",
      "Epoch: 58/100... Training loss: 0.0977\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.0968\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0986\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.0971\n",
      "Epoch: 58/100... Training loss: 0.0972\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.0982\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0955\n",
      "Epoch: 58/100... Training loss: 0.0982\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0969\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0956\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0986\n",
      "Epoch: 58/100... Training loss: 0.0986\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.0971\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.0984\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.0970\n",
      "Epoch: 58/100... Training loss: 0.0962\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0977\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0980\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.0946\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.0977\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0978\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.0971\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.0977\n",
      "Epoch: 58/100... Training loss: 0.0970\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.0959\n",
      "Epoch: 58/100... Training loss: 0.0956\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.0968\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.0952\n",
      "Epoch: 58/100... Training loss: 0.0990\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.0982\n",
      "Epoch: 58/100... Training loss: 0.0936\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1046\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.0976\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.0972\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0965\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.0986\n",
      "Epoch: 58/100... Training loss: 0.0995\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.0954\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0952\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.0984\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.0940\n",
      "Epoch: 58/100... Training loss: 0.0972\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0961\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.0957\n",
      "Epoch: 58/100... Training loss: 0.0973\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0976\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.0995\n",
      "Epoch: 58/100... Training loss: 0.0967\n",
      "Epoch: 58/100... Training loss: 0.0984\n",
      "Epoch: 58/100... Training loss: 0.0965\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.0972\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.0980\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.0986\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0973\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0975\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.0966\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0986\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0959\n",
      "Epoch: 58/100... Training loss: 0.0995\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.0956\n",
      "Epoch: 58/100... Training loss: 0.0990\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0965\n",
      "Epoch: 58/100... Training loss: 0.0975\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.0957\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.0990\n",
      "Epoch: 58/100... Training loss: 0.0970\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.0955\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.0975\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.0975\n",
      "Epoch: 59/100... Training loss: 0.0965\n",
      "Epoch: 59/100... Training loss: 0.0978\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.0973\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0978\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.0964\n",
      "Epoch: 59/100... Training loss: 0.0973\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.0974\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.0955\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.0943\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.0964\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0966\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.0978\n",
      "Epoch: 59/100... Training loss: 0.0975\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1050\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.0978\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0972\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.0973\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.0974\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.0965\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.0987\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.0970\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0973\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.0962\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.0953\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.0965\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.0987\n",
      "Epoch: 59/100... Training loss: 0.0972\n",
      "Epoch: 59/100... Training loss: 0.0973\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.0972\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0987\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.0960\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.0975\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.0973\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.0979\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.0975\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100... Training loss: 0.0972\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.0959\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.0969\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.0973\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.0972\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.0963\n",
      "Epoch: 59/100... Training loss: 0.0952\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.0963\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1059\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0962\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.0960\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.0972\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.0963\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.0962\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.0950\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.0956\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.0968\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.0953\n",
      "Epoch: 59/100... Training loss: 0.0987\n",
      "Epoch: 59/100... Training loss: 0.0956\n",
      "Epoch: 59/100... Training loss: 0.0951\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.0947\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.0962\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0971\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.0969\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0964\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.0961\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.0953\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.0969\n",
      "Epoch: 60/100... Training loss: 0.0976\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.0968\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.0981\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.0961\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0977\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.0973\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.0954\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.0976\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.0965\n",
      "Epoch: 60/100... Training loss: 0.0953\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0958\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.0970\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.0975\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.0976\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.0984\n",
      "Epoch: 60/100... Training loss: 0.0977\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.0972\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0974\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.0967\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.0976\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.0956\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.0979\n",
      "Epoch: 60/100... Training loss: 0.0969\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.0970\n",
      "Epoch: 60/100... Training loss: 0.0966\n",
      "Epoch: 60/100... Training loss: 0.0973\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.0981\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0962\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0968\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.0949\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.0970\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.0978\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.0964\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0960\n",
      "Epoch: 60/100... Training loss: 0.0965\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0968\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0970\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.0977\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.0945\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.0977\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.0975\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0981\n",
      "Epoch: 60/100... Training loss: 0.0964\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.0969\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.0953\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0965\n",
      "Epoch: 60/100... Training loss: 0.0984\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.0956\n",
      "Epoch: 60/100... Training loss: 0.0984\n",
      "Epoch: 60/100... Training loss: 0.0959\n",
      "Epoch: 60/100... Training loss: 0.0981\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0979\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.0937\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0975\n",
      "Epoch: 60/100... Training loss: 0.0965\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.0973\n",
      "Epoch: 60/100... Training loss: 0.0981\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.0967\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0977\n",
      "Epoch: 60/100... Training loss: 0.0981\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.0979\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.0981\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0963\n",
      "Epoch: 60/100... Training loss: 0.0979\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.0942\n",
      "Epoch: 61/100... Training loss: 0.0974\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.0976\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0946\n",
      "Epoch: 61/100... Training loss: 0.0984\n",
      "Epoch: 61/100... Training loss: 0.0979\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0991\n",
      "Epoch: 61/100... Training loss: 0.0951\n",
      "Epoch: 61/100... Training loss: 0.0956\n",
      "Epoch: 61/100... Training loss: 0.0985\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.0964\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0975\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0968\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.0959\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.0967\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0966\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.0959\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.0953\n",
      "Epoch: 61/100... Training loss: 0.0966\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0978\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.0988\n",
      "Epoch: 61/100... Training loss: 0.0961\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.0979\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.0984\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.0959\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0985\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0988\n",
      "Epoch: 61/100... Training loss: 0.0968\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.0976\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.0967\n",
      "Epoch: 61/100... Training loss: 0.0971\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0979\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.0991\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.0973\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.0963\n",
      "Epoch: 61/100... Training loss: 0.0960\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.0976\n",
      "Epoch: 61/100... Training loss: 0.0960\n",
      "Epoch: 61/100... Training loss: 0.0973\n",
      "Epoch: 61/100... Training loss: 0.0991\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.1046\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.0975\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.0973\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0985\n",
      "Epoch: 61/100... Training loss: 0.0955\n",
      "Epoch: 61/100... Training loss: 0.0969\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.0978\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.0978\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.0978\n",
      "Epoch: 61/100... Training loss: 0.0950\n",
      "Epoch: 61/100... Training loss: 0.0988\n",
      "Epoch: 61/100... Training loss: 0.0967\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0973\n",
      "Epoch: 61/100... Training loss: 0.0988\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.0975\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.0975\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.0964\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0955\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.0974\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.0969\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.0970\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.0975\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0969\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100... Training loss: 0.0975\n",
      "Epoch: 61/100... Training loss: 0.0974\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.0973\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.0963\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0976\n",
      "Epoch: 61/100... Training loss: 0.0966\n",
      "Epoch: 61/100... Training loss: 0.0979\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.0985\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.0970\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.0985\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.0966\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.0954\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.0968\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.0984\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.0968\n",
      "Epoch: 61/100... Training loss: 0.0974\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.0955\n",
      "Epoch: 61/100... Training loss: 0.0993\n",
      "Epoch: 61/100... Training loss: 0.0950\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.0945\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0978\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.0966\n",
      "Epoch: 61/100... Training loss: 0.0970\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.0964\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.0971\n",
      "Epoch: 61/100... Training loss: 0.0961\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1054\n",
      "Epoch: 61/100... Training loss: 0.0946\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0985\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.0968\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.0963\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.0960\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0964\n",
      "Epoch: 61/100... Training loss: 0.0970\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.0988\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.0977\n",
      "Epoch: 62/100... Training loss: 0.0983\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0963\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.0977\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.0973\n",
      "Epoch: 62/100... Training loss: 0.0979\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.0984\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.0968\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.0968\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.0974\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.0968\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.0970\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.0963\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.0955\n",
      "Epoch: 62/100... Training loss: 0.0974\n",
      "Epoch: 62/100... Training loss: 0.0967\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.0969\n",
      "Epoch: 62/100... Training loss: 0.0961\n",
      "Epoch: 62/100... Training loss: 0.0985\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.0975\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.0964\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0966\n",
      "Epoch: 62/100... Training loss: 0.0977\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.0958\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.0985\n",
      "Epoch: 62/100... Training loss: 0.0968\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.0973\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.0979\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0969\n",
      "Epoch: 62/100... Training loss: 0.0980\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0984\n",
      "Epoch: 62/100... Training loss: 0.0949\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1036\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.0966\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.0960\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.0971\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.0965\n",
      "Epoch: 62/100... Training loss: 0.1054\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0980\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.0951\n",
      "Epoch: 62/100... Training loss: 0.0983\n",
      "Epoch: 62/100... Training loss: 0.0983\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.0984\n",
      "Epoch: 62/100... Training loss: 0.0962\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.0967\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.0966\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1054\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.0973\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.0985\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.0980\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.0973\n",
      "Epoch: 62/100... Training loss: 0.0971\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.0965\n",
      "Epoch: 62/100... Training loss: 0.0963\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.0984\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.0974\n",
      "Epoch: 62/100... Training loss: 0.0957\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.0951\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.0974\n",
      "Epoch: 62/100... Training loss: 0.0970\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.0983\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.0973\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0980\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0967\n",
      "Epoch: 62/100... Training loss: 0.0975\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.0960\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.0975\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.0985\n",
      "Epoch: 62/100... Training loss: 0.1039\n",
      "Epoch: 62/100... Training loss: 0.0979\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0952\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.0984\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.0983\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0972\n",
      "Epoch: 62/100... Training loss: 0.0975\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.0981\n",
      "Epoch: 62/100... Training loss: 0.0971\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0973\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.0965\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0959\n",
      "Epoch: 62/100... Training loss: 0.0965\n",
      "Epoch: 62/100... Training loss: 0.0948\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0982\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.0974\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.0970\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0977\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.0941\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.0963\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0965\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.0977\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.0971\n",
      "Epoch: 63/100... Training loss: 0.0970\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.0981\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.0955\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100... Training loss: 0.0975\n",
      "Epoch: 63/100... Training loss: 0.0989\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.0972\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.0967\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.0966\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0963\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.0972\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.0958\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.0968\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0973\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0965\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.0962\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.0975\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0952\n",
      "Epoch: 63/100... Training loss: 0.0981\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.0973\n",
      "Epoch: 63/100... Training loss: 0.0960\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0973\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.0957\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0964\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0971\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0958\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0944\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.0967\n",
      "Epoch: 63/100... Training loss: 0.0969\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0953\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0966\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0969\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.0971\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.0989\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.0967\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0967\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0956\n",
      "Epoch: 63/100... Training loss: 0.0968\n",
      "Epoch: 63/100... Training loss: 0.0959\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0968\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.0964\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0955\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0949\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0977\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.0964\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.0979\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0973\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.0977\n",
      "Epoch: 63/100... Training loss: 0.0989\n",
      "Epoch: 63/100... Training loss: 0.0957\n",
      "Epoch: 63/100... Training loss: 0.0965\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.0965\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.1033\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.0989\n",
      "Epoch: 63/100... Training loss: 0.0970\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0967\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.0970\n",
      "Epoch: 63/100... Training loss: 0.1038\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0968\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.0955\n",
      "Epoch: 63/100... Training loss: 0.0962\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.0970\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0969\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.0975\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.0969\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.0961\n",
      "Epoch: 63/100... Training loss: 0.0956\n",
      "Epoch: 63/100... Training loss: 0.0966\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.0954\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.0960\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.0988\n",
      "Epoch: 64/100... Training loss: 0.0968\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.0970\n",
      "Epoch: 64/100... Training loss: 0.0988\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0971\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.0959\n",
      "Epoch: 64/100... Training loss: 0.0972\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.0973\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0965\n",
      "Epoch: 64/100... Training loss: 0.0978\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.0974\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.0976\n",
      "Epoch: 64/100... Training loss: 0.0961\n",
      "Epoch: 64/100... Training loss: 0.0953\n",
      "Epoch: 64/100... Training loss: 0.0971\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0973\n",
      "Epoch: 64/100... Training loss: 0.0978\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0969\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0962\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0974\n",
      "Epoch: 64/100... Training loss: 0.0953\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0972\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.0948\n",
      "Epoch: 64/100... Training loss: 0.0958\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0963\n",
      "Epoch: 64/100... Training loss: 0.0988\n",
      "Epoch: 64/100... Training loss: 0.0971\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.0976\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.0962\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0959\n",
      "Epoch: 64/100... Training loss: 0.0988\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.0963\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0975\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.0978\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.0973\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.0953\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.0956\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0971\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0965\n",
      "Epoch: 64/100... Training loss: 0.0958\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100... Training loss: 0.0988\n",
      "Epoch: 64/100... Training loss: 0.0956\n",
      "Epoch: 64/100... Training loss: 0.0988\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0970\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.0972\n",
      "Epoch: 64/100... Training loss: 0.0975\n",
      "Epoch: 64/100... Training loss: 0.0971\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.0953\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0978\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.0973\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.0971\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.0965\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0968\n",
      "Epoch: 64/100... Training loss: 0.0970\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0978\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.0963\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.0974\n",
      "Epoch: 64/100... Training loss: 0.0965\n",
      "Epoch: 64/100... Training loss: 0.0962\n",
      "Epoch: 64/100... Training loss: 0.0959\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0964\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.0956\n",
      "Epoch: 64/100... Training loss: 0.0973\n",
      "Epoch: 64/100... Training loss: 0.0976\n",
      "Epoch: 64/100... Training loss: 0.0968\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.0964\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.0969\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.0977\n",
      "Epoch: 64/100... Training loss: 0.0963\n",
      "Epoch: 64/100... Training loss: 0.0972\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0963\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.0957\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.0988\n",
      "Epoch: 64/100... Training loss: 0.0958\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.0973\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0988\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0965\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.0976\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0970\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0966\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.0971\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0964\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0970\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.0954\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.0964\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.0975\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.0983\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.0973\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0958\n",
      "Epoch: 65/100... Training loss: 0.0977\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0970\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0975\n",
      "Epoch: 65/100... Training loss: 0.0970\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.0970\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0967\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.0945\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0968\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0964\n",
      "Epoch: 65/100... Training loss: 0.0972\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.0963\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.0969\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0975\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0983\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.0974\n",
      "Epoch: 65/100... Training loss: 0.0957\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.0964\n",
      "Epoch: 65/100... Training loss: 0.0970\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.0965\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0953\n",
      "Epoch: 65/100... Training loss: 0.0975\n",
      "Epoch: 65/100... Training loss: 0.0963\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0970\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0961\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0974\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.0950\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0963\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0970\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.0972\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0956\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0968\n",
      "Epoch: 65/100... Training loss: 0.1055\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1038\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.0951\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0953\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.0964\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0977\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.0965\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.0962\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.0966\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0959\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0956\n",
      "Epoch: 65/100... Training loss: 0.0975\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.0970\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0951\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.0968\n",
      "Epoch: 65/100... Training loss: 0.0969\n",
      "Epoch: 65/100... Training loss: 0.0962\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0970\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.0983\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0958\n",
      "Epoch: 65/100... Training loss: 0.0954\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0960\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0963\n",
      "Epoch: 65/100... Training loss: 0.0957\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.0952\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0977\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.0961\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.0955\n",
      "Epoch: 65/100... Training loss: 0.0975\n",
      "Epoch: 65/100... Training loss: 0.0983\n",
      "Epoch: 65/100... Training loss: 0.0953\n",
      "Epoch: 65/100... Training loss: 0.0966\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.0954\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0946\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.0982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0973\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0962\n",
      "Epoch: 65/100... Training loss: 0.0970\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.0960\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.0962\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.0959\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.0958\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.0955\n",
      "Epoch: 66/100... Training loss: 0.0969\n",
      "Epoch: 66/100... Training loss: 0.0963\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0963\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0975\n",
      "Epoch: 66/100... Training loss: 0.0968\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.0973\n",
      "Epoch: 66/100... Training loss: 0.0970\n",
      "Epoch: 66/100... Training loss: 0.0961\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.0985\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0973\n",
      "Epoch: 66/100... Training loss: 0.0975\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.0949\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0965\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0969\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.0955\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0968\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.0985\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.0975\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0958\n",
      "Epoch: 66/100... Training loss: 0.0974\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.0958\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.0968\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0970\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.0950\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.0971\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.0968\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1046\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0950\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.0956\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0957\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0970\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.0971\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.0963\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.0975\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0954\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.0961\n",
      "Epoch: 66/100... Training loss: 0.0954\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0964\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.0964\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.0943\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.0969\n",
      "Epoch: 66/100... Training loss: 0.0975\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.0970\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.0971\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.0962\n",
      "Epoch: 66/100... Training loss: 0.0952\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.0957\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.0975\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.0970\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0959\n",
      "Epoch: 66/100... Training loss: 0.0948\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0967\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.0980\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0980\n",
      "Epoch: 66/100... Training loss: 0.0985\n",
      "Epoch: 66/100... Training loss: 0.0961\n",
      "Epoch: 66/100... Training loss: 0.0964\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.0966\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0969\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0966\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.0970\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0974\n",
      "Epoch: 67/100... Training loss: 0.0962\n",
      "Epoch: 67/100... Training loss: 0.0955\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0974\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.0961\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1024\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.0965\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.0942\n",
      "Epoch: 67/100... Training loss: 0.0956\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0970\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.0961\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.0983\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.0952\n",
      "Epoch: 67/100... Training loss: 0.0974\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.0950\n",
      "Epoch: 67/100... Training loss: 0.0983\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.0974\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.0954\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.0942\n",
      "Epoch: 67/100... Training loss: 0.0955\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.0961\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.0971\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1024\n",
      "Epoch: 67/100... Training loss: 0.0964\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.0969\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.0957\n",
      "Epoch: 67/100... Training loss: 0.0953\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.0967\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1024\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.0968\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.0969\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.0968\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.0968\n",
      "Epoch: 67/100... Training loss: 0.0962\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.0970\n",
      "Epoch: 67/100... Training loss: 0.0960\n",
      "Epoch: 67/100... Training loss: 0.0962\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.0969\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.0983\n",
      "Epoch: 67/100... Training loss: 0.1042\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0966\n",
      "Epoch: 67/100... Training loss: 0.0961\n",
      "Epoch: 67/100... Training loss: 0.0968\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.0968\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0974\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.0958\n",
      "Epoch: 67/100... Training loss: 0.0968\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.0955\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.0960\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.0960\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.0970\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.0963\n",
      "Epoch: 67/100... Training loss: 0.0967\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0965\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.0954\n",
      "Epoch: 67/100... Training loss: 0.0974\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.0947\n",
      "Epoch: 67/100... Training loss: 0.0963\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0940\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.0983\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.0965\n",
      "Epoch: 67/100... Training loss: 0.0962\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0971\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0965\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0960\n",
      "Epoch: 68/100... Training loss: 0.0957\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.0970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0972\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.0960\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0963\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0956\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0946\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.0930\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0970\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0962\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0965\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.0959\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.0963\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0976\n",
      "Epoch: 68/100... Training loss: 0.0949\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0958\n",
      "Epoch: 68/100... Training loss: 0.0963\n",
      "Epoch: 68/100... Training loss: 0.1051\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.0960\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.0967\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0968\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.0967\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.0968\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.0941\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.0963\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.0973\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.0956\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.0974\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0952\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0971\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0954\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.0962\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0962\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.0963\n",
      "Epoch: 68/100... Training loss: 0.0960\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1036\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.0976\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.0976\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0972\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0966\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.0953\n",
      "Epoch: 68/100... Training loss: 0.0966\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.0979\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.0973\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.0971\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.0974\n",
      "Epoch: 68/100... Training loss: 0.0947\n",
      "Epoch: 68/100... Training loss: 0.0974\n",
      "Epoch: 68/100... Training loss: 0.0993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0974\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.0968\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.0950\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.0946\n",
      "Epoch: 68/100... Training loss: 0.0962\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0961\n",
      "Epoch: 68/100... Training loss: 0.0963\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0976\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0965\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.0972\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0958\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0973\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0964\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0985\n",
      "Epoch: 69/100... Training loss: 0.0975\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0960\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.0949\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0985\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0935\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.0952\n",
      "Epoch: 69/100... Training loss: 0.0968\n",
      "Epoch: 69/100... Training loss: 0.0971\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0954\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.0943\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.0975\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.0957\n",
      "Epoch: 69/100... Training loss: 0.0957\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0960\n",
      "Epoch: 69/100... Training loss: 0.0951\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.0974\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.0952\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0956\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.0972\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.0955\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0972\n",
      "Epoch: 69/100... Training loss: 0.0969\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.1054\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0968\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0951\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.0964\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.0959\n",
      "Epoch: 69/100... Training loss: 0.0964\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.0946\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.0975\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0972\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0972\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100... Training loss: 0.0945\n",
      "Epoch: 69/100... Training loss: 0.0972\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0942\n",
      "Epoch: 69/100... Training loss: 0.0954\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0966\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0964\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0941\n",
      "Epoch: 69/100... Training loss: 0.0957\n",
      "Epoch: 69/100... Training loss: 0.0972\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0956\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0969\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.0971\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0974\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.0937\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.0956\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.0971\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.0942\n",
      "Epoch: 69/100... Training loss: 0.0967\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.0953\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.0967\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0959\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.0948\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.0967\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0965\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0934\n",
      "Epoch: 69/100... Training loss: 0.0985\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0971\n",
      "Epoch: 69/100... Training loss: 0.0975\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.0972\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.0964\n",
      "Epoch: 69/100... Training loss: 0.0967\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0956\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.0942\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.0960\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0985\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.0975\n",
      "Epoch: 69/100... Training loss: 0.0962\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0966\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0970\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0969\n",
      "Epoch: 69/100... Training loss: 0.0974\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0949\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0947\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.0951\n",
      "Epoch: 69/100... Training loss: 0.0974\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0964\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0974\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.0966\n",
      "Epoch: 70/100... Training loss: 0.0962\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.0965\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.0971\n",
      "Epoch: 70/100... Training loss: 0.0927\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0978\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0966\n",
      "Epoch: 70/100... Training loss: 0.0968\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.0978\n",
      "Epoch: 70/100... Training loss: 0.0961\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.0945\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0964\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0953\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0960\n",
      "Epoch: 70/100... Training loss: 0.0979\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0961\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0958\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.0965\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.0974\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0979\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0968\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0972\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0962\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.0974\n",
      "Epoch: 70/100... Training loss: 0.0958\n",
      "Epoch: 70/100... Training loss: 0.0962\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0978\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0957\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.0979\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.0971\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0948\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0968\n",
      "Epoch: 70/100... Training loss: 0.0971\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.0958\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.0953\n",
      "Epoch: 70/100... Training loss: 0.0958\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.0949\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.0968\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0966\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0953\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.0966\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0952\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.0968\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0964\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100... Training loss: 0.0972\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.0969\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.0978\n",
      "Epoch: 70/100... Training loss: 0.0974\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0960\n",
      "Epoch: 70/100... Training loss: 0.0958\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0950\n",
      "Epoch: 70/100... Training loss: 0.0959\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1038\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0965\n",
      "Epoch: 70/100... Training loss: 0.0978\n",
      "Epoch: 70/100... Training loss: 0.0979\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.0972\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0965\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.0973\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.0962\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.0968\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0968\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0950\n",
      "Epoch: 71/100... Training loss: 0.0941\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0958\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.0963\n",
      "Epoch: 71/100... Training loss: 0.0962\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0966\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.0955\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0945\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0960\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0964\n",
      "Epoch: 71/100... Training loss: 0.0959\n",
      "Epoch: 71/100... Training loss: 0.0967\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.0965\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0960\n",
      "Epoch: 71/100... Training loss: 0.0923\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0969\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.0951\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0954\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0957\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0963\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0962\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.0968\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.0925\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.0941\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0959\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0971\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0989\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.0989\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0943\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.0966\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0951\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0964\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.0956\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0962\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.0989\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.0953\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.0957\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.0948\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.0967\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.0974\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.0954\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.0954\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0968\n",
      "Epoch: 71/100... Training loss: 0.0942\n",
      "Epoch: 71/100... Training loss: 0.0935\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0953\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.0946\n",
      "Epoch: 71/100... Training loss: 0.0964\n",
      "Epoch: 71/100... Training loss: 0.0967\n",
      "Epoch: 71/100... Training loss: 0.0966\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0944\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.0955\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0939\n",
      "Epoch: 72/100... Training loss: 0.0961\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.1039\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.0959\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.0973\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.0975\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0969\n",
      "Epoch: 72/100... Training loss: 0.0949\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.1036\n",
      "Epoch: 72/100... Training loss: 0.0969\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.0967\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.0950\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.0956\n",
      "Epoch: 72/100... Training loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0970\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0944\n",
      "Epoch: 72/100... Training loss: 0.0960\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0973\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0946\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0968\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0975\n",
      "Epoch: 72/100... Training loss: 0.0977\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.0969\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.0963\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.0966\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0961\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.0967\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0957\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.0967\n",
      "Epoch: 72/100... Training loss: 0.1044\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.0965\n",
      "Epoch: 72/100... Training loss: 0.0970\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.0966\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0956\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0956\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0967\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0977\n",
      "Epoch: 72/100... Training loss: 0.0965\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.0955\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0968\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0967\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.0968\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0941\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.0959\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.0943\n",
      "Epoch: 72/100... Training loss: 0.0958\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.0964\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.0954\n",
      "Epoch: 72/100... Training loss: 0.0966\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.0969\n",
      "Epoch: 72/100... Training loss: 0.0970\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0973\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.0969\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0975\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.0964\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0955\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.0969\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.0954\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0949\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.0940\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0970\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0945\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.0965\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0957\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0980\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.0961\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.0963\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.0963\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0969\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.0963\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.0951\n",
      "Epoch: 73/100... Training loss: 0.0959\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0946\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0959\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.0949\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.0966\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.0947\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.0966\n",
      "Epoch: 73/100... Training loss: 0.0963\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0952\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0965\n",
      "Epoch: 73/100... Training loss: 0.0969\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0947\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.0952\n",
      "Epoch: 73/100... Training loss: 0.1009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100... Training loss: 0.0965\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.0962\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0949\n",
      "Epoch: 73/100... Training loss: 0.0946\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.0964\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0962\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0966\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0953\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0964\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0970\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0970\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.0963\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.0973\n",
      "Epoch: 73/100... Training loss: 0.0961\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.0959\n",
      "Epoch: 73/100... Training loss: 0.0965\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.0960\n",
      "Epoch: 73/100... Training loss: 0.0966\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.0962\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0959\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.0968\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0962\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0960\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.0969\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0958\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.0960\n",
      "Epoch: 74/100... Training loss: 0.0948\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0954\n",
      "Epoch: 74/100... Training loss: 0.0957\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.0964\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0967\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.0947\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.0959\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0953\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.0962\n",
      "Epoch: 74/100... Training loss: 0.0964\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0968\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0965\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.0944\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.0965\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.0977\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0951\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0948\n",
      "Epoch: 74/100... Training loss: 0.0965\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1035\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.0963\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0977\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.0961\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.0958\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0977\n",
      "Epoch: 74/100... Training loss: 0.0957\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.0963\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0952\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0958\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0964\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.0958\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0962\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.1037\n",
      "Epoch: 74/100... Training loss: 0.0968\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.0941\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0967\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0968\n",
      "Epoch: 74/100... Training loss: 0.0961\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0964\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.0962\n",
      "Epoch: 74/100... Training loss: 0.0951\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.0968\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0963\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.0965\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0953\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.0963\n",
      "Epoch: 74/100... Training loss: 0.0963\n",
      "Epoch: 74/100... Training loss: 0.1034\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0959\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.0960\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0961\n",
      "Epoch: 74/100... Training loss: 0.0948\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0977\n",
      "Epoch: 74/100... Training loss: 0.0938\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0959\n",
      "Epoch: 74/100... Training loss: 0.0964\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0934\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.0962\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.0958\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.0965\n",
      "Epoch: 75/100... Training loss: 0.0958\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0975\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.0979\n",
      "Epoch: 75/100... Training loss: 0.0963\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.0979\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0953\n",
      "Epoch: 75/100... Training loss: 0.0972\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0957\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0960\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0955\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.0972\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.0976\n",
      "Epoch: 75/100... Training loss: 0.0966\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0963\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0962\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0966\n",
      "Epoch: 75/100... Training loss: 0.0962\n",
      "Epoch: 75/100... Training loss: 0.0958\n",
      "Epoch: 75/100... Training loss: 0.0959\n",
      "Epoch: 75/100... Training loss: 0.0965\n",
      "Epoch: 75/100... Training loss: 0.0972\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0967\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.0961\n",
      "Epoch: 75/100... Training loss: 0.0948\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.0966\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1038\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.0960\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.0963\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0972\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0964\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.0960\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.0957\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.0957\n",
      "Epoch: 75/100... Training loss: 0.0967\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0981\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0967\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0970\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.0972\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.0970\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.0952\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.0970\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.0952\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0976\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0981\n",
      "Epoch: 75/100... Training loss: 0.0972\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.0979\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0972\n",
      "Epoch: 75/100... Training loss: 0.0961\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.1040\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.0981\n",
      "Epoch: 75/100... Training loss: 0.0945\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0967\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.0966\n",
      "Epoch: 75/100... Training loss: 0.0965\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0964\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0972\n",
      "Epoch: 75/100... Training loss: 0.0964\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0962\n",
      "Epoch: 75/100... Training loss: 0.0960\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.0981\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.0962\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.0966\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0969\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.0966\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0958\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0968\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0953\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0950\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.1043\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1046\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.0968\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0962\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0942\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0966\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0959\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.0958\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0966\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0973\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.0936\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.0969\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.1028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100... Training loss: 0.0961\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0952\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0962\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.0969\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.0961\n",
      "Epoch: 76/100... Training loss: 0.0964\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0968\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0957\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0965\n",
      "Epoch: 76/100... Training loss: 0.0963\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0958\n",
      "Epoch: 76/100... Training loss: 0.0955\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0948\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.0958\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.0969\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0957\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.0947\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0962\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.0954\n",
      "Epoch: 76/100... Training loss: 0.0968\n",
      "Epoch: 76/100... Training loss: 0.0968\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.0959\n",
      "Epoch: 76/100... Training loss: 0.0968\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0966\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0924\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0937\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0961\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.0960\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0963\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0960\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0969\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0939\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0942\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0970\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0971\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.0975\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.0970\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1037\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0970\n",
      "Epoch: 77/100... Training loss: 0.0964\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0975\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.0957\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0964\n",
      "Epoch: 77/100... Training loss: 0.0971\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.0958\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0964\n",
      "Epoch: 77/100... Training loss: 0.0954\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0961\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0969\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0962\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1041\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0969\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0955\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.0965\n",
      "Epoch: 77/100... Training loss: 0.0959\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0945\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0961\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0971\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0969\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0970\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0961\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.0964\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1031\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0970\n",
      "Epoch: 77/100... Training loss: 0.0954\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.0945\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0961\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0951\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0952\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.0959\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.0958\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0975\n",
      "Epoch: 77/100... Training loss: 0.0958\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0963\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0971\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0975\n",
      "Epoch: 77/100... Training loss: 0.0963\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0959\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0967\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0962\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0955\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0969\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0966\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.0957\n",
      "Epoch: 77/100... Training loss: 0.0968\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0947\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.0975\n",
      "Epoch: 77/100... Training loss: 0.0971\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0952\n",
      "Epoch: 77/100... Training loss: 0.0957\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0970\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0964\n",
      "Epoch: 77/100... Training loss: 0.0949\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.0955\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0967\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0944\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0946\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.0963\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.0959\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0971\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0968\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0965\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0960\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0947\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.0972\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.0957\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0963\n",
      "Epoch: 78/100... Training loss: 0.0965\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.0944\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0942\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0956\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.0961\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0966\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0960\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.0938\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.0967\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0961\n",
      "Epoch: 78/100... Training loss: 0.0958\n",
      "Epoch: 78/100... Training loss: 0.0958\n",
      "Epoch: 78/100... Training loss: 0.0954\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0959\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0963\n",
      "Epoch: 78/100... Training loss: 0.0963\n",
      "Epoch: 78/100... Training loss: 0.0960\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0972\n",
      "Epoch: 78/100... Training loss: 0.0947\n",
      "Epoch: 78/100... Training loss: 0.0950\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.0957\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.0960\n",
      "Epoch: 78/100... Training loss: 0.0937\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0965\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1033\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0968\n",
      "Epoch: 78/100... Training loss: 0.0947\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.0961\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0953\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0968\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0968\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0965\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0949\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.0965\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.1033\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0966\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.0963\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.0972\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0957\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0954\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0955\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.0953\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0971\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.0959\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0972\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0931\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.0947\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.0965\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.0972\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0975\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0972\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0952\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0961\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0969\n",
      "Epoch: 79/100... Training loss: 0.0970\n",
      "Epoch: 79/100... Training loss: 0.0948\n",
      "Epoch: 79/100... Training loss: 0.0967\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0959\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.0963\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0964\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0972\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.0955\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0947\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0970\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0956\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0968\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0960\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0968\n",
      "Epoch: 79/100... Training loss: 0.1033\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.0951\n",
      "Epoch: 79/100... Training loss: 0.0951\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0944\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0968\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0957\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0958\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.0962\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0967\n",
      "Epoch: 79/100... Training loss: 0.0960\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0956\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0960\n",
      "Epoch: 79/100... Training loss: 0.0959\n",
      "Epoch: 79/100... Training loss: 0.0962\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.0926\n",
      "Epoch: 79/100... Training loss: 0.0954\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0950\n",
      "Epoch: 79/100... Training loss: 0.0968\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0966\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.0968\n",
      "Epoch: 79/100... Training loss: 0.0949\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0966\n",
      "Epoch: 79/100... Training loss: 0.0935\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.0967\n",
      "Epoch: 79/100... Training loss: 0.0972\n",
      "Epoch: 79/100... Training loss: 0.0963\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.0957\n",
      "Epoch: 79/100... Training loss: 0.0966\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.0953\n",
      "Epoch: 79/100... Training loss: 0.0975\n",
      "Epoch: 79/100... Training loss: 0.0964\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0970\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.0933\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.0941\n",
      "Epoch: 79/100... Training loss: 0.0969\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0953\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0963\n",
      "Epoch: 79/100... Training loss: 0.0975\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0957\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0967\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0943\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0956\n",
      "Epoch: 79/100... Training loss: 0.0964\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.0962\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0966\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.0942\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0972\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0959\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0945\n",
      "Epoch: 79/100... Training loss: 0.0966\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0967\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100... Training loss: 0.0962\n",
      "Epoch: 79/100... Training loss: 0.1048\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.0965\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0953\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0964\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0967\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0966\n",
      "Epoch: 80/100... Training loss: 0.0964\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0976\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0951\n",
      "Epoch: 80/100... Training loss: 0.0974\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0955\n",
      "Epoch: 80/100... Training loss: 0.0963\n",
      "Epoch: 80/100... Training loss: 0.0962\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1026\n",
      "Epoch: 80/100... Training loss: 0.0974\n",
      "Epoch: 80/100... Training loss: 0.0952\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.0956\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.0959\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0947\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0948\n",
      "Epoch: 80/100... Training loss: 0.0964\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0960\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0967\n",
      "Epoch: 80/100... Training loss: 0.0976\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.0931\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.0963\n",
      "Epoch: 80/100... Training loss: 0.0965\n",
      "Epoch: 80/100... Training loss: 0.0952\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.0965\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0965\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.0967\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.0974\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.0965\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.0938\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.0952\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0952\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0935\n",
      "Epoch: 80/100... Training loss: 0.0962\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0966\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.0958\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.0967\n",
      "Epoch: 80/100... Training loss: 0.0959\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0948\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0956\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0959\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.0965\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0969\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.0965\n",
      "Epoch: 80/100... Training loss: 0.0968\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0964\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.0940\n",
      "Epoch: 80/100... Training loss: 0.0960\n",
      "Epoch: 80/100... Training loss: 0.0961\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0964\n",
      "Epoch: 80/100... Training loss: 0.0974\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0961\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0963\n",
      "Epoch: 80/100... Training loss: 0.0964\n",
      "Epoch: 80/100... Training loss: 0.0968\n",
      "Epoch: 80/100... Training loss: 0.0947\n",
      "Epoch: 80/100... Training loss: 0.0963\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.0962\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.0962\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0968\n",
      "Epoch: 80/100... Training loss: 0.0937\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.0964\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.0949\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.0929\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0976\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0977\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0951\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0944\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.0962\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0964\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.0956\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.0946\n",
      "Epoch: 81/100... Training loss: 0.0959\n",
      "Epoch: 81/100... Training loss: 0.0965\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0954\n",
      "Epoch: 81/100... Training loss: 0.0956\n",
      "Epoch: 81/100... Training loss: 0.0955\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.0974\n",
      "Epoch: 81/100... Training loss: 0.0957\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0953\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.0963\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0956\n",
      "Epoch: 81/100... Training loss: 0.0965\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0966\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.0949\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.0957\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.0959\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.0993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0953\n",
      "Epoch: 81/100... Training loss: 0.0964\n",
      "Epoch: 81/100... Training loss: 0.0974\n",
      "Epoch: 81/100... Training loss: 0.0961\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0976\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1039\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0957\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0955\n",
      "Epoch: 81/100... Training loss: 0.0954\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0964\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0962\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.0950\n",
      "Epoch: 81/100... Training loss: 0.0945\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.0959\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.0963\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.0966\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.0963\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.0965\n",
      "Epoch: 81/100... Training loss: 0.0945\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.0959\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0945\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.0964\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0954\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.0945\n",
      "Epoch: 81/100... Training loss: 0.0949\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0961\n",
      "Epoch: 81/100... Training loss: 0.0976\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.0936\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.0957\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.0955\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0949\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.0970\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0961\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0963\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.0976\n",
      "Epoch: 81/100... Training loss: 0.0956\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0966\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0967\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.0959\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0947\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.0960\n",
      "Epoch: 81/100... Training loss: 0.0960\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0941\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0953\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0957\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.0967\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0945\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0967\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0958\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0974\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0967\n",
      "Epoch: 82/100... Training loss: 0.0953\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0967\n",
      "Epoch: 82/100... Training loss: 0.0968\n",
      "Epoch: 82/100... Training loss: 0.0973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0967\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0966\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.0958\n",
      "Epoch: 82/100... Training loss: 0.0935\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0954\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0975\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.0968\n",
      "Epoch: 82/100... Training loss: 0.0951\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0954\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0965\n",
      "Epoch: 82/100... Training loss: 0.0963\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0958\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0949\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0968\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.0967\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0954\n",
      "Epoch: 82/100... Training loss: 0.1032\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0958\n",
      "Epoch: 82/100... Training loss: 0.0961\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0962\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.0968\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0950\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0953\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.0961\n",
      "Epoch: 82/100... Training loss: 0.0961\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0951\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0958\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0975\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.0952\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0959\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.0953\n",
      "Epoch: 82/100... Training loss: 0.0943\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0969\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0968\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0950\n",
      "Epoch: 82/100... Training loss: 0.0967\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0960\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.0975\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0960\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.0957\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0974\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0951\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0951\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0960\n",
      "Epoch: 82/100... Training loss: 0.0942\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0968\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0963\n",
      "Epoch: 82/100... Training loss: 0.0954\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.0973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.0961\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0965\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.0955\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0949\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1043\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0962\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0968\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.0966\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0964\n",
      "Epoch: 82/100... Training loss: 0.0953\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.0947\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0967\n",
      "Epoch: 82/100... Training loss: 0.0975\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.0966\n",
      "Epoch: 82/100... Training loss: 0.0957\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1043\n",
      "Epoch: 83/100... Training loss: 0.0966\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.0957\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0958\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0964\n",
      "Epoch: 83/100... Training loss: 0.0964\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0956\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0937\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.0957\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0968\n",
      "Epoch: 83/100... Training loss: 0.0966\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.0957\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0928\n",
      "Epoch: 83/100... Training loss: 0.0954\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.0960\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.0974\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0961\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0948\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.0950\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0957\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0968\n",
      "Epoch: 83/100... Training loss: 0.0974\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0966\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.0956\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0963\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0961\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1033\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0956\n",
      "Epoch: 83/100... Training loss: 0.0961\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0957\n",
      "Epoch: 83/100... Training loss: 0.0938\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0946\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.0961\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0947\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0950\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.0957\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0961\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0946\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0957\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.0968\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0949\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.0956\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0940\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0956\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.0971\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.0955\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0964\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0949\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0942\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.0953\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0952\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.0974\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0955\n",
      "Epoch: 83/100... Training loss: 0.0953\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.0961\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0964\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.0943\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0936\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0966\n",
      "Epoch: 83/100... Training loss: 0.0971\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0951\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0964\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0953\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0965\n",
      "Epoch: 84/100... Training loss: 0.0951\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0951\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.0959\n",
      "Epoch: 84/100... Training loss: 0.0961\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0970\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0957\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0939\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0952\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0964\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0967\n",
      "Epoch: 84/100... Training loss: 0.0970\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0957\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0960\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.0969\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.0956\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0961\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0970\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0967\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0969\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0954\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0962\n",
      "Epoch: 84/100... Training loss: 0.0954\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0961\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0969\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0964\n",
      "Epoch: 84/100... Training loss: 0.0970\n",
      "Epoch: 84/100... Training loss: 0.0952\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0967\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.0960\n",
      "Epoch: 84/100... Training loss: 0.0967\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0962\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0962\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0960\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0964\n",
      "Epoch: 84/100... Training loss: 0.0961\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0965\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.1031\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0962\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0967\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.0945\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0965\n",
      "Epoch: 84/100... Training loss: 0.0951\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0967\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0969\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0961\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0958\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.0959\n",
      "Epoch: 84/100... Training loss: 0.0970\n",
      "Epoch: 84/100... Training loss: 0.0956\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.0951\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0962\n",
      "Epoch: 84/100... Training loss: 0.0960\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0949\n",
      "Epoch: 84/100... Training loss: 0.0959\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.0967\n",
      "Epoch: 84/100... Training loss: 0.0951\n",
      "Epoch: 84/100... Training loss: 0.0963\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.0969\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0959\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.0961\n",
      "Epoch: 84/100... Training loss: 0.0963\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.0962\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0960\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.0962\n",
      "Epoch: 84/100... Training loss: 0.0932\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0970\n",
      "Epoch: 84/100... Training loss: 0.0952\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0953\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.0953\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0958\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0954\n",
      "Epoch: 85/100... Training loss: 0.0957\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0951\n",
      "Epoch: 85/100... Training loss: 0.0944\n",
      "Epoch: 85/100... Training loss: 0.0951\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.1025\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0963\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.0954\n",
      "Epoch: 85/100... Training loss: 0.0959\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.0961\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0961\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0963\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0947\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.0950\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.0955\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0964\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0961\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0957\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.0964\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0961\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0953\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0964\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0964\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.0950\n",
      "Epoch: 85/100... Training loss: 0.0943\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.0949\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1025\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0963\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.0950\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0964\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0958\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0947\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.0951\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0953\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.0956\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.0956\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.0945\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1036\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.0950\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0948\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0963\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0965\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0965\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0949\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0958\n",
      "Epoch: 85/100... Training loss: 0.0962\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0950\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0959\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0959\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.0974\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0942\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.0957\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0965\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0945\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0963\n",
      "Epoch: 86/100... Training loss: 0.1035\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0973\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0958\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0959\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0953\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0962\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.0946\n",
      "Epoch: 86/100... Training loss: 0.0973\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.0950\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0965\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0963\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.1029\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.0965\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0955\n",
      "Epoch: 86/100... Training loss: 0.0969\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.0948\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0959\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.0938\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0958\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0956\n",
      "Epoch: 86/100... Training loss: 0.0973\n",
      "Epoch: 86/100... Training loss: 0.0963\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0961\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0966\n",
      "Epoch: 86/100... Training loss: 0.0969\n",
      "Epoch: 86/100... Training loss: 0.0930\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.0926\n",
      "Epoch: 86/100... Training loss: 0.0962\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.0966\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.0969\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0948\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0942\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0973\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0965\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.0948\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.0949\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.0973\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0965\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0950\n",
      "Epoch: 86/100... Training loss: 0.0962\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0972\n",
      "Epoch: 86/100... Training loss: 0.0953\n",
      "Epoch: 86/100... Training loss: 0.0955\n",
      "Epoch: 86/100... Training loss: 0.0942\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0957\n",
      "Epoch: 86/100... Training loss: 0.0972\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0957\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0950\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.0951\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0957\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0965\n",
      "Epoch: 86/100... Training loss: 0.0972\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0959\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.0965\n",
      "Epoch: 86/100... Training loss: 0.0961\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0972\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.0957\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.0951\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.1032\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100... Training loss: 0.0954\n",
      "Epoch: 87/100... Training loss: 0.0960\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.0962\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0931\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.0958\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0954\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.0953\n",
      "Epoch: 87/100... Training loss: 0.0962\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0965\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.0963\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0959\n",
      "Epoch: 87/100... Training loss: 0.0964\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0953\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0966\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0965\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0943\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0958\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1031\n",
      "Epoch: 87/100... Training loss: 0.0960\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0962\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0955\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0950\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0967\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0949\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.0977\n",
      "Epoch: 87/100... Training loss: 0.0956\n",
      "Epoch: 87/100... Training loss: 0.0962\n",
      "Epoch: 87/100... Training loss: 0.0944\n",
      "Epoch: 87/100... Training loss: 0.0967\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0965\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0955\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0966\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0962\n",
      "Epoch: 87/100... Training loss: 0.0951\n",
      "Epoch: 87/100... Training loss: 0.0961\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0945\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0953\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0977\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.0965\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0945\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0935\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.0946\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0955\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0966\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0954\n",
      "Epoch: 87/100... Training loss: 0.0928\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0959\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0959\n",
      "Epoch: 87/100... Training loss: 0.0967\n",
      "Epoch: 87/100... Training loss: 0.0959\n",
      "Epoch: 87/100... Training loss: 0.0963\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1044\n",
      "Epoch: 87/100... Training loss: 0.0958\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0962\n",
      "Epoch: 87/100... Training loss: 0.0949\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0966\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0956\n",
      "Epoch: 87/100... Training loss: 0.0955\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.0946\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0967\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0967\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1024\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0977\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0958\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0977\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.0967\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.0957\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0942\n",
      "Epoch: 87/100... Training loss: 0.0965\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0944\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.0967\n",
      "Epoch: 87/100... Training loss: 0.0950\n",
      "Epoch: 87/100... Training loss: 0.0962\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0961\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0962\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0962\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.0935\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0959\n",
      "Epoch: 88/100... Training loss: 0.0943\n",
      "Epoch: 88/100... Training loss: 0.0953\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.0958\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0959\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0942\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0943\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0936\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0954\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0940\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.0972\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0955\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.0970\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0970\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0948\n",
      "Epoch: 88/100... Training loss: 0.0948\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.0961\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0957\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.0961\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0946\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0954\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0924\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0957\n",
      "Epoch: 88/100... Training loss: 0.0983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0954\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0968\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0968\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0961\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0967\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.0956\n",
      "Epoch: 88/100... Training loss: 0.0942\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0961\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0957\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0942\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0972\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0962\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0951\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0970\n",
      "Epoch: 88/100... Training loss: 0.0949\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.0957\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0948\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0956\n",
      "Epoch: 88/100... Training loss: 0.0950\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0954\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.0962\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0961\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.0957\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0962\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0964\n",
      "Epoch: 88/100... Training loss: 0.0944\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0963\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0941\n",
      "Epoch: 88/100... Training loss: 0.0951\n",
      "Epoch: 88/100... Training loss: 0.0972\n",
      "Epoch: 88/100... Training loss: 0.0942\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.0961\n",
      "Epoch: 88/100... Training loss: 0.0942\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0956\n",
      "Epoch: 88/100... Training loss: 0.0972\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0951\n",
      "Epoch: 89/100... Training loss: 0.0964\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0950\n",
      "Epoch: 89/100... Training loss: 0.0962\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.0962\n",
      "Epoch: 89/100... Training loss: 0.0965\n",
      "Epoch: 89/100... Training loss: 0.0958\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0966\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.0950\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0970\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.0957\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0955\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0954\n",
      "Epoch: 89/100... Training loss: 0.0949\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0945\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0960\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.0964\n",
      "Epoch: 89/100... Training loss: 0.0966\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.0943\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0954\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.0955\n",
      "Epoch: 89/100... Training loss: 0.1044\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0962\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0959\n",
      "Epoch: 89/100... Training loss: 0.0958\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0948\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0970\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0958\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0960\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.0957\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0965\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0944\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0953\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.0941\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0965\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0952\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0981\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0952\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0961\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0948\n",
      "Epoch: 89/100... Training loss: 0.0944\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0981\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0921\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0956\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0964\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0950\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0958\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.0942\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0961\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0961\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0947\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0970\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0963\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.0959\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0951\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0948\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0952\n",
      "Epoch: 89/100... Training loss: 0.0949\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0962\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0955\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.0958\n",
      "Epoch: 89/100... Training loss: 0.0970\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0945\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0964\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0967\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.0954\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0947\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.0964\n",
      "Epoch: 90/100... Training loss: 0.0953\n",
      "Epoch: 90/100... Training loss: 0.0964\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.0955\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.0955\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0957\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0959\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0958\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.0964\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0958\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0958\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0964\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0957\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0947\n",
      "Epoch: 90/100... Training loss: 0.1035\n",
      "Epoch: 90/100... Training loss: 0.0963\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.0956\n",
      "Epoch: 90/100... Training loss: 0.0956\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0961\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.0964\n",
      "Epoch: 90/100... Training loss: 0.0967\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.0944\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0953\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.0974\n",
      "Epoch: 90/100... Training loss: 0.0957\n",
      "Epoch: 90/100... Training loss: 0.0943\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.0974\n",
      "Epoch: 90/100... Training loss: 0.0954\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0947\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0956\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0961\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0959\n",
      "Epoch: 90/100... Training loss: 0.0962\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0949\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.0962\n",
      "Epoch: 90/100... Training loss: 0.0950\n",
      "Epoch: 90/100... Training loss: 0.0964\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0951\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.1017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.0961\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0959\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0941\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0956\n",
      "Epoch: 90/100... Training loss: 0.0962\n",
      "Epoch: 90/100... Training loss: 0.0962\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0954\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0957\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0956\n",
      "Epoch: 90/100... Training loss: 0.0960\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.0918\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0961\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0937\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0963\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0946\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0963\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0958\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0951\n",
      "Epoch: 90/100... Training loss: 0.0974\n",
      "Epoch: 90/100... Training loss: 0.0952\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0951\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0931\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0963\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0938\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.0967\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0967\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.0964\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0949\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.0953\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0958\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.0953\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0964\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0952\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.0964\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.0960\n",
      "Epoch: 91/100... Training loss: 0.0953\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.0945\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.0962\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0963\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0958\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0972\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0953\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.0959\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0943\n",
      "Epoch: 91/100... Training loss: 0.0957\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0957\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0962\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0960\n",
      "Epoch: 91/100... Training loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1031\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0972\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0957\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.0961\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0958\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.0972\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.0956\n",
      "Epoch: 91/100... Training loss: 0.0948\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.0962\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0958\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0955\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0972\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.0964\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0945\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0963\n",
      "Epoch: 91/100... Training loss: 0.0963\n",
      "Epoch: 91/100... Training loss: 0.0953\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1036\n",
      "Epoch: 91/100... Training loss: 0.0946\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0953\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.0931\n",
      "Epoch: 91/100... Training loss: 0.0963\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0943\n",
      "Epoch: 91/100... Training loss: 0.0963\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0939\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.0933\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.0972\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0964\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0958\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0955\n",
      "Epoch: 91/100... Training loss: 0.0953\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0960\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0945\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.0962\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0956\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1033\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0939\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.0964\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0963\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0949\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0956\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0962\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0963\n",
      "Epoch: 91/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0954\n",
      "Epoch: 91/100... Training loss: 0.0955\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0963\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0953\n",
      "Epoch: 91/100... Training loss: 0.0949\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0955\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0949\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0957\n",
      "Epoch: 92/100... Training loss: 0.0950\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0958\n",
      "Epoch: 92/100... Training loss: 0.0957\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0968\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.0957\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0966\n",
      "Epoch: 92/100... Training loss: 0.0964\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.0941\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0959\n",
      "Epoch: 92/100... Training loss: 0.0949\n",
      "Epoch: 92/100... Training loss: 0.0965\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0966\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0948\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0964\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0961\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0969\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0940\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0963\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0965\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0959\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0964\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0959\n",
      "Epoch: 92/100... Training loss: 0.0952\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0948\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0964\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.0950\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0956\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.0942\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0959\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0952\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0959\n",
      "Epoch: 92/100... Training loss: 0.0961\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0954\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.0931\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0964\n",
      "Epoch: 92/100... Training loss: 0.0968\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0957\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0963\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0949\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0953\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0965\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0963\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0956\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0965\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0965\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0966\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0965\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0965\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0968\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.1033\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.0969\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0945\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0971\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0969\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0948\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0969\n",
      "Epoch: 92/100... Training loss: 0.0946\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0946\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0961\n",
      "Epoch: 93/100... Training loss: 0.0952\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.1028\n",
      "Epoch: 93/100... Training loss: 0.0969\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.0940\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0960\n",
      "Epoch: 93/100... Training loss: 0.0965\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0964\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.0960\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0951\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0956\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0937\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.0960\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.0956\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.0950\n",
      "Epoch: 93/100... Training loss: 0.0957\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0946\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0951\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0937\n",
      "Epoch: 93/100... Training loss: 0.0961\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0959\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0964\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0955\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100... Training loss: 0.0966\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.1033\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.0969\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.0963\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0969\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0940\n",
      "Epoch: 93/100... Training loss: 0.0956\n",
      "Epoch: 93/100... Training loss: 0.0966\n",
      "Epoch: 93/100... Training loss: 0.0966\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0941\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0959\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.0931\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0959\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0948\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.0952\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.0948\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0965\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0947\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.0944\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0966\n",
      "Epoch: 93/100... Training loss: 0.0946\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0953\n",
      "Epoch: 93/100... Training loss: 0.0952\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0943\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0969\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0954\n",
      "Epoch: 93/100... Training loss: 0.0952\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0964\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0951\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0963\n",
      "Epoch: 93/100... Training loss: 0.0966\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0950\n",
      "Epoch: 93/100... Training loss: 0.0957\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0965\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0960\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0933\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0962\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.0937\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0957\n",
      "Epoch: 93/100... Training loss: 0.0962\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0960\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0928\n",
      "Epoch: 94/100... Training loss: 0.0952\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0963\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100... Training loss: 0.0960\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0952\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0943\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0963\n",
      "Epoch: 94/100... Training loss: 0.0959\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0971\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.1040\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0948\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0955\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.0943\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0960\n",
      "Epoch: 94/100... Training loss: 0.0959\n",
      "Epoch: 94/100... Training loss: 0.0965\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.0971\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0971\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0971\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0963\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0963\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0956\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0951\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0959\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0959\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0965\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0963\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.0963\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0971\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0955\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.0950\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0936\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0956\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0964\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0971\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0944\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0925\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.0950\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.0965\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0963\n",
      "Epoch: 94/100... Training loss: 0.0937\n",
      "Epoch: 94/100... Training loss: 0.0965\n",
      "Epoch: 94/100... Training loss: 0.0952\n",
      "Epoch: 94/100... Training loss: 0.0948\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0959\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0942\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0950\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0964\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.0958\n",
      "Epoch: 94/100... Training loss: 0.0945\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1029\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0946\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0960\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.0960\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0942\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.0951\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0940\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0949\n",
      "Epoch: 95/100... Training loss: 0.0965\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.0937\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0948\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0957\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0956\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0958\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0940\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0956\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0944\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0944\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0960\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.0947\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0965\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0946\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.1023\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0958\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0943\n",
      "Epoch: 95/100... Training loss: 0.0958\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0950\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.0949\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0957\n",
      "Epoch: 95/100... Training loss: 0.0937\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0952\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.0993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0940\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.0964\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.0957\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0957\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0948\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0946\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.0950\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.0965\n",
      "Epoch: 95/100... Training loss: 0.0943\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0959\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0928\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0942\n",
      "Epoch: 95/100... Training loss: 0.0964\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0959\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0941\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0924\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0961\n",
      "Epoch: 95/100... Training loss: 0.0964\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0956\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0952\n",
      "Epoch: 95/100... Training loss: 0.0965\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0952\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0958\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0955\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.0951\n",
      "Epoch: 96/100... Training loss: 0.0952\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0952\n",
      "Epoch: 96/100... Training loss: 0.0942\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0962\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0953\n",
      "Epoch: 96/100... Training loss: 0.0958\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0944\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0959\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0946\n",
      "Epoch: 96/100... Training loss: 0.1023\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0955\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0962\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0962\n",
      "Epoch: 96/100... Training loss: 0.0962\n",
      "Epoch: 96/100... Training loss: 0.0947\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0956\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0959\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0953\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0957\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0964\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0959\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0957\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.0953\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0937\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0954\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0953\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0958\n",
      "Epoch: 96/100... Training loss: 0.1023\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.0946\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0948\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0958\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0919\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0953\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0964\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0945\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.0945\n",
      "Epoch: 96/100... Training loss: 0.0951\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0960\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0951\n",
      "Epoch: 96/100... Training loss: 0.0955\n",
      "Epoch: 96/100... Training loss: 0.0954\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0941\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0962\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.0954\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0936\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.0972\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.0964\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.0959\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0959\n",
      "Epoch: 97/100... Training loss: 0.1038\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0955\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0933\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0942\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0969\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0950\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0960\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.1018\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0977\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0951\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0952\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0977\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0944\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0961\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0977\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.0963\n",
      "Epoch: 97/100... Training loss: 0.1032\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0942\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0962\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.0958\n",
      "Epoch: 97/100... Training loss: 0.0949\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0950\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0955\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0961\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0963\n",
      "Epoch: 97/100... Training loss: 0.0930\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0946\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0977\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.0977\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0936\n",
      "Epoch: 97/100... Training loss: 0.0935\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0956\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.0963\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.0949\n",
      "Epoch: 97/100... Training loss: 0.0997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0963\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0969\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0969\n",
      "Epoch: 97/100... Training loss: 0.0947\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.0959\n",
      "Epoch: 97/100... Training loss: 0.1018\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.0958\n",
      "Epoch: 97/100... Training loss: 0.0944\n",
      "Epoch: 97/100... Training loss: 0.0961\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0962\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0962\n",
      "Epoch: 97/100... Training loss: 0.0956\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0951\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0953\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0961\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0944\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.1020\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0969\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0961\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.0955\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0948\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.0943\n",
      "Epoch: 97/100... Training loss: 0.0954\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0958\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0958\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0969\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0963\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0941\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0946\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0954\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0957\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0946\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0961\n",
      "Epoch: 97/100... Training loss: 0.0969\n",
      "Epoch: 97/100... Training loss: 0.0945\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0961\n",
      "Epoch: 98/100... Training loss: 0.0954\n",
      "Epoch: 98/100... Training loss: 0.0925\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.0952\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0953\n",
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.0962\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0961\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.0957\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0966\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.0949\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0955\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0949\n",
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0952\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0942\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0958\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0957\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0953\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.0963\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0956\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0962\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0956\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0961\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0963\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0954\n",
      "Epoch: 98/100... Training loss: 0.0966\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0931\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0966\n",
      "Epoch: 98/100... Training loss: 0.0955\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0966\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.0949\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0954\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0952\n",
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0958\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.1017\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0947\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.0966\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0955\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.0969\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.0961\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0954\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0953\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0955\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0962\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0934\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0944\n",
      "Epoch: 98/100... Training loss: 0.0947\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0951\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.0947\n",
      "Epoch: 98/100... Training loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0966\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.0930\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0958\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0952\n",
      "Epoch: 99/100... Training loss: 0.0952\n",
      "Epoch: 99/100... Training loss: 0.0958\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0979\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0952\n",
      "Epoch: 99/100... Training loss: 0.0952\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0952\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0944\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0934\n",
      "Epoch: 99/100... Training loss: 0.0948\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.0953\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0941\n",
      "Epoch: 99/100... Training loss: 0.0950\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.0966\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0961\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0955\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.0956\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0951\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.0951\n",
      "Epoch: 99/100... Training loss: 0.0946\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0957\n",
      "Epoch: 99/100... Training loss: 0.0961\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0961\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0947\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0959\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.0948\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0961\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0961\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.0956\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0927\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0953\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0948\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0957\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0957\n",
      "Epoch: 99/100... Training loss: 0.0966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0944\n",
      "Epoch: 99/100... Training loss: 0.0948\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0955\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0953\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0953\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0966\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0925\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0955\n",
      "Epoch: 99/100... Training loss: 0.0943\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0945\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0968\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0947\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0966\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0949\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0968\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0951\n",
      "Epoch: 99/100... Training loss: 0.0961\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0951\n",
      "Epoch: 99/100... Training loss: 0.0966\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0968\n",
      "Epoch: 99/100... Training loss: 0.0955\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.0954\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0959\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0961\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0956\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0946\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0966\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0956\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0960\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0950\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0958\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0958\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0952\n",
      "Epoch: 100/100... Training loss: 0.0970\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0951\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0952\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.0957\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0959\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.0943\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0932\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0942\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100... Training loss: 0.0927\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.0957\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0970\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.0949\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0959\n",
      "Epoch: 100/100... Training loss: 0.0955\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.0956\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.0929\n",
      "Epoch: 100/100... Training loss: 0.0952\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0950\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.0938\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0958\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0952\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0955\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.0957\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0943\n",
      "Epoch: 100/100... Training loss: 0.0952\n",
      "Epoch: 100/100... Training loss: 0.0963\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0961\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.0947\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0954\n",
      "Epoch: 100/100... Training loss: 0.0963\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0934\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.0935\n",
      "Epoch: 100/100... Training loss: 0.0955\n",
      "Epoch: 100/100... Training loss: 0.0959\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.0942\n",
      "Epoch: 100/100... Training loss: 0.0945\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.0961\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0941\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0961\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0951\n",
      "Epoch: 100/100... Training loss: 0.0960\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0963\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0923\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0953\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.0956\n",
      "Epoch: 100/100... Training loss: 0.0945\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0961\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0958\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0963\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0947\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0935\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0970\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0958\n",
      "Epoch: 100/100... Training loss: 0.0949\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0961\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0951\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 200\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.5\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        # Get images from the batch\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        \n",
    "        # Add random noise to the input images\n",
    "        noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "        # Clip the images to be between 0 and 1\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)#clip是限幅函数，让数组中的元素处于0-1之间\n",
    "        \n",
    "        # Noisy images as inputs, original images as targets\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: noisy_imgs,\n",
    "                                                         targets_: imgs})#输入是带噪声图片，输出标签是无噪声图片\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the performance\n",
    "\n",
    "Here I'm adding noise to the test images and passing them through the autoencoder. It does a suprising great job of removing the noise, even though it's sometimes difficult to tell what the original number is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "noisy_imgs = in_imgs + noise_factor * np.random.randn(*in_imgs.shape)\n",
    "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: noisy_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([noisy_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
